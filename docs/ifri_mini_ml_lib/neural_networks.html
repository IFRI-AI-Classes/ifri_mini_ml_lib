<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 15.0.3"/>
    <title>ifri_mini_ml_lib.neural_networks API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:.75rem center;margin-bottom:1rem;}.pdoc .alert > em{display:none;}.pdoc .alert > *:last-child{margin-bottom:0;}.pdoc .alert.note{color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .alert.tip{color:#0a3622;background-color:#d1e7dd;border-color:#a3cfbb;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%230a3622%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%206a6%206%200%201%201%2010.174%204.31c-.203.196-.359.4-.453.619l-.762%201.769A.5.5%200%200%201%2010.5%2013a.5.5%200%200%201%200%201%20.5.5%200%200%201%200%201l-.224.447a1%201%200%200%201-.894.553H6.618a1%201%200%200%201-.894-.553L5.5%2015a.5.5%200%200%201%200-1%20.5.5%200%200%201%200-1%20.5.5%200%200%201-.46-.302l-.761-1.77a2%202%200%200%200-.453-.618A5.98%205.98%200%200%201%202%206m6-5a5%205%200%200%200-3.479%208.592c.263.254.514.564.676.941L5.83%2012h4.342l.632-1.467c.162-.377.413-.687.676-.941A5%205%200%200%200%208%201%22/%3E%3C/svg%3E");}.pdoc .alert.important{color:#055160;background-color:#cff4fc;border-color:#9eeaf9;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23055160%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%200a2%202%200%200%200-2%202v12a2%202%200%200%200%202%202h12a2%202%200%200%200%202-2V2a2%202%200%200%200-2-2zm6%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .alert.caution{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M11.46.146A.5.5%200%200%200%2011.107%200H4.893a.5.5%200%200%200-.353.146L.146%204.54A.5.5%200%200%200%200%204.893v6.214a.5.5%200%200%200%20.146.353l4.394%204.394a.5.5%200%200%200%20.353.146h6.214a.5.5%200%200%200%20.353-.146l4.394-4.394a.5.5%200%200%200%20.146-.353V4.893a.5.5%200%200%200-.146-.353zM8%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .decorator-deprecated{color:#842029;}.pdoc .decorator-deprecated ~ span{filter:grayscale(1) opacity(0.8);}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../ifri_mini_ml_lib.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;ifri_mini_ml_lib</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="class" href="#MLPClassifier">MLPClassifier</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#MLPClassifier.__init__">MLPClassifier</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.hidden_layer_sizes">hidden_layer_sizes</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.activation">activation</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.solver">solver</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.alpha">alpha</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.batch_size">batch_size</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.learning_rate">learning_rate</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.max_iter">max_iter</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.shuffle">shuffle</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.beta1">beta1</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.beta2">beta2</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.epsilon">epsilon</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.momentum">momentum</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.tol">tol</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.early_stopping">early_stopping</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.validation_fraction">validation_fraction</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.n_iter_no_change">n_iter_no_change</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.activation_functions">activation_functions</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.activation_derivatives">activation_derivatives</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.activation_func">activation_func</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.activation_derivative">activation_derivative</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.weights">weights</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.biases">biases</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.n_layers">n_layers</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.n_outputs">n_outputs</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.velocity_weights">velocity_weights</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.velocity_biases">velocity_biases</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.m_weights">m_weights</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.m_biases">m_biases</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.v_weights">v_weights</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.v_biases">v_biases</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.t">t</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.loss_history">loss_history</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.val_loss_history">val_loss_history</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.best_loss">best_loss</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.no_improvement_count">no_improvement_count</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.trained">trained</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPClassifier.classes_">classes_</a>
                        </li>
                        <li>
                                <a class="function" href="#MLPClassifier.fit">fit</a>
                        </li>
                        <li>
                                <a class="function" href="#MLPClassifier.predict">predict</a>
                        </li>
                        <li>
                                <a class="function" href="#MLPClassifier.predict_proba">predict_proba</a>
                        </li>
                        <li>
                                <a class="function" href="#MLPClassifier.score">score</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#MLPRegressor">MLPRegressor</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#MLPRegressor.__init__">MLPRegressor</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.hidden_layer_sizes">hidden_layer_sizes</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.activation">activation</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.solver">solver</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.alpha">alpha</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.batch_size">batch_size</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.learning_rate">learning_rate</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.max_iter">max_iter</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.shuffle">shuffle</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.beta1">beta1</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.beta2">beta2</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.epsilon">epsilon</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.momentum">momentum</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.tol">tol</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.early_stopping">early_stopping</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.validation_fraction">validation_fraction</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.n_iter_no_change">n_iter_no_change</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.activation_functions">activation_functions</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.activation_derivatives">activation_derivatives</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.activation_func">activation_func</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.activation_derivative">activation_derivative</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.weights">weights</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.biases">biases</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.n_layers">n_layers</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.n_outputs">n_outputs</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.velocity_weights">velocity_weights</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.velocity_biases">velocity_biases</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.m_weights">m_weights</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.m_biases">m_biases</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.v_weights">v_weights</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.v_biases">v_biases</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.t">t</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.loss_history">loss_history</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.val_loss_history">val_loss_history</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.best_loss">best_loss</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.no_improvement_count">no_improvement_count</a>
                        </li>
                        <li>
                                <a class="variable" href="#MLPRegressor.trained">trained</a>
                        </li>
                        <li>
                                <a class="function" href="#MLPRegressor.fit">fit</a>
                        </li>
                        <li>
                                <a class="function" href="#MLPRegressor.predict">predict</a>
                        </li>
                        <li>
                                <a class="function" href="#MLPRegressor.score">score</a>
                        </li>
                </ul>

            </li>
    </ul>


            <footer>Â© 2025 IFRI Machine Learning Library</footer>

        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../ifri_mini_ml_lib.html">ifri_mini_ml_lib</a><wbr>.neural_networks    </h1>

                
                        <input id="mod-neural_networks-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-neural_networks-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">1</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.mlp_classifier</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLPClassifier</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">2</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.mlp_regressor</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLPRegressor</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos">3</span></a>
</span><span id="L-4"><a href="#L-4"><span class="linenos">4</span></a><span class="n">__all__</span> <span class="o">=</span><span class="p">[</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos">5</span></a>    <span class="s2">&quot;MLPClassifier&quot;</span><span class="p">,</span> <span class="s2">&quot;MLPRegressor&quot;</span><span class="p">,</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos">6</span></a><span class="p">]</span>
</span></pre></div>


            </section>
                <section id="MLPClassifier">
                            <input id="MLPClassifier-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">MLPClassifier</span>:

                <label class="view-source-button" for="MLPClassifier-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MLPClassifier"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MLPClassifier-6"><a href="#MLPClassifier-6"><span class="linenos">  6</span></a><span class="k">class</span><span class="w"> </span><span class="nc">MLPClassifier</span><span class="p">:</span>
</span><span id="MLPClassifier-7"><a href="#MLPClassifier-7"><span class="linenos">  7</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-8"><a href="#MLPClassifier-8"><span class="linenos">  8</span></a><span class="sd">    Multi-Layer Perceptron with different activation functions and optimizers</span>
</span><span id="MLPClassifier-9"><a href="#MLPClassifier-9"><span class="linenos">  9</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-10"><a href="#MLPClassifier-10"><span class="linenos"> 10</span></a>    
</span><span id="MLPClassifier-11"><a href="#MLPClassifier-11"><span class="linenos"> 11</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="MLPClassifier-12"><a href="#MLPClassifier-12"><span class="linenos"> 12</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="MLPClassifier-13"><a href="#MLPClassifier-13"><span class="linenos"> 13</span></a>        <span class="n">hidden_layer_sizes</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">100</span><span class="p">,),</span>
</span><span id="MLPClassifier-14"><a href="#MLPClassifier-14"><span class="linenos"> 14</span></a>        <span class="n">activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
</span><span id="MLPClassifier-15"><a href="#MLPClassifier-15"><span class="linenos"> 15</span></a>        <span class="n">solver</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sgd&quot;</span><span class="p">,</span>
</span><span id="MLPClassifier-16"><a href="#MLPClassifier-16"><span class="linenos"> 16</span></a>        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0001</span><span class="p">,</span>
</span><span id="MLPClassifier-17"><a href="#MLPClassifier-17"><span class="linenos"> 17</span></a>        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
</span><span id="MLPClassifier-18"><a href="#MLPClassifier-18"><span class="linenos"> 18</span></a>        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
</span><span id="MLPClassifier-19"><a href="#MLPClassifier-19"><span class="linenos"> 19</span></a>        <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
</span><span id="MLPClassifier-20"><a href="#MLPClassifier-20"><span class="linenos"> 20</span></a>        <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="MLPClassifier-21"><a href="#MLPClassifier-21"><span class="linenos"> 21</span></a>        <span class="n">random_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="MLPClassifier-22"><a href="#MLPClassifier-22"><span class="linenos"> 22</span></a>        <span class="n">beta1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
</span><span id="MLPClassifier-23"><a href="#MLPClassifier-23"><span class="linenos"> 23</span></a>        <span class="n">beta2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.999</span><span class="p">,</span>
</span><span id="MLPClassifier-24"><a href="#MLPClassifier-24"><span class="linenos"> 24</span></a>        <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
</span><span id="MLPClassifier-25"><a href="#MLPClassifier-25"><span class="linenos"> 25</span></a>        <span class="n">momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
</span><span id="MLPClassifier-26"><a href="#MLPClassifier-26"><span class="linenos"> 26</span></a>        <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
</span><span id="MLPClassifier-27"><a href="#MLPClassifier-27"><span class="linenos"> 27</span></a>        <span class="n">early_stopping</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="MLPClassifier-28"><a href="#MLPClassifier-28"><span class="linenos"> 28</span></a>        <span class="n">validation_fraction</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
</span><span id="MLPClassifier-29"><a href="#MLPClassifier-29"><span class="linenos"> 29</span></a>        <span class="n">n_iter_no_change</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>
</span><span id="MLPClassifier-30"><a href="#MLPClassifier-30"><span class="linenos"> 30</span></a>    <span class="p">):</span>
</span><span id="MLPClassifier-31"><a href="#MLPClassifier-31"><span class="linenos"> 31</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-32"><a href="#MLPClassifier-32"><span class="linenos"> 32</span></a><span class="sd">        Initialize an MLP network</span>
</span><span id="MLPClassifier-33"><a href="#MLPClassifier-33"><span class="linenos"> 33</span></a><span class="sd">        </span>
</span><span id="MLPClassifier-34"><a href="#MLPClassifier-34"><span class="linenos"> 34</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPClassifier-35"><a href="#MLPClassifier-35"><span class="linenos"> 35</span></a><span class="sd">        -----------</span>
</span><span id="MLPClassifier-36"><a href="#MLPClassifier-36"><span class="linenos"> 36</span></a><span class="sd">        hidden_layer_sizes : tuple</span>
</span><span id="MLPClassifier-37"><a href="#MLPClassifier-37"><span class="linenos"> 37</span></a><span class="sd">            The sizes of hidden layers</span>
</span><span id="MLPClassifier-38"><a href="#MLPClassifier-38"><span class="linenos"> 38</span></a><span class="sd">        activation : str</span>
</span><span id="MLPClassifier-39"><a href="#MLPClassifier-39"><span class="linenos"> 39</span></a><span class="sd">            Activation function (&#39;sigmoid&#39;, &#39;relu&#39;, &#39;tanh&#39;, &#39;leaky_relu&#39;)</span>
</span><span id="MLPClassifier-40"><a href="#MLPClassifier-40"><span class="linenos"> 40</span></a><span class="sd">        solver : str</span>
</span><span id="MLPClassifier-41"><a href="#MLPClassifier-41"><span class="linenos"> 41</span></a><span class="sd">            Optimization algorithm (&#39;sgd&#39;, &#39;adam&#39;, &#39;rmsprop&#39;, &#39;momentum&#39;)</span>
</span><span id="MLPClassifier-42"><a href="#MLPClassifier-42"><span class="linenos"> 42</span></a><span class="sd">        alpha : float</span>
</span><span id="MLPClassifier-43"><a href="#MLPClassifier-43"><span class="linenos"> 43</span></a><span class="sd">            L2 regularization parameter</span>
</span><span id="MLPClassifier-44"><a href="#MLPClassifier-44"><span class="linenos"> 44</span></a><span class="sd">        batch_size : int</span>
</span><span id="MLPClassifier-45"><a href="#MLPClassifier-45"><span class="linenos"> 45</span></a><span class="sd">            Batch size for training</span>
</span><span id="MLPClassifier-46"><a href="#MLPClassifier-46"><span class="linenos"> 46</span></a><span class="sd">        learning_rate : float</span>
</span><span id="MLPClassifier-47"><a href="#MLPClassifier-47"><span class="linenos"> 47</span></a><span class="sd">            Learning rate</span>
</span><span id="MLPClassifier-48"><a href="#MLPClassifier-48"><span class="linenos"> 48</span></a><span class="sd">        max_iter : int</span>
</span><span id="MLPClassifier-49"><a href="#MLPClassifier-49"><span class="linenos"> 49</span></a><span class="sd">            Maximum number of iterations</span>
</span><span id="MLPClassifier-50"><a href="#MLPClassifier-50"><span class="linenos"> 50</span></a><span class="sd">        shuffle : bool</span>
</span><span id="MLPClassifier-51"><a href="#MLPClassifier-51"><span class="linenos"> 51</span></a><span class="sd">            If True, shuffle data at each epoch</span>
</span><span id="MLPClassifier-52"><a href="#MLPClassifier-52"><span class="linenos"> 52</span></a><span class="sd">        random_state : int or None</span>
</span><span id="MLPClassifier-53"><a href="#MLPClassifier-53"><span class="linenos"> 53</span></a><span class="sd">            Seed for reproducibility</span>
</span><span id="MLPClassifier-54"><a href="#MLPClassifier-54"><span class="linenos"> 54</span></a><span class="sd">        beta1 : float</span>
</span><span id="MLPClassifier-55"><a href="#MLPClassifier-55"><span class="linenos"> 55</span></a><span class="sd">            Parameter for Adam (exponential decay of first moment)</span>
</span><span id="MLPClassifier-56"><a href="#MLPClassifier-56"><span class="linenos"> 56</span></a><span class="sd">        beta2 : float</span>
</span><span id="MLPClassifier-57"><a href="#MLPClassifier-57"><span class="linenos"> 57</span></a><span class="sd">            Parameter for Adam (exponential decay of second moment)</span>
</span><span id="MLPClassifier-58"><a href="#MLPClassifier-58"><span class="linenos"> 58</span></a><span class="sd">        epsilon : float</span>
</span><span id="MLPClassifier-59"><a href="#MLPClassifier-59"><span class="linenos"> 59</span></a><span class="sd">            Value to avoid division by zero</span>
</span><span id="MLPClassifier-60"><a href="#MLPClassifier-60"><span class="linenos"> 60</span></a><span class="sd">        momentum : float</span>
</span><span id="MLPClassifier-61"><a href="#MLPClassifier-61"><span class="linenos"> 61</span></a><span class="sd">            Parameter for momentum optimizer</span>
</span><span id="MLPClassifier-62"><a href="#MLPClassifier-62"><span class="linenos"> 62</span></a><span class="sd">        tol : float</span>
</span><span id="MLPClassifier-63"><a href="#MLPClassifier-63"><span class="linenos"> 63</span></a><span class="sd">            Tolerance for early stopping</span>
</span><span id="MLPClassifier-64"><a href="#MLPClassifier-64"><span class="linenos"> 64</span></a><span class="sd">        early_stopping : bool</span>
</span><span id="MLPClassifier-65"><a href="#MLPClassifier-65"><span class="linenos"> 65</span></a><span class="sd">            If True, use early stopping based on validation</span>
</span><span id="MLPClassifier-66"><a href="#MLPClassifier-66"><span class="linenos"> 66</span></a><span class="sd">        validation_fraction : float</span>
</span><span id="MLPClassifier-67"><a href="#MLPClassifier-67"><span class="linenos"> 67</span></a><span class="sd">            Fraction of training data to use as validation</span>
</span><span id="MLPClassifier-68"><a href="#MLPClassifier-68"><span class="linenos"> 68</span></a><span class="sd">        n_iter_no_change : int</span>
</span><span id="MLPClassifier-69"><a href="#MLPClassifier-69"><span class="linenos"> 69</span></a><span class="sd">            Number of iterations with no improvement for early stopping</span>
</span><span id="MLPClassifier-70"><a href="#MLPClassifier-70"><span class="linenos"> 70</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-71"><a href="#MLPClassifier-71"><span class="linenos"> 71</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_sizes</span> <span class="o">=</span> <span class="n">hidden_layer_sizes</span>
</span><span id="MLPClassifier-72"><a href="#MLPClassifier-72"><span class="linenos"> 72</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
</span><span id="MLPClassifier-73"><a href="#MLPClassifier-73"><span class="linenos"> 73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">=</span> <span class="n">solver</span>
</span><span id="MLPClassifier-74"><a href="#MLPClassifier-74"><span class="linenos"> 74</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
</span><span id="MLPClassifier-75"><a href="#MLPClassifier-75"><span class="linenos"> 75</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
</span><span id="MLPClassifier-76"><a href="#MLPClassifier-76"><span class="linenos"> 76</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
</span><span id="MLPClassifier-77"><a href="#MLPClassifier-77"><span class="linenos"> 77</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
</span><span id="MLPClassifier-78"><a href="#MLPClassifier-78"><span class="linenos"> 78</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span>
</span><span id="MLPClassifier-79"><a href="#MLPClassifier-79"><span class="linenos"> 79</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">=</span> <span class="n">beta1</span>
</span><span id="MLPClassifier-80"><a href="#MLPClassifier-80"><span class="linenos"> 80</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">=</span> <span class="n">beta2</span>
</span><span id="MLPClassifier-81"><a href="#MLPClassifier-81"><span class="linenos"> 81</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
</span><span id="MLPClassifier-82"><a href="#MLPClassifier-82"><span class="linenos"> 82</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
</span><span id="MLPClassifier-83"><a href="#MLPClassifier-83"><span class="linenos"> 83</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
</span><span id="MLPClassifier-84"><a href="#MLPClassifier-84"><span class="linenos"> 84</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping</span> <span class="o">=</span> <span class="n">early_stopping</span>
</span><span id="MLPClassifier-85"><a href="#MLPClassifier-85"><span class="linenos"> 85</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">validation_fraction</span> <span class="o">=</span> <span class="n">validation_fraction</span>
</span><span id="MLPClassifier-86"><a href="#MLPClassifier-86"><span class="linenos"> 86</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span> <span class="o">=</span> <span class="n">n_iter_no_change</span>
</span><span id="MLPClassifier-87"><a href="#MLPClassifier-87"><span class="linenos"> 87</span></a>        
</span><span id="MLPClassifier-88"><a href="#MLPClassifier-88"><span class="linenos"> 88</span></a>        <span class="k">if</span> <span class="n">random_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="MLPClassifier-89"><a href="#MLPClassifier-89"><span class="linenos"> 89</span></a>            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
</span><span id="MLPClassifier-90"><a href="#MLPClassifier-90"><span class="linenos"> 90</span></a>        
</span><span id="MLPClassifier-91"><a href="#MLPClassifier-91"><span class="linenos"> 91</span></a>        <span class="c1"># Selection of activation functions</span>
</span><span id="MLPClassifier-92"><a href="#MLPClassifier-92"><span class="linenos"> 92</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation_functions</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="MLPClassifier-93"><a href="#MLPClassifier-93"><span class="linenos"> 93</span></a>            <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid</span><span class="p">,</span>
</span><span id="MLPClassifier-94"><a href="#MLPClassifier-94"><span class="linenos"> 94</span></a>            <span class="s1">&#39;relu&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">,</span>
</span><span id="MLPClassifier-95"><a href="#MLPClassifier-95"><span class="linenos"> 95</span></a>            <span class="s1">&#39;tanh&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tanh</span><span class="p">,</span>
</span><span id="MLPClassifier-96"><a href="#MLPClassifier-96"><span class="linenos"> 96</span></a>            <span class="s1">&#39;softmax&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">,</span>
</span><span id="MLPClassifier-97"><a href="#MLPClassifier-97"><span class="linenos"> 97</span></a>            <span class="s1">&#39;leaky_relu&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaky_relu</span><span class="p">,</span>
</span><span id="MLPClassifier-98"><a href="#MLPClassifier-98"><span class="linenos"> 98</span></a>        <span class="p">}</span>
</span><span id="MLPClassifier-99"><a href="#MLPClassifier-99"><span class="linenos"> 99</span></a>        
</span><span id="MLPClassifier-100"><a href="#MLPClassifier-100"><span class="linenos">100</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation_derivatives</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="MLPClassifier-101"><a href="#MLPClassifier-101"><span class="linenos">101</span></a>            <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid_derivative</span><span class="p">,</span>
</span><span id="MLPClassifier-102"><a href="#MLPClassifier-102"><span class="linenos">102</span></a>            <span class="s1">&#39;relu&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu_derivative</span><span class="p">,</span>
</span><span id="MLPClassifier-103"><a href="#MLPClassifier-103"><span class="linenos">103</span></a>            <span class="s1">&#39;tanh&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tanh_derivative</span><span class="p">,</span>
</span><span id="MLPClassifier-104"><a href="#MLPClassifier-104"><span class="linenos">104</span></a>            <span class="s1">&#39;softmax&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax_derivative</span><span class="p">,</span>
</span><span id="MLPClassifier-105"><a href="#MLPClassifier-105"><span class="linenos">105</span></a>            <span class="s1">&#39;leaky_relu&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaky_relu_derivative</span><span class="p">,</span>
</span><span id="MLPClassifier-106"><a href="#MLPClassifier-106"><span class="linenos">106</span></a>        <span class="p">}</span>
</span><span id="MLPClassifier-107"><a href="#MLPClassifier-107"><span class="linenos">107</span></a>        
</span><span id="MLPClassifier-108"><a href="#MLPClassifier-108"><span class="linenos">108</span></a>        <span class="c1"># Selection of activation function and its derivative</span>
</span><span id="MLPClassifier-109"><a href="#MLPClassifier-109"><span class="linenos">109</span></a>        <span class="k">if</span> <span class="n">activation</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_functions</span><span class="p">:</span>
</span><span id="MLPClassifier-110"><a href="#MLPClassifier-110"><span class="linenos">110</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Activation &#39;</span><span class="si">{</span><span class="n">activation</span><span class="si">}</span><span class="s2">&#39; not recognized. Use &#39;sigmoid&#39;, &#39;relu&#39;, &#39;tanh&#39;, or &#39;leaky_relu&#39;.&quot;</span><span class="p">)</span>
</span><span id="MLPClassifier-111"><a href="#MLPClassifier-111"><span class="linenos">111</span></a>        
</span><span id="MLPClassifier-112"><a href="#MLPClassifier-112"><span class="linenos">112</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_functions</span><span class="p">[</span><span class="n">activation</span><span class="p">]</span>
</span><span id="MLPClassifier-113"><a href="#MLPClassifier-113"><span class="linenos">113</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation_derivative</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_derivatives</span><span class="p">[</span><span class="n">activation</span><span class="p">]</span>
</span><span id="MLPClassifier-114"><a href="#MLPClassifier-114"><span class="linenos">114</span></a>        
</span><span id="MLPClassifier-115"><a href="#MLPClassifier-115"><span class="linenos">115</span></a>        <span class="c1"># Weight initialization</span>
</span><span id="MLPClassifier-116"><a href="#MLPClassifier-116"><span class="linenos">116</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-117"><a href="#MLPClassifier-117"><span class="linenos">117</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-118"><a href="#MLPClassifier-118"><span class="linenos">118</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="MLPClassifier-119"><a href="#MLPClassifier-119"><span class="linenos">119</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="MLPClassifier-120"><a href="#MLPClassifier-120"><span class="linenos">120</span></a>        
</span><span id="MLPClassifier-121"><a href="#MLPClassifier-121"><span class="linenos">121</span></a>        <span class="c1"># For optimizers</span>
</span><span id="MLPClassifier-122"><a href="#MLPClassifier-122"><span class="linenos">122</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">velocity_weights</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># For Momentum</span>
</span><span id="MLPClassifier-123"><a href="#MLPClassifier-123"><span class="linenos">123</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">velocity_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-124"><a href="#MLPClassifier-124"><span class="linenos">124</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">m_weights</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># For Adam</span>
</span><span id="MLPClassifier-125"><a href="#MLPClassifier-125"><span class="linenos">125</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">m_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-126"><a href="#MLPClassifier-126"><span class="linenos">126</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># For Adam</span>
</span><span id="MLPClassifier-127"><a href="#MLPClassifier-127"><span class="linenos">127</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-128"><a href="#MLPClassifier-128"><span class="linenos">128</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Timestep for Adam</span>
</span><span id="MLPClassifier-129"><a href="#MLPClassifier-129"><span class="linenos">129</span></a>        
</span><span id="MLPClassifier-130"><a href="#MLPClassifier-130"><span class="linenos">130</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-131"><a href="#MLPClassifier-131"><span class="linenos">131</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-132"><a href="#MLPClassifier-132"><span class="linenos">132</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</span><span id="MLPClassifier-133"><a href="#MLPClassifier-133"><span class="linenos">133</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="MLPClassifier-134"><a href="#MLPClassifier-134"><span class="linenos">134</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">trained</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="MLPClassifier-135"><a href="#MLPClassifier-135"><span class="linenos">135</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="MLPClassifier-136"><a href="#MLPClassifier-136"><span class="linenos">136</span></a>    
</span><span id="MLPClassifier-137"><a href="#MLPClassifier-137"><span class="linenos">137</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_initialize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="MLPClassifier-138"><a href="#MLPClassifier-138"><span class="linenos">138</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-139"><a href="#MLPClassifier-139"><span class="linenos">139</span></a><span class="sd">        Initialize the weights and biases of the network</span>
</span><span id="MLPClassifier-140"><a href="#MLPClassifier-140"><span class="linenos">140</span></a><span class="sd">        </span>
</span><span id="MLPClassifier-141"><a href="#MLPClassifier-141"><span class="linenos">141</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPClassifier-142"><a href="#MLPClassifier-142"><span class="linenos">142</span></a><span class="sd">        -----------</span>
</span><span id="MLPClassifier-143"><a href="#MLPClassifier-143"><span class="linenos">143</span></a><span class="sd">        n_features : int</span>
</span><span id="MLPClassifier-144"><a href="#MLPClassifier-144"><span class="linenos">144</span></a><span class="sd">            Number of input features</span>
</span><span id="MLPClassifier-145"><a href="#MLPClassifier-145"><span class="linenos">145</span></a><span class="sd">        n_outputs : int</span>
</span><span id="MLPClassifier-146"><a href="#MLPClassifier-146"><span class="linenos">146</span></a><span class="sd">            Number of output classes</span>
</span><span id="MLPClassifier-147"><a href="#MLPClassifier-147"><span class="linenos">147</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-148"><a href="#MLPClassifier-148"><span class="linenos">148</span></a>        <span class="c1"># Layer dimensions</span>
</span><span id="MLPClassifier-149"><a href="#MLPClassifier-149"><span class="linenos">149</span></a>        <span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_features</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_sizes</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">n_outputs</span><span class="p">]</span>
</span><span id="MLPClassifier-150"><a href="#MLPClassifier-150"><span class="linenos">150</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="MLPClassifier-151"><a href="#MLPClassifier-151"><span class="linenos">151</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span> <span class="o">=</span> <span class="n">n_outputs</span>
</span><span id="MLPClassifier-152"><a href="#MLPClassifier-152"><span class="linenos">152</span></a>        
</span><span id="MLPClassifier-153"><a href="#MLPClassifier-153"><span class="linenos">153</span></a>        <span class="c1"># Reset lists</span>
</span><span id="MLPClassifier-154"><a href="#MLPClassifier-154"><span class="linenos">154</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-155"><a href="#MLPClassifier-155"><span class="linenos">155</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-156"><a href="#MLPClassifier-156"><span class="linenos">156</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">velocity_weights</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-157"><a href="#MLPClassifier-157"><span class="linenos">157</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">velocity_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-158"><a href="#MLPClassifier-158"><span class="linenos">158</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">m_weights</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-159"><a href="#MLPClassifier-159"><span class="linenos">159</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">m_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-160"><a href="#MLPClassifier-160"><span class="linenos">160</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-161"><a href="#MLPClassifier-161"><span class="linenos">161</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-162"><a href="#MLPClassifier-162"><span class="linenos">162</span></a>        
</span><span id="MLPClassifier-163"><a href="#MLPClassifier-163"><span class="linenos">163</span></a>        <span class="c1"># Weight initialization with Xavier/Glorot method</span>
</span><span id="MLPClassifier-164"><a href="#MLPClassifier-164"><span class="linenos">164</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="MLPClassifier-165"><a href="#MLPClassifier-165"><span class="linenos">165</span></a>            <span class="n">limit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">6</span> <span class="o">/</span> <span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]))</span>
</span><span id="MLPClassifier-166"><a href="#MLPClassifier-166"><span class="linenos">166</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">limit</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])))</span>
</span><span id="MLPClassifier-167"><a href="#MLPClassifier-167"><span class="linenos">167</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]))</span>
</span><span id="MLPClassifier-168"><a href="#MLPClassifier-168"><span class="linenos">168</span></a>            
</span><span id="MLPClassifier-169"><a href="#MLPClassifier-169"><span class="linenos">169</span></a>            <span class="c1"># Initialization for optimizers</span>
</span><span id="MLPClassifier-170"><a href="#MLPClassifier-170"><span class="linenos">170</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">velocity_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>  <span class="c1"># For Momentum</span>
</span><span id="MLPClassifier-171"><a href="#MLPClassifier-171"><span class="linenos">171</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">velocity_biases</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</span><span id="MLPClassifier-172"><a href="#MLPClassifier-172"><span class="linenos">172</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">m_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>  <span class="c1"># For Adam</span>
</span><span id="MLPClassifier-173"><a href="#MLPClassifier-173"><span class="linenos">173</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">m_biases</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</span><span id="MLPClassifier-174"><a href="#MLPClassifier-174"><span class="linenos">174</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>  <span class="c1"># For Adam</span>
</span><span id="MLPClassifier-175"><a href="#MLPClassifier-175"><span class="linenos">175</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</span><span id="MLPClassifier-176"><a href="#MLPClassifier-176"><span class="linenos">176</span></a>    
</span><span id="MLPClassifier-177"><a href="#MLPClassifier-177"><span class="linenos">177</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_softmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPClassifier-178"><a href="#MLPClassifier-178"><span class="linenos">178</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-179"><a href="#MLPClassifier-179"><span class="linenos">179</span></a><span class="sd">        Softmax activation function</span>
</span><span id="MLPClassifier-180"><a href="#MLPClassifier-180"><span class="linenos">180</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-181"><a href="#MLPClassifier-181"><span class="linenos">181</span></a>        <span class="n">exp_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span><span id="MLPClassifier-182"><a href="#MLPClassifier-182"><span class="linenos">182</span></a>        <span class="k">return</span> <span class="n">exp_x</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">exp_x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="MLPClassifier-183"><a href="#MLPClassifier-183"><span class="linenos">183</span></a>    
</span><span id="MLPClassifier-184"><a href="#MLPClassifier-184"><span class="linenos">184</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_softmax_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPClassifier-185"><a href="#MLPClassifier-185"><span class="linenos">185</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-186"><a href="#MLPClassifier-186"><span class="linenos">186</span></a><span class="sd">        Derivative of softmax function</span>
</span><span id="MLPClassifier-187"><a href="#MLPClassifier-187"><span class="linenos">187</span></a><span class="sd">        For backpropagation with softmax and cross-entropy,</span>
</span><span id="MLPClassifier-188"><a href="#MLPClassifier-188"><span class="linenos">188</span></a><span class="sd">        this derivative is simplified and already handled in _backward_pass</span>
</span><span id="MLPClassifier-189"><a href="#MLPClassifier-189"><span class="linenos">189</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-190"><a href="#MLPClassifier-190"><span class="linenos">190</span></a>        <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="MLPClassifier-191"><a href="#MLPClassifier-191"><span class="linenos">191</span></a>        <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">s</span><span class="p">)</span>
</span><span id="MLPClassifier-192"><a href="#MLPClassifier-192"><span class="linenos">192</span></a>    
</span><span id="MLPClassifier-193"><a href="#MLPClassifier-193"><span class="linenos">193</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_leaky_relu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPClassifier-194"><a href="#MLPClassifier-194"><span class="linenos">194</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-195"><a href="#MLPClassifier-195"><span class="linenos">195</span></a><span class="sd">        Leaky ReLU activation function</span>
</span><span id="MLPClassifier-196"><a href="#MLPClassifier-196"><span class="linenos">196</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-197"><a href="#MLPClassifier-197"><span class="linenos">197</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
</span><span id="MLPClassifier-198"><a href="#MLPClassifier-198"><span class="linenos">198</span></a>    
</span><span id="MLPClassifier-199"><a href="#MLPClassifier-199"><span class="linenos">199</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_leaky_relu_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPClassifier-200"><a href="#MLPClassifier-200"><span class="linenos">200</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-201"><a href="#MLPClassifier-201"><span class="linenos">201</span></a><span class="sd">        Derivative of Leaky ReLU function</span>
</span><span id="MLPClassifier-202"><a href="#MLPClassifier-202"><span class="linenos">202</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-203"><a href="#MLPClassifier-203"><span class="linenos">203</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
</span><span id="MLPClassifier-204"><a href="#MLPClassifier-204"><span class="linenos">204</span></a>    
</span><span id="MLPClassifier-205"><a href="#MLPClassifier-205"><span class="linenos">205</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPClassifier-206"><a href="#MLPClassifier-206"><span class="linenos">206</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-207"><a href="#MLPClassifier-207"><span class="linenos">207</span></a><span class="sd">        Sigmoid activation function</span>
</span><span id="MLPClassifier-208"><a href="#MLPClassifier-208"><span class="linenos">208</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-209"><a href="#MLPClassifier-209"><span class="linenos">209</span></a>        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">)))</span>
</span><span id="MLPClassifier-210"><a href="#MLPClassifier-210"><span class="linenos">210</span></a>    
</span><span id="MLPClassifier-211"><a href="#MLPClassifier-211"><span class="linenos">211</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_sigmoid_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPClassifier-212"><a href="#MLPClassifier-212"><span class="linenos">212</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-213"><a href="#MLPClassifier-213"><span class="linenos">213</span></a><span class="sd">        Derivative of sigmoid function</span>
</span><span id="MLPClassifier-214"><a href="#MLPClassifier-214"><span class="linenos">214</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-215"><a href="#MLPClassifier-215"><span class="linenos">215</span></a>        <span class="n">sigmoid_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="MLPClassifier-216"><a href="#MLPClassifier-216"><span class="linenos">216</span></a>        <span class="k">return</span> <span class="n">sigmoid_x</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigmoid_x</span><span class="p">)</span>
</span><span id="MLPClassifier-217"><a href="#MLPClassifier-217"><span class="linenos">217</span></a>    
</span><span id="MLPClassifier-218"><a href="#MLPClassifier-218"><span class="linenos">218</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_relu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPClassifier-219"><a href="#MLPClassifier-219"><span class="linenos">219</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-220"><a href="#MLPClassifier-220"><span class="linenos">220</span></a><span class="sd">        ReLU activation function</span>
</span><span id="MLPClassifier-221"><a href="#MLPClassifier-221"><span class="linenos">221</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-222"><a href="#MLPClassifier-222"><span class="linenos">222</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</span><span id="MLPClassifier-223"><a href="#MLPClassifier-223"><span class="linenos">223</span></a>    
</span><span id="MLPClassifier-224"><a href="#MLPClassifier-224"><span class="linenos">224</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_relu_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPClassifier-225"><a href="#MLPClassifier-225"><span class="linenos">225</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-226"><a href="#MLPClassifier-226"><span class="linenos">226</span></a><span class="sd">        Derivative of ReLU function</span>
</span><span id="MLPClassifier-227"><a href="#MLPClassifier-227"><span class="linenos">227</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-228"><a href="#MLPClassifier-228"><span class="linenos">228</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="MLPClassifier-229"><a href="#MLPClassifier-229"><span class="linenos">229</span></a>    
</span><span id="MLPClassifier-230"><a href="#MLPClassifier-230"><span class="linenos">230</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_tanh</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPClassifier-231"><a href="#MLPClassifier-231"><span class="linenos">231</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-232"><a href="#MLPClassifier-232"><span class="linenos">232</span></a><span class="sd">        Tanh activation function</span>
</span><span id="MLPClassifier-233"><a href="#MLPClassifier-233"><span class="linenos">233</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-234"><a href="#MLPClassifier-234"><span class="linenos">234</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="MLPClassifier-235"><a href="#MLPClassifier-235"><span class="linenos">235</span></a>    
</span><span id="MLPClassifier-236"><a href="#MLPClassifier-236"><span class="linenos">236</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_tanh_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPClassifier-237"><a href="#MLPClassifier-237"><span class="linenos">237</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-238"><a href="#MLPClassifier-238"><span class="linenos">238</span></a><span class="sd">        Derivative of tanh function</span>
</span><span id="MLPClassifier-239"><a href="#MLPClassifier-239"><span class="linenos">239</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-240"><a href="#MLPClassifier-240"><span class="linenos">240</span></a>        <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="MLPClassifier-241"><a href="#MLPClassifier-241"><span class="linenos">241</span></a>    
</span><span id="MLPClassifier-242"><a href="#MLPClassifier-242"><span class="linenos">242</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_forward_pass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
</span><span id="MLPClassifier-243"><a href="#MLPClassifier-243"><span class="linenos">243</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-244"><a href="#MLPClassifier-244"><span class="linenos">244</span></a><span class="sd">        Forward propagation to calculate activations</span>
</span><span id="MLPClassifier-245"><a href="#MLPClassifier-245"><span class="linenos">245</span></a><span class="sd">        </span>
</span><span id="MLPClassifier-246"><a href="#MLPClassifier-246"><span class="linenos">246</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPClassifier-247"><a href="#MLPClassifier-247"><span class="linenos">247</span></a><span class="sd">        -----------</span>
</span><span id="MLPClassifier-248"><a href="#MLPClassifier-248"><span class="linenos">248</span></a><span class="sd">        X : np.ndarray, shape (n_samples, n_features)</span>
</span><span id="MLPClassifier-249"><a href="#MLPClassifier-249"><span class="linenos">249</span></a><span class="sd">            Input data</span>
</span><span id="MLPClassifier-250"><a href="#MLPClassifier-250"><span class="linenos">250</span></a><span class="sd">            </span>
</span><span id="MLPClassifier-251"><a href="#MLPClassifier-251"><span class="linenos">251</span></a><span class="sd">        Returns:</span>
</span><span id="MLPClassifier-252"><a href="#MLPClassifier-252"><span class="linenos">252</span></a><span class="sd">        --------</span>
</span><span id="MLPClassifier-253"><a href="#MLPClassifier-253"><span class="linenos">253</span></a><span class="sd">        activations : List of activations for each layer</span>
</span><span id="MLPClassifier-254"><a href="#MLPClassifier-254"><span class="linenos">254</span></a><span class="sd">        layer_inputs : List of inputs for each layer (before activation)</span>
</span><span id="MLPClassifier-255"><a href="#MLPClassifier-255"><span class="linenos">255</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-256"><a href="#MLPClassifier-256"><span class="linenos">256</span></a>        <span class="n">activations</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="p">]</span>
</span><span id="MLPClassifier-257"><a href="#MLPClassifier-257"><span class="linenos">257</span></a>        <span class="n">layer_inputs</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-258"><a href="#MLPClassifier-258"><span class="linenos">258</span></a>        
</span><span id="MLPClassifier-259"><a href="#MLPClassifier-259"><span class="linenos">259</span></a>        <span class="c1"># Pass through all layers except the last one</span>
</span><span id="MLPClassifier-260"><a href="#MLPClassifier-260"><span class="linenos">260</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="MLPClassifier-261"><a href="#MLPClassifier-261"><span class="linenos">261</span></a>            <span class="n">layer_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPClassifier-262"><a href="#MLPClassifier-262"><span class="linenos">262</span></a>            <span class="n">layer_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer_input</span><span class="p">)</span>
</span><span id="MLPClassifier-263"><a href="#MLPClassifier-263"><span class="linenos">263</span></a>            <span class="n">activation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_func</span><span class="p">(</span><span class="n">layer_input</span><span class="p">)</span>
</span><span id="MLPClassifier-264"><a href="#MLPClassifier-264"><span class="linenos">264</span></a>            <span class="n">activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
</span><span id="MLPClassifier-265"><a href="#MLPClassifier-265"><span class="linenos">265</span></a>        
</span><span id="MLPClassifier-266"><a href="#MLPClassifier-266"><span class="linenos">266</span></a>        <span class="c1"># Output layer with softmax for classification</span>
</span><span id="MLPClassifier-267"><a href="#MLPClassifier-267"><span class="linenos">267</span></a>        <span class="n">last_layer_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="MLPClassifier-268"><a href="#MLPClassifier-268"><span class="linenos">268</span></a>        <span class="n">layer_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">last_layer_input</span><span class="p">)</span>
</span><span id="MLPClassifier-269"><a href="#MLPClassifier-269"><span class="linenos">269</span></a>        
</span><span id="MLPClassifier-270"><a href="#MLPClassifier-270"><span class="linenos">270</span></a>        <span class="c1"># Use softmax for output layer</span>
</span><span id="MLPClassifier-271"><a href="#MLPClassifier-271"><span class="linenos">271</span></a>        <span class="n">output_activation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">last_layer_input</span><span class="p">)</span>
</span><span id="MLPClassifier-272"><a href="#MLPClassifier-272"><span class="linenos">272</span></a>        <span class="n">activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_activation</span><span class="p">)</span>
</span><span id="MLPClassifier-273"><a href="#MLPClassifier-273"><span class="linenos">273</span></a>        
</span><span id="MLPClassifier-274"><a href="#MLPClassifier-274"><span class="linenos">274</span></a>        <span class="k">return</span> <span class="n">activations</span><span class="p">,</span> <span class="n">layer_inputs</span>
</span><span id="MLPClassifier-275"><a href="#MLPClassifier-275"><span class="linenos">275</span></a>    
</span><span id="MLPClassifier-276"><a href="#MLPClassifier-276"><span class="linenos">276</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_true</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span><span id="MLPClassifier-277"><a href="#MLPClassifier-277"><span class="linenos">277</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-278"><a href="#MLPClassifier-278"><span class="linenos">278</span></a><span class="sd">        Calculate cross-entropy loss with L2 regularization</span>
</span><span id="MLPClassifier-279"><a href="#MLPClassifier-279"><span class="linenos">279</span></a><span class="sd">        </span>
</span><span id="MLPClassifier-280"><a href="#MLPClassifier-280"><span class="linenos">280</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPClassifier-281"><a href="#MLPClassifier-281"><span class="linenos">281</span></a><span class="sd">        -----------</span>
</span><span id="MLPClassifier-282"><a href="#MLPClassifier-282"><span class="linenos">282</span></a><span class="sd">        y_true : np.ndarray, shape (n_samples, n_classes)</span>
</span><span id="MLPClassifier-283"><a href="#MLPClassifier-283"><span class="linenos">283</span></a><span class="sd">            One-hot encoded labels</span>
</span><span id="MLPClassifier-284"><a href="#MLPClassifier-284"><span class="linenos">284</span></a><span class="sd">        y_pred : np.ndarray, shape (n_samples, n_classes)</span>
</span><span id="MLPClassifier-285"><a href="#MLPClassifier-285"><span class="linenos">285</span></a><span class="sd">            Model predictions</span>
</span><span id="MLPClassifier-286"><a href="#MLPClassifier-286"><span class="linenos">286</span></a><span class="sd">            </span>
</span><span id="MLPClassifier-287"><a href="#MLPClassifier-287"><span class="linenos">287</span></a><span class="sd">        Returns:</span>
</span><span id="MLPClassifier-288"><a href="#MLPClassifier-288"><span class="linenos">288</span></a><span class="sd">        --------</span>
</span><span id="MLPClassifier-289"><a href="#MLPClassifier-289"><span class="linenos">289</span></a><span class="sd">        loss : float</span>
</span><span id="MLPClassifier-290"><a href="#MLPClassifier-290"><span class="linenos">290</span></a><span class="sd">            Loss value</span>
</span><span id="MLPClassifier-291"><a href="#MLPClassifier-291"><span class="linenos">291</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-292"><a href="#MLPClassifier-292"><span class="linenos">292</span></a>        <span class="n">m</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="MLPClassifier-293"><a href="#MLPClassifier-293"><span class="linenos">293</span></a>        <span class="c1"># Cross-entropy</span>
</span><span id="MLPClassifier-294"><a href="#MLPClassifier-294"><span class="linenos">294</span></a>        <span class="n">log_likelihood</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_true</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)))</span> <span class="o">/</span> <span class="n">m</span>
</span><span id="MLPClassifier-295"><a href="#MLPClassifier-295"><span class="linenos">295</span></a>        
</span><span id="MLPClassifier-296"><a href="#MLPClassifier-296"><span class="linenos">296</span></a>        <span class="c1"># L2 regularization</span>
</span><span id="MLPClassifier-297"><a href="#MLPClassifier-297"><span class="linenos">297</span></a>        <span class="n">l2_reg</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="MLPClassifier-298"><a href="#MLPClassifier-298"><span class="linenos">298</span></a>        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">:</span>
</span><span id="MLPClassifier-299"><a href="#MLPClassifier-299"><span class="linenos">299</span></a>            <span class="n">l2_reg</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>
</span><span id="MLPClassifier-300"><a href="#MLPClassifier-300"><span class="linenos">300</span></a>        <span class="n">l2_reg</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">)</span>
</span><span id="MLPClassifier-301"><a href="#MLPClassifier-301"><span class="linenos">301</span></a>        
</span><span id="MLPClassifier-302"><a href="#MLPClassifier-302"><span class="linenos">302</span></a>        <span class="k">return</span> <span class="n">log_likelihood</span> <span class="o">+</span> <span class="n">l2_reg</span>
</span><span id="MLPClassifier-303"><a href="#MLPClassifier-303"><span class="linenos">303</span></a>    
</span><span id="MLPClassifier-304"><a href="#MLPClassifier-304"><span class="linenos">304</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_backward_pass</span><span class="p">(</span>
</span><span id="MLPClassifier-305"><a href="#MLPClassifier-305"><span class="linenos">305</span></a>        <span class="bp">self</span><span class="p">,</span> 
</span><span id="MLPClassifier-306"><a href="#MLPClassifier-306"><span class="linenos">306</span></a>        <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
</span><span id="MLPClassifier-307"><a href="#MLPClassifier-307"><span class="linenos">307</span></a>        <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
</span><span id="MLPClassifier-308"><a href="#MLPClassifier-308"><span class="linenos">308</span></a>        <span class="n">activations</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> 
</span><span id="MLPClassifier-309"><a href="#MLPClassifier-309"><span class="linenos">309</span></a>        <span class="n">layer_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span>
</span><span id="MLPClassifier-310"><a href="#MLPClassifier-310"><span class="linenos">310</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
</span><span id="MLPClassifier-311"><a href="#MLPClassifier-311"><span class="linenos">311</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-312"><a href="#MLPClassifier-312"><span class="linenos">312</span></a><span class="sd">        Backpropagation of gradient</span>
</span><span id="MLPClassifier-313"><a href="#MLPClassifier-313"><span class="linenos">313</span></a><span class="sd">        </span>
</span><span id="MLPClassifier-314"><a href="#MLPClassifier-314"><span class="linenos">314</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPClassifier-315"><a href="#MLPClassifier-315"><span class="linenos">315</span></a><span class="sd">        -----------</span>
</span><span id="MLPClassifier-316"><a href="#MLPClassifier-316"><span class="linenos">316</span></a><span class="sd">        X : np.ndarray</span>
</span><span id="MLPClassifier-317"><a href="#MLPClassifier-317"><span class="linenos">317</span></a><span class="sd">            Input data</span>
</span><span id="MLPClassifier-318"><a href="#MLPClassifier-318"><span class="linenos">318</span></a><span class="sd">        y : np.ndarray</span>
</span><span id="MLPClassifier-319"><a href="#MLPClassifier-319"><span class="linenos">319</span></a><span class="sd">            One-hot encoded labels</span>
</span><span id="MLPClassifier-320"><a href="#MLPClassifier-320"><span class="linenos">320</span></a><span class="sd">        activations : List of activations for each layer</span>
</span><span id="MLPClassifier-321"><a href="#MLPClassifier-321"><span class="linenos">321</span></a><span class="sd">        layer_inputs : List of inputs for each layer</span>
</span><span id="MLPClassifier-322"><a href="#MLPClassifier-322"><span class="linenos">322</span></a><span class="sd">            </span>
</span><span id="MLPClassifier-323"><a href="#MLPClassifier-323"><span class="linenos">323</span></a><span class="sd">        Returns:</span>
</span><span id="MLPClassifier-324"><a href="#MLPClassifier-324"><span class="linenos">324</span></a><span class="sd">        --------</span>
</span><span id="MLPClassifier-325"><a href="#MLPClassifier-325"><span class="linenos">325</span></a><span class="sd">        gradients_w : List of gradients for weights</span>
</span><span id="MLPClassifier-326"><a href="#MLPClassifier-326"><span class="linenos">326</span></a><span class="sd">        gradients_b : List of gradients for biases</span>
</span><span id="MLPClassifier-327"><a href="#MLPClassifier-327"><span class="linenos">327</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-328"><a href="#MLPClassifier-328"><span class="linenos">328</span></a>        <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="MLPClassifier-329"><a href="#MLPClassifier-329"><span class="linenos">329</span></a>        <span class="n">gradients_w</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span>
</span><span id="MLPClassifier-330"><a href="#MLPClassifier-330"><span class="linenos">330</span></a>        <span class="n">gradients_b</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span>
</span><span id="MLPClassifier-331"><a href="#MLPClassifier-331"><span class="linenos">331</span></a>        
</span><span id="MLPClassifier-332"><a href="#MLPClassifier-332"><span class="linenos">332</span></a>        <span class="c1"># Gradient of output layer (derivative of cross-entropy with softmax)</span>
</span><span id="MLPClassifier-333"><a href="#MLPClassifier-333"><span class="linenos">333</span></a>        <span class="n">delta</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">y</span>
</span><span id="MLPClassifier-334"><a href="#MLPClassifier-334"><span class="linenos">334</span></a>        
</span><span id="MLPClassifier-335"><a href="#MLPClassifier-335"><span class="linenos">335</span></a>        <span class="c1"># Backpropagate gradient through layers</span>
</span><span id="MLPClassifier-336"><a href="#MLPClassifier-336"><span class="linenos">336</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
</span><span id="MLPClassifier-337"><a href="#MLPClassifier-337"><span class="linenos">337</span></a>            <span class="c1"># Calculate gradient for weights and biases of layer i</span>
</span><span id="MLPClassifier-338"><a href="#MLPClassifier-338"><span class="linenos">338</span></a>            <span class="n">gradients_w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">delta</span><span class="p">)</span> <span class="o">/</span> <span class="n">m</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPClassifier-339"><a href="#MLPClassifier-339"><span class="linenos">339</span></a>            <span class="n">gradients_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="MLPClassifier-340"><a href="#MLPClassifier-340"><span class="linenos">340</span></a>            
</span><span id="MLPClassifier-341"><a href="#MLPClassifier-341"><span class="linenos">341</span></a>            <span class="c1"># Backpropagate delta (except for first layer)</span>
</span><span id="MLPClassifier-342"><a href="#MLPClassifier-342"><span class="linenos">342</span></a>            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="MLPClassifier-343"><a href="#MLPClassifier-343"><span class="linenos">343</span></a>                <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span><span id="MLPClassifier-344"><a href="#MLPClassifier-344"><span class="linenos">344</span></a>                <span class="c1"># For other layers, apply derivative of activation function</span>
</span><span id="MLPClassifier-345"><a href="#MLPClassifier-345"><span class="linenos">345</span></a>                <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Not for last layer which uses softmax</span>
</span><span id="MLPClassifier-346"><a href="#MLPClassifier-346"><span class="linenos">346</span></a>                    <span class="n">delta</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_derivative</span><span class="p">(</span><span class="n">layer_inputs</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="MLPClassifier-347"><a href="#MLPClassifier-347"><span class="linenos">347</span></a>        
</span><span id="MLPClassifier-348"><a href="#MLPClassifier-348"><span class="linenos">348</span></a>        <span class="k">return</span> <span class="n">gradients_w</span><span class="p">,</span> <span class="n">gradients_b</span>
</span><span id="MLPClassifier-349"><a href="#MLPClassifier-349"><span class="linenos">349</span></a>    
</span><span id="MLPClassifier-350"><a href="#MLPClassifier-350"><span class="linenos">350</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_update_weights_sgd</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients_w</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">gradients_b</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="MLPClassifier-351"><a href="#MLPClassifier-351"><span class="linenos">351</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-352"><a href="#MLPClassifier-352"><span class="linenos">352</span></a><span class="sd">        Update weights with stochastic gradient descent</span>
</span><span id="MLPClassifier-353"><a href="#MLPClassifier-353"><span class="linenos">353</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-354"><a href="#MLPClassifier-354"><span class="linenos">354</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="MLPClassifier-355"><a href="#MLPClassifier-355"><span class="linenos">355</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients_w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPClassifier-356"><a href="#MLPClassifier-356"><span class="linenos">356</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPClassifier-357"><a href="#MLPClassifier-357"><span class="linenos">357</span></a>    
</span><span id="MLPClassifier-358"><a href="#MLPClassifier-358"><span class="linenos">358</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_update_weights_momentum</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients_w</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">gradients_b</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="MLPClassifier-359"><a href="#MLPClassifier-359"><span class="linenos">359</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-360"><a href="#MLPClassifier-360"><span class="linenos">360</span></a><span class="sd">        Update weights with gradient descent with momentum</span>
</span><span id="MLPClassifier-361"><a href="#MLPClassifier-361"><span class="linenos">361</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-362"><a href="#MLPClassifier-362"><span class="linenos">362</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="MLPClassifier-363"><a href="#MLPClassifier-363"><span class="linenos">363</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">velocity_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">velocity_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients_w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPClassifier-364"><a href="#MLPClassifier-364"><span class="linenos">364</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">velocity_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">velocity_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPClassifier-365"><a href="#MLPClassifier-365"><span class="linenos">365</span></a>            
</span><span id="MLPClassifier-366"><a href="#MLPClassifier-366"><span class="linenos">366</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">velocity_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPClassifier-367"><a href="#MLPClassifier-367"><span class="linenos">367</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">velocity_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPClassifier-368"><a href="#MLPClassifier-368"><span class="linenos">368</span></a>    
</span><span id="MLPClassifier-369"><a href="#MLPClassifier-369"><span class="linenos">369</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_update_weights_rmsprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients_w</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">gradients_b</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="MLPClassifier-370"><a href="#MLPClassifier-370"><span class="linenos">370</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-371"><a href="#MLPClassifier-371"><span class="linenos">371</span></a><span class="sd">        Update weights with RMSProp</span>
</span><span id="MLPClassifier-372"><a href="#MLPClassifier-372"><span class="linenos">372</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-373"><a href="#MLPClassifier-373"><span class="linenos">373</span></a>        <span class="n">decay_rate</span> <span class="o">=</span> <span class="mf">0.9</span>
</span><span id="MLPClassifier-374"><a href="#MLPClassifier-374"><span class="linenos">374</span></a>        
</span><span id="MLPClassifier-375"><a href="#MLPClassifier-375"><span class="linenos">375</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="MLPClassifier-376"><a href="#MLPClassifier-376"><span class="linenos">376</span></a>            <span class="c1"># Update accumulators</span>
</span><span id="MLPClassifier-377"><a href="#MLPClassifier-377"><span class="linenos">377</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">decay_rate</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">decay_rate</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">gradients_w</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="MLPClassifier-378"><a href="#MLPClassifier-378"><span class="linenos">378</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">decay_rate</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">decay_rate</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">gradients_b</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="MLPClassifier-379"><a href="#MLPClassifier-379"><span class="linenos">379</span></a>            
</span><span id="MLPClassifier-380"><a href="#MLPClassifier-380"><span class="linenos">380</span></a>            <span class="c1"># Update weights</span>
</span><span id="MLPClassifier-381"><a href="#MLPClassifier-381"><span class="linenos">381</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients_w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">))</span>
</span><span id="MLPClassifier-382"><a href="#MLPClassifier-382"><span class="linenos">382</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">))</span>
</span><span id="MLPClassifier-383"><a href="#MLPClassifier-383"><span class="linenos">383</span></a>    
</span><span id="MLPClassifier-384"><a href="#MLPClassifier-384"><span class="linenos">384</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_update_weights_adam</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients_w</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">gradients_b</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="MLPClassifier-385"><a href="#MLPClassifier-385"><span class="linenos">385</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-386"><a href="#MLPClassifier-386"><span class="linenos">386</span></a><span class="sd">        Update weights with Adam optimizer</span>
</span><span id="MLPClassifier-387"><a href="#MLPClassifier-387"><span class="linenos">387</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-388"><a href="#MLPClassifier-388"><span class="linenos">388</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="MLPClassifier-389"><a href="#MLPClassifier-389"><span class="linenos">389</span></a>            <span class="c1"># Update moments</span>
</span><span id="MLPClassifier-390"><a href="#MLPClassifier-390"><span class="linenos">390</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">m_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="p">)</span> <span class="o">*</span> <span class="n">gradients_w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPClassifier-391"><a href="#MLPClassifier-391"><span class="linenos">391</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">m_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="p">)</span> <span class="o">*</span> <span class="n">gradients_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPClassifier-392"><a href="#MLPClassifier-392"><span class="linenos">392</span></a>            
</span><span id="MLPClassifier-393"><a href="#MLPClassifier-393"><span class="linenos">393</span></a>            <span class="c1"># Update second-order moments</span>
</span><span id="MLPClassifier-394"><a href="#MLPClassifier-394"><span class="linenos">394</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">gradients_w</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="MLPClassifier-395"><a href="#MLPClassifier-395"><span class="linenos">395</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">gradients_b</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="MLPClassifier-396"><a href="#MLPClassifier-396"><span class="linenos">396</span></a>            
</span><span id="MLPClassifier-397"><a href="#MLPClassifier-397"><span class="linenos">397</span></a>            <span class="c1"># Bias correction</span>
</span><span id="MLPClassifier-398"><a href="#MLPClassifier-398"><span class="linenos">398</span></a>            <span class="n">m_weights_corrected</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">)</span>
</span><span id="MLPClassifier-399"><a href="#MLPClassifier-399"><span class="linenos">399</span></a>            <span class="n">m_biases_corrected</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">)</span>
</span><span id="MLPClassifier-400"><a href="#MLPClassifier-400"><span class="linenos">400</span></a>            <span class="n">v_weights_corrected</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">)</span>
</span><span id="MLPClassifier-401"><a href="#MLPClassifier-401"><span class="linenos">401</span></a>            <span class="n">v_biases_corrected</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">)</span>
</span><span id="MLPClassifier-402"><a href="#MLPClassifier-402"><span class="linenos">402</span></a>            
</span><span id="MLPClassifier-403"><a href="#MLPClassifier-403"><span class="linenos">403</span></a>            <span class="c1"># Update weights</span>
</span><span id="MLPClassifier-404"><a href="#MLPClassifier-404"><span class="linenos">404</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">m_weights_corrected</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v_weights_corrected</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">))</span>
</span><span id="MLPClassifier-405"><a href="#MLPClassifier-405"><span class="linenos">405</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">m_biases_corrected</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v_biases_corrected</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">))</span>
</span><span id="MLPClassifier-406"><a href="#MLPClassifier-406"><span class="linenos">406</span></a>        
</span><span id="MLPClassifier-407"><a href="#MLPClassifier-407"><span class="linenos">407</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="MLPClassifier-408"><a href="#MLPClassifier-408"><span class="linenos">408</span></a>    
</span><span id="MLPClassifier-409"><a href="#MLPClassifier-409"><span class="linenos">409</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_split_train_validation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
</span><span id="MLPClassifier-410"><a href="#MLPClassifier-410"><span class="linenos">410</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-411"><a href="#MLPClassifier-411"><span class="linenos">411</span></a><span class="sd">        Split data into training and validation sets</span>
</span><span id="MLPClassifier-412"><a href="#MLPClassifier-412"><span class="linenos">412</span></a><span class="sd">        </span>
</span><span id="MLPClassifier-413"><a href="#MLPClassifier-413"><span class="linenos">413</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPClassifier-414"><a href="#MLPClassifier-414"><span class="linenos">414</span></a><span class="sd">        -----------</span>
</span><span id="MLPClassifier-415"><a href="#MLPClassifier-415"><span class="linenos">415</span></a><span class="sd">        X : np.ndarray</span>
</span><span id="MLPClassifier-416"><a href="#MLPClassifier-416"><span class="linenos">416</span></a><span class="sd">            Input data</span>
</span><span id="MLPClassifier-417"><a href="#MLPClassifier-417"><span class="linenos">417</span></a><span class="sd">        y : np.ndarray</span>
</span><span id="MLPClassifier-418"><a href="#MLPClassifier-418"><span class="linenos">418</span></a><span class="sd">            Labels</span>
</span><span id="MLPClassifier-419"><a href="#MLPClassifier-419"><span class="linenos">419</span></a><span class="sd">            </span>
</span><span id="MLPClassifier-420"><a href="#MLPClassifier-420"><span class="linenos">420</span></a><span class="sd">        Returns:</span>
</span><span id="MLPClassifier-421"><a href="#MLPClassifier-421"><span class="linenos">421</span></a><span class="sd">        --------</span>
</span><span id="MLPClassifier-422"><a href="#MLPClassifier-422"><span class="linenos">422</span></a><span class="sd">        X_train, X_val, y_train, y_val : The split datasets</span>
</span><span id="MLPClassifier-423"><a href="#MLPClassifier-423"><span class="linenos">423</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-424"><a href="#MLPClassifier-424"><span class="linenos">424</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="MLPClassifier-425"><a href="#MLPClassifier-425"><span class="linenos">425</span></a>        <span class="n">n_val</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_fraction</span><span class="p">)</span>
</span><span id="MLPClassifier-426"><a href="#MLPClassifier-426"><span class="linenos">426</span></a>        
</span><span id="MLPClassifier-427"><a href="#MLPClassifier-427"><span class="linenos">427</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
</span><span id="MLPClassifier-428"><a href="#MLPClassifier-428"><span class="linenos">428</span></a>            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
</span><span id="MLPClassifier-429"><a href="#MLPClassifier-429"><span class="linenos">429</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="MLPClassifier-430"><a href="#MLPClassifier-430"><span class="linenos">430</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="MLPClassifier-431"><a href="#MLPClassifier-431"><span class="linenos">431</span></a>        
</span><span id="MLPClassifier-432"><a href="#MLPClassifier-432"><span class="linenos">432</span></a>        <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">n_val</span><span class="p">],</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_val</span><span class="p">]</span>
</span><span id="MLPClassifier-433"><a href="#MLPClassifier-433"><span class="linenos">433</span></a>        <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">n_val</span><span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">n_val</span><span class="p">:]</span>
</span><span id="MLPClassifier-434"><a href="#MLPClassifier-434"><span class="linenos">434</span></a>        
</span><span id="MLPClassifier-435"><a href="#MLPClassifier-435"><span class="linenos">435</span></a>        <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span>
</span><span id="MLPClassifier-436"><a href="#MLPClassifier-436"><span class="linenos">436</span></a>    
</span><span id="MLPClassifier-437"><a href="#MLPClassifier-437"><span class="linenos">437</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_encode_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPClassifier-438"><a href="#MLPClassifier-438"><span class="linenos">438</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-439"><a href="#MLPClassifier-439"><span class="linenos">439</span></a><span class="sd">        Encode labels to one-hot representation</span>
</span><span id="MLPClassifier-440"><a href="#MLPClassifier-440"><span class="linenos">440</span></a><span class="sd">        </span>
</span><span id="MLPClassifier-441"><a href="#MLPClassifier-441"><span class="linenos">441</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPClassifier-442"><a href="#MLPClassifier-442"><span class="linenos">442</span></a><span class="sd">        -----------</span>
</span><span id="MLPClassifier-443"><a href="#MLPClassifier-443"><span class="linenos">443</span></a><span class="sd">        y : np.ndarray</span>
</span><span id="MLPClassifier-444"><a href="#MLPClassifier-444"><span class="linenos">444</span></a><span class="sd">            Input labels</span>
</span><span id="MLPClassifier-445"><a href="#MLPClassifier-445"><span class="linenos">445</span></a><span class="sd">            </span>
</span><span id="MLPClassifier-446"><a href="#MLPClassifier-446"><span class="linenos">446</span></a><span class="sd">        Returns:</span>
</span><span id="MLPClassifier-447"><a href="#MLPClassifier-447"><span class="linenos">447</span></a><span class="sd">        --------</span>
</span><span id="MLPClassifier-448"><a href="#MLPClassifier-448"><span class="linenos">448</span></a><span class="sd">        one_hot : np.ndarray</span>
</span><span id="MLPClassifier-449"><a href="#MLPClassifier-449"><span class="linenos">449</span></a><span class="sd">            One-hot encoded labels</span>
</span><span id="MLPClassifier-450"><a href="#MLPClassifier-450"><span class="linenos">450</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-451"><a href="#MLPClassifier-451"><span class="linenos">451</span></a>        <span class="c1"># Determine unique classes and create a mapping</span>
</span><span id="MLPClassifier-452"><a href="#MLPClassifier-452"><span class="linenos">452</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="MLPClassifier-453"><a href="#MLPClassifier-453"><span class="linenos">453</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="MLPClassifier-454"><a href="#MLPClassifier-454"><span class="linenos">454</span></a>        <span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
</span><span id="MLPClassifier-455"><a href="#MLPClassifier-455"><span class="linenos">455</span></a>        
</span><span id="MLPClassifier-456"><a href="#MLPClassifier-456"><span class="linenos">456</span></a>        <span class="c1"># Create an empty one-hot encoded matrix</span>
</span><span id="MLPClassifier-457"><a href="#MLPClassifier-457"><span class="linenos">457</span></a>        <span class="n">one_hot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span>
</span><span id="MLPClassifier-458"><a href="#MLPClassifier-458"><span class="linenos">458</span></a>        
</span><span id="MLPClassifier-459"><a href="#MLPClassifier-459"><span class="linenos">459</span></a>        <span class="c1"># Map original labels to one-hot encoded labels</span>
</span><span id="MLPClassifier-460"><a href="#MLPClassifier-460"><span class="linenos">460</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
</span><span id="MLPClassifier-461"><a href="#MLPClassifier-461"><span class="linenos">461</span></a>            <span class="n">one_hot</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes_</span> <span class="o">==</span> <span class="n">label</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="MLPClassifier-462"><a href="#MLPClassifier-462"><span class="linenos">462</span></a>        
</span><span id="MLPClassifier-463"><a href="#MLPClassifier-463"><span class="linenos">463</span></a>        <span class="k">return</span> <span class="n">one_hot</span>
</span><span id="MLPClassifier-464"><a href="#MLPClassifier-464"><span class="linenos">464</span></a>    
</span><span id="MLPClassifier-465"><a href="#MLPClassifier-465"><span class="linenos">465</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;MLPClassifier&#39;</span><span class="p">:</span>
</span><span id="MLPClassifier-466"><a href="#MLPClassifier-466"><span class="linenos">466</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-467"><a href="#MLPClassifier-467"><span class="linenos">467</span></a><span class="sd">        Train the MLP on the provided data</span>
</span><span id="MLPClassifier-468"><a href="#MLPClassifier-468"><span class="linenos">468</span></a><span class="sd">        </span>
</span><span id="MLPClassifier-469"><a href="#MLPClassifier-469"><span class="linenos">469</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPClassifier-470"><a href="#MLPClassifier-470"><span class="linenos">470</span></a><span class="sd">        -----------</span>
</span><span id="MLPClassifier-471"><a href="#MLPClassifier-471"><span class="linenos">471</span></a><span class="sd">        X : np.ndarray of shape (n_samples, n_features)</span>
</span><span id="MLPClassifier-472"><a href="#MLPClassifier-472"><span class="linenos">472</span></a><span class="sd">            Training data</span>
</span><span id="MLPClassifier-473"><a href="#MLPClassifier-473"><span class="linenos">473</span></a><span class="sd">        y : np.ndarray of shape (n_samples,)</span>
</span><span id="MLPClassifier-474"><a href="#MLPClassifier-474"><span class="linenos">474</span></a><span class="sd">            Target labels</span>
</span><span id="MLPClassifier-475"><a href="#MLPClassifier-475"><span class="linenos">475</span></a><span class="sd">            </span>
</span><span id="MLPClassifier-476"><a href="#MLPClassifier-476"><span class="linenos">476</span></a><span class="sd">        Returns:</span>
</span><span id="MLPClassifier-477"><a href="#MLPClassifier-477"><span class="linenos">477</span></a><span class="sd">        --------</span>
</span><span id="MLPClassifier-478"><a href="#MLPClassifier-478"><span class="linenos">478</span></a><span class="sd">        self : object</span>
</span><span id="MLPClassifier-479"><a href="#MLPClassifier-479"><span class="linenos">479</span></a><span class="sd">            The trained MLP</span>
</span><span id="MLPClassifier-480"><a href="#MLPClassifier-480"><span class="linenos">480</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-481"><a href="#MLPClassifier-481"><span class="linenos">481</span></a>        <span class="c1"># Convert arrays</span>
</span><span id="MLPClassifier-482"><a href="#MLPClassifier-482"><span class="linenos">482</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="MLPClassifier-483"><a href="#MLPClassifier-483"><span class="linenos">483</span></a>        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="MLPClassifier-484"><a href="#MLPClassifier-484"><span class="linenos">484</span></a>        
</span><span id="MLPClassifier-485"><a href="#MLPClassifier-485"><span class="linenos">485</span></a>        <span class="c1"># Determine number of classes</span>
</span><span id="MLPClassifier-486"><a href="#MLPClassifier-486"><span class="linenos">486</span></a>        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</span><span id="MLPClassifier-487"><a href="#MLPClassifier-487"><span class="linenos">487</span></a>        
</span><span id="MLPClassifier-488"><a href="#MLPClassifier-488"><span class="linenos">488</span></a>        <span class="c1"># Encode labels and determine number of classes</span>
</span><span id="MLPClassifier-489"><a href="#MLPClassifier-489"><span class="linenos">489</span></a>        <span class="n">y_one_hot</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_labels</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="MLPClassifier-490"><a href="#MLPClassifier-490"><span class="linenos">490</span></a>        <span class="n">n_outputs</span> <span class="o">=</span> <span class="n">y_one_hot</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="MLPClassifier-491"><a href="#MLPClassifier-491"><span class="linenos">491</span></a>        
</span><span id="MLPClassifier-492"><a href="#MLPClassifier-492"><span class="linenos">492</span></a>        <span class="c1"># Initialize weights</span>
</span><span id="MLPClassifier-493"><a href="#MLPClassifier-493"><span class="linenos">493</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_weights</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">)</span>
</span><span id="MLPClassifier-494"><a href="#MLPClassifier-494"><span class="linenos">494</span></a>        
</span><span id="MLPClassifier-495"><a href="#MLPClassifier-495"><span class="linenos">495</span></a>        <span class="c1"># Split into training and validation sets if early_stopping</span>
</span><span id="MLPClassifier-496"><a href="#MLPClassifier-496"><span class="linenos">496</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping</span><span class="p">:</span>
</span><span id="MLPClassifier-497"><a href="#MLPClassifier-497"><span class="linenos">497</span></a>            <span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_train_validation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="MLPClassifier-498"><a href="#MLPClassifier-498"><span class="linenos">498</span></a>            <span class="n">y_train_one_hot</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_labels</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
</span><span id="MLPClassifier-499"><a href="#MLPClassifier-499"><span class="linenos">499</span></a>            <span class="n">y_val_one_hot</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_labels</span><span class="p">(</span><span class="n">y_val</span><span class="p">)</span>
</span><span id="MLPClassifier-500"><a href="#MLPClassifier-500"><span class="linenos">500</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="MLPClassifier-501"><a href="#MLPClassifier-501"><span class="linenos">501</span></a>            <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</span><span id="MLPClassifier-502"><a href="#MLPClassifier-502"><span class="linenos">502</span></a>            <span class="n">y_train_one_hot</span> <span class="o">=</span> <span class="n">y_one_hot</span>
</span><span id="MLPClassifier-503"><a href="#MLPClassifier-503"><span class="linenos">503</span></a>        
</span><span id="MLPClassifier-504"><a href="#MLPClassifier-504"><span class="linenos">504</span></a>        <span class="c1"># Update method according to chosen optimizer</span>
</span><span id="MLPClassifier-505"><a href="#MLPClassifier-505"><span class="linenos">505</span></a>        <span class="n">update_methods</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="MLPClassifier-506"><a href="#MLPClassifier-506"><span class="linenos">506</span></a>            <span class="s1">&#39;sgd&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights_sgd</span><span class="p">,</span>
</span><span id="MLPClassifier-507"><a href="#MLPClassifier-507"><span class="linenos">507</span></a>            <span class="s1">&#39;momentum&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights_momentum</span><span class="p">,</span>
</span><span id="MLPClassifier-508"><a href="#MLPClassifier-508"><span class="linenos">508</span></a>            <span class="s1">&#39;rmsprop&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights_rmsprop</span><span class="p">,</span>
</span><span id="MLPClassifier-509"><a href="#MLPClassifier-509"><span class="linenos">509</span></a>            <span class="s1">&#39;adam&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights_adam</span>
</span><span id="MLPClassifier-510"><a href="#MLPClassifier-510"><span class="linenos">510</span></a>        <span class="p">}</span>
</span><span id="MLPClassifier-511"><a href="#MLPClassifier-511"><span class="linenos">511</span></a>        
</span><span id="MLPClassifier-512"><a href="#MLPClassifier-512"><span class="linenos">512</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">update_methods</span><span class="p">:</span>
</span><span id="MLPClassifier-513"><a href="#MLPClassifier-513"><span class="linenos">513</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimizer &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s2">&#39; not recognized.&quot;</span><span class="p">)</span>
</span><span id="MLPClassifier-514"><a href="#MLPClassifier-514"><span class="linenos">514</span></a>        
</span><span id="MLPClassifier-515"><a href="#MLPClassifier-515"><span class="linenos">515</span></a>        <span class="n">update_weights</span> <span class="o">=</span> <span class="n">update_methods</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">]</span>
</span><span id="MLPClassifier-516"><a href="#MLPClassifier-516"><span class="linenos">516</span></a>        
</span><span id="MLPClassifier-517"><a href="#MLPClassifier-517"><span class="linenos">517</span></a>        <span class="c1"># Training over multiple epochs</span>
</span><span id="MLPClassifier-518"><a href="#MLPClassifier-518"><span class="linenos">518</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-519"><a href="#MLPClassifier-519"><span class="linenos">519</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-520"><a href="#MLPClassifier-520"><span class="linenos">520</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</span><span id="MLPClassifier-521"><a href="#MLPClassifier-521"><span class="linenos">521</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="MLPClassifier-522"><a href="#MLPClassifier-522"><span class="linenos">522</span></a>        
</span><span id="MLPClassifier-523"><a href="#MLPClassifier-523"><span class="linenos">523</span></a>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">):</span>
</span><span id="MLPClassifier-524"><a href="#MLPClassifier-524"><span class="linenos">524</span></a>            <span class="c1"># Shuffle data if requested</span>
</span><span id="MLPClassifier-525"><a href="#MLPClassifier-525"><span class="linenos">525</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
</span><span id="MLPClassifier-526"><a href="#MLPClassifier-526"><span class="linenos">526</span></a>                <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>
</span><span id="MLPClassifier-527"><a href="#MLPClassifier-527"><span class="linenos">527</span></a>                <span class="n">X_train_shuffled</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="MLPClassifier-528"><a href="#MLPClassifier-528"><span class="linenos">528</span></a>                <span class="n">y_train_shuffled</span> <span class="o">=</span> <span class="n">y_train_one_hot</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="MLPClassifier-529"><a href="#MLPClassifier-529"><span class="linenos">529</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="MLPClassifier-530"><a href="#MLPClassifier-530"><span class="linenos">530</span></a>                <span class="n">X_train_shuffled</span> <span class="o">=</span> <span class="n">X_train</span>
</span><span id="MLPClassifier-531"><a href="#MLPClassifier-531"><span class="linenos">531</span></a>                <span class="n">y_train_shuffled</span> <span class="o">=</span> <span class="n">y_train_one_hot</span>
</span><span id="MLPClassifier-532"><a href="#MLPClassifier-532"><span class="linenos">532</span></a>            
</span><span id="MLPClassifier-533"><a href="#MLPClassifier-533"><span class="linenos">533</span></a>            <span class="c1"># Training by mini-batches</span>
</span><span id="MLPClassifier-534"><a href="#MLPClassifier-534"><span class="linenos">534</span></a>            <span class="n">batch_losses</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier-535"><a href="#MLPClassifier-535"><span class="linenos">535</span></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
</span><span id="MLPClassifier-536"><a href="#MLPClassifier-536"><span class="linenos">536</span></a>                <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_train_shuffled</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
</span><span id="MLPClassifier-537"><a href="#MLPClassifier-537"><span class="linenos">537</span></a>                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_train_shuffled</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
</span><span id="MLPClassifier-538"><a href="#MLPClassifier-538"><span class="linenos">538</span></a>                
</span><span id="MLPClassifier-539"><a href="#MLPClassifier-539"><span class="linenos">539</span></a>                <span class="c1"># Forward propagation</span>
</span><span id="MLPClassifier-540"><a href="#MLPClassifier-540"><span class="linenos">540</span></a>                <span class="n">activations</span><span class="p">,</span> <span class="n">layer_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
</span><span id="MLPClassifier-541"><a href="#MLPClassifier-541"><span class="linenos">541</span></a>                
</span><span id="MLPClassifier-542"><a href="#MLPClassifier-542"><span class="linenos">542</span></a>                <span class="c1"># Loss calculation</span>
</span><span id="MLPClassifier-543"><a href="#MLPClassifier-543"><span class="linenos">543</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">y_batch</span><span class="p">,</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="MLPClassifier-544"><a href="#MLPClassifier-544"><span class="linenos">544</span></a>                <span class="n">batch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</span><span id="MLPClassifier-545"><a href="#MLPClassifier-545"><span class="linenos">545</span></a>                
</span><span id="MLPClassifier-546"><a href="#MLPClassifier-546"><span class="linenos">546</span></a>                <span class="c1"># Backpropagation</span>
</span><span id="MLPClassifier-547"><a href="#MLPClassifier-547"><span class="linenos">547</span></a>                <span class="n">gradients_w</span><span class="p">,</span> <span class="n">gradients_b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pass</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">,</span> <span class="n">activations</span><span class="p">,</span> <span class="n">layer_inputs</span><span class="p">)</span>
</span><span id="MLPClassifier-548"><a href="#MLPClassifier-548"><span class="linenos">548</span></a>                
</span><span id="MLPClassifier-549"><a href="#MLPClassifier-549"><span class="linenos">549</span></a>                <span class="c1"># Weight update</span>
</span><span id="MLPClassifier-550"><a href="#MLPClassifier-550"><span class="linenos">550</span></a>                <span class="n">update_weights</span><span class="p">(</span><span class="n">gradients_w</span><span class="p">,</span> <span class="n">gradients_b</span><span class="p">)</span>
</span><span id="MLPClassifier-551"><a href="#MLPClassifier-551"><span class="linenos">551</span></a>            
</span><span id="MLPClassifier-552"><a href="#MLPClassifier-552"><span class="linenos">552</span></a>            <span class="c1"># Average loss over the epoch</span>
</span><span id="MLPClassifier-553"><a href="#MLPClassifier-553"><span class="linenos">553</span></a>            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">batch_losses</span><span class="p">)</span>
</span><span id="MLPClassifier-554"><a href="#MLPClassifier-554"><span class="linenos">554</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)</span>
</span><span id="MLPClassifier-555"><a href="#MLPClassifier-555"><span class="linenos">555</span></a>            
</span><span id="MLPClassifier-556"><a href="#MLPClassifier-556"><span class="linenos">556</span></a>            <span class="c1"># Validation if early_stopping is activated</span>
</span><span id="MLPClassifier-557"><a href="#MLPClassifier-557"><span class="linenos">557</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping</span><span class="p">:</span>
</span><span id="MLPClassifier-558"><a href="#MLPClassifier-558"><span class="linenos">558</span></a>                <span class="c1"># Calculate loss on validation set</span>
</span><span id="MLPClassifier-559"><a href="#MLPClassifier-559"><span class="linenos">559</span></a>                <span class="n">val_activations</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
</span><span id="MLPClassifier-560"><a href="#MLPClassifier-560"><span class="linenos">560</span></a>                <span class="n">val_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">y_val_one_hot</span><span class="p">,</span> <span class="n">val_activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="MLPClassifier-561"><a href="#MLPClassifier-561"><span class="linenos">561</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">val_loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
</span><span id="MLPClassifier-562"><a href="#MLPClassifier-562"><span class="linenos">562</span></a>                
</span><span id="MLPClassifier-563"><a href="#MLPClassifier-563"><span class="linenos">563</span></a>                <span class="c1"># Check for improvement</span>
</span><span id="MLPClassifier-564"><a href="#MLPClassifier-564"><span class="linenos">564</span></a>                <span class="k">if</span> <span class="n">val_loss</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">:</span>
</span><span id="MLPClassifier-565"><a href="#MLPClassifier-565"><span class="linenos">565</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="n">val_loss</span>
</span><span id="MLPClassifier-566"><a href="#MLPClassifier-566"><span class="linenos">566</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="MLPClassifier-567"><a href="#MLPClassifier-567"><span class="linenos">567</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="MLPClassifier-568"><a href="#MLPClassifier-568"><span class="linenos">568</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="MLPClassifier-569"><a href="#MLPClassifier-569"><span class="linenos">569</span></a>                
</span><span id="MLPClassifier-570"><a href="#MLPClassifier-570"><span class="linenos">570</span></a>                <span class="c1"># Early stopping</span>
</span><span id="MLPClassifier-571"><a href="#MLPClassifier-571"><span class="linenos">571</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span><span class="p">:</span>
</span><span id="MLPClassifier-572"><a href="#MLPClassifier-572"><span class="linenos">572</span></a>                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Early stopping at epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="MLPClassifier-573"><a href="#MLPClassifier-573"><span class="linenos">573</span></a>                    <span class="k">break</span>
</span><span id="MLPClassifier-574"><a href="#MLPClassifier-574"><span class="linenos">574</span></a>        
</span><span id="MLPClassifier-575"><a href="#MLPClassifier-575"><span class="linenos">575</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">trained</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="MLPClassifier-576"><a href="#MLPClassifier-576"><span class="linenos">576</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="MLPClassifier-577"><a href="#MLPClassifier-577"><span class="linenos">577</span></a>    
</span><span id="MLPClassifier-578"><a href="#MLPClassifier-578"><span class="linenos">578</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPClassifier-579"><a href="#MLPClassifier-579"><span class="linenos">579</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-580"><a href="#MLPClassifier-580"><span class="linenos">580</span></a><span class="sd">        Predict classes for samples X</span>
</span><span id="MLPClassifier-581"><a href="#MLPClassifier-581"><span class="linenos">581</span></a><span class="sd">        </span>
</span><span id="MLPClassifier-582"><a href="#MLPClassifier-582"><span class="linenos">582</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPClassifier-583"><a href="#MLPClassifier-583"><span class="linenos">583</span></a><span class="sd">        -----------</span>
</span><span id="MLPClassifier-584"><a href="#MLPClassifier-584"><span class="linenos">584</span></a><span class="sd">        X : np.ndarray of shape (n_samples, n_features)</span>
</span><span id="MLPClassifier-585"><a href="#MLPClassifier-585"><span class="linenos">585</span></a><span class="sd">            Data for which to make predictions</span>
</span><span id="MLPClassifier-586"><a href="#MLPClassifier-586"><span class="linenos">586</span></a><span class="sd">            </span>
</span><span id="MLPClassifier-587"><a href="#MLPClassifier-587"><span class="linenos">587</span></a><span class="sd">        Returns:</span>
</span><span id="MLPClassifier-588"><a href="#MLPClassifier-588"><span class="linenos">588</span></a><span class="sd">        --------</span>
</span><span id="MLPClassifier-589"><a href="#MLPClassifier-589"><span class="linenos">589</span></a><span class="sd">        y_pred : np.ndarray of shape (n_samples,)</span>
</span><span id="MLPClassifier-590"><a href="#MLPClassifier-590"><span class="linenos">590</span></a><span class="sd">            Predicted classes</span>
</span><span id="MLPClassifier-591"><a href="#MLPClassifier-591"><span class="linenos">591</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-592"><a href="#MLPClassifier-592"><span class="linenos">592</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trained</span><span class="p">:</span>
</span><span id="MLPClassifier-593"><a href="#MLPClassifier-593"><span class="linenos">593</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The model must be trained before making predictions.&quot;</span><span class="p">)</span>
</span><span id="MLPClassifier-594"><a href="#MLPClassifier-594"><span class="linenos">594</span></a>        
</span><span id="MLPClassifier-595"><a href="#MLPClassifier-595"><span class="linenos">595</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="MLPClassifier-596"><a href="#MLPClassifier-596"><span class="linenos">596</span></a>        <span class="n">activations</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="MLPClassifier-597"><a href="#MLPClassifier-597"><span class="linenos">597</span></a>        <span class="n">y_pred_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="MLPClassifier-598"><a href="#MLPClassifier-598"><span class="linenos">598</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="n">y_pred_indices</span><span class="p">]</span>
</span><span id="MLPClassifier-599"><a href="#MLPClassifier-599"><span class="linenos">599</span></a>    
</span><span id="MLPClassifier-600"><a href="#MLPClassifier-600"><span class="linenos">600</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPClassifier-601"><a href="#MLPClassifier-601"><span class="linenos">601</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-602"><a href="#MLPClassifier-602"><span class="linenos">602</span></a><span class="sd">        Predict probabilities for each class</span>
</span><span id="MLPClassifier-603"><a href="#MLPClassifier-603"><span class="linenos">603</span></a><span class="sd">        </span>
</span><span id="MLPClassifier-604"><a href="#MLPClassifier-604"><span class="linenos">604</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPClassifier-605"><a href="#MLPClassifier-605"><span class="linenos">605</span></a><span class="sd">        -----------</span>
</span><span id="MLPClassifier-606"><a href="#MLPClassifier-606"><span class="linenos">606</span></a><span class="sd">        X : np.ndarray of shape (n_samples, n_features)</span>
</span><span id="MLPClassifier-607"><a href="#MLPClassifier-607"><span class="linenos">607</span></a><span class="sd">            Data for which to make predictions</span>
</span><span id="MLPClassifier-608"><a href="#MLPClassifier-608"><span class="linenos">608</span></a><span class="sd">            </span>
</span><span id="MLPClassifier-609"><a href="#MLPClassifier-609"><span class="linenos">609</span></a><span class="sd">        Returns:</span>
</span><span id="MLPClassifier-610"><a href="#MLPClassifier-610"><span class="linenos">610</span></a><span class="sd">        --------</span>
</span><span id="MLPClassifier-611"><a href="#MLPClassifier-611"><span class="linenos">611</span></a><span class="sd">        probas : np.ndarray of shape (n_samples, n_classes)</span>
</span><span id="MLPClassifier-612"><a href="#MLPClassifier-612"><span class="linenos">612</span></a><span class="sd">            Probabilities for each class</span>
</span><span id="MLPClassifier-613"><a href="#MLPClassifier-613"><span class="linenos">613</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-614"><a href="#MLPClassifier-614"><span class="linenos">614</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trained</span><span class="p">:</span>
</span><span id="MLPClassifier-615"><a href="#MLPClassifier-615"><span class="linenos">615</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The model must be trained before making predictions.&quot;</span><span class="p">)</span>
</span><span id="MLPClassifier-616"><a href="#MLPClassifier-616"><span class="linenos">616</span></a>        
</span><span id="MLPClassifier-617"><a href="#MLPClassifier-617"><span class="linenos">617</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="MLPClassifier-618"><a href="#MLPClassifier-618"><span class="linenos">618</span></a>        <span class="n">activations</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="MLPClassifier-619"><a href="#MLPClassifier-619"><span class="linenos">619</span></a>        <span class="k">return</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="MLPClassifier-620"><a href="#MLPClassifier-620"><span class="linenos">620</span></a>    
</span><span id="MLPClassifier-621"><a href="#MLPClassifier-621"><span class="linenos">621</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span><span id="MLPClassifier-622"><a href="#MLPClassifier-622"><span class="linenos">622</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier-623"><a href="#MLPClassifier-623"><span class="linenos">623</span></a><span class="sd">        Return the accuracy of the model on the provided data</span>
</span><span id="MLPClassifier-624"><a href="#MLPClassifier-624"><span class="linenos">624</span></a><span class="sd">        </span>
</span><span id="MLPClassifier-625"><a href="#MLPClassifier-625"><span class="linenos">625</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPClassifier-626"><a href="#MLPClassifier-626"><span class="linenos">626</span></a><span class="sd">        -----------</span>
</span><span id="MLPClassifier-627"><a href="#MLPClassifier-627"><span class="linenos">627</span></a><span class="sd">        X : np.ndarray of shape (n_samples, n_features)</span>
</span><span id="MLPClassifier-628"><a href="#MLPClassifier-628"><span class="linenos">628</span></a><span class="sd">            Test data</span>
</span><span id="MLPClassifier-629"><a href="#MLPClassifier-629"><span class="linenos">629</span></a><span class="sd">        y : np.ndarray of shape (n_samples,)</span>
</span><span id="MLPClassifier-630"><a href="#MLPClassifier-630"><span class="linenos">630</span></a><span class="sd">            True labels</span>
</span><span id="MLPClassifier-631"><a href="#MLPClassifier-631"><span class="linenos">631</span></a><span class="sd">            </span>
</span><span id="MLPClassifier-632"><a href="#MLPClassifier-632"><span class="linenos">632</span></a><span class="sd">        Returns:</span>
</span><span id="MLPClassifier-633"><a href="#MLPClassifier-633"><span class="linenos">633</span></a><span class="sd">        --------</span>
</span><span id="MLPClassifier-634"><a href="#MLPClassifier-634"><span class="linenos">634</span></a><span class="sd">        accuracy : float</span>
</span><span id="MLPClassifier-635"><a href="#MLPClassifier-635"><span class="linenos">635</span></a><span class="sd">            Model accuracy</span>
</span><span id="MLPClassifier-636"><a href="#MLPClassifier-636"><span class="linenos">636</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier-637"><a href="#MLPClassifier-637"><span class="linenos">637</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trained</span><span class="p">:</span>
</span><span id="MLPClassifier-638"><a href="#MLPClassifier-638"><span class="linenos">638</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The model must be trained before calculating its score.&quot;</span><span class="p">)</span>
</span><span id="MLPClassifier-639"><a href="#MLPClassifier-639"><span class="linenos">639</span></a>            
</span><span id="MLPClassifier-640"><a href="#MLPClassifier-640"><span class="linenos">640</span></a>        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="MLPClassifier-641"><a href="#MLPClassifier-641"><span class="linenos">641</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Multi-Layer Perceptron with different activation functions and optimizers</p>
</div>


                            <div id="MLPClassifier.__init__" class="classattr">
                                        <input id="MLPClassifier.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">MLPClassifier</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">hidden_layer_sizes</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">100</span><span class="p">,)</span>,</span><span class="param">	<span class="n">activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span>,</span><span class="param">	<span class="n">solver</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;sgd&#39;</span>,</span><span class="param">	<span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0001</span>,</span><span class="param">	<span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span>,</span><span class="param">	<span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span>,</span><span class="param">	<span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">200</span>,</span><span class="param">	<span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>,</span><span class="param">	<span class="n">random_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">beta1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span>,</span><span class="param">	<span class="n">beta2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.999</span>,</span><span class="param">	<span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-08</span>,</span><span class="param">	<span class="n">momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span>,</span><span class="param">	<span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0001</span>,</span><span class="param">	<span class="n">early_stopping</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">validation_fraction</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span>,</span><span class="param">	<span class="n">n_iter_no_change</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span></span>)</span>

                <label class="view-source-button" for="MLPClassifier.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MLPClassifier.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MLPClassifier.__init__-11"><a href="#MLPClassifier.__init__-11"><span class="linenos"> 11</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="MLPClassifier.__init__-12"><a href="#MLPClassifier.__init__-12"><span class="linenos"> 12</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-13"><a href="#MLPClassifier.__init__-13"><span class="linenos"> 13</span></a>        <span class="n">hidden_layer_sizes</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">100</span><span class="p">,),</span>
</span><span id="MLPClassifier.__init__-14"><a href="#MLPClassifier.__init__-14"><span class="linenos"> 14</span></a>        <span class="n">activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-15"><a href="#MLPClassifier.__init__-15"><span class="linenos"> 15</span></a>        <span class="n">solver</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sgd&quot;</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-16"><a href="#MLPClassifier.__init__-16"><span class="linenos"> 16</span></a>        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0001</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-17"><a href="#MLPClassifier.__init__-17"><span class="linenos"> 17</span></a>        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-18"><a href="#MLPClassifier.__init__-18"><span class="linenos"> 18</span></a>        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-19"><a href="#MLPClassifier.__init__-19"><span class="linenos"> 19</span></a>        <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-20"><a href="#MLPClassifier.__init__-20"><span class="linenos"> 20</span></a>        <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-21"><a href="#MLPClassifier.__init__-21"><span class="linenos"> 21</span></a>        <span class="n">random_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-22"><a href="#MLPClassifier.__init__-22"><span class="linenos"> 22</span></a>        <span class="n">beta1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-23"><a href="#MLPClassifier.__init__-23"><span class="linenos"> 23</span></a>        <span class="n">beta2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.999</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-24"><a href="#MLPClassifier.__init__-24"><span class="linenos"> 24</span></a>        <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-25"><a href="#MLPClassifier.__init__-25"><span class="linenos"> 25</span></a>        <span class="n">momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-26"><a href="#MLPClassifier.__init__-26"><span class="linenos"> 26</span></a>        <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-27"><a href="#MLPClassifier.__init__-27"><span class="linenos"> 27</span></a>        <span class="n">early_stopping</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-28"><a href="#MLPClassifier.__init__-28"><span class="linenos"> 28</span></a>        <span class="n">validation_fraction</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-29"><a href="#MLPClassifier.__init__-29"><span class="linenos"> 29</span></a>        <span class="n">n_iter_no_change</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>
</span><span id="MLPClassifier.__init__-30"><a href="#MLPClassifier.__init__-30"><span class="linenos"> 30</span></a>    <span class="p">):</span>
</span><span id="MLPClassifier.__init__-31"><a href="#MLPClassifier.__init__-31"><span class="linenos"> 31</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier.__init__-32"><a href="#MLPClassifier.__init__-32"><span class="linenos"> 32</span></a><span class="sd">        Initialize an MLP network</span>
</span><span id="MLPClassifier.__init__-33"><a href="#MLPClassifier.__init__-33"><span class="linenos"> 33</span></a><span class="sd">        </span>
</span><span id="MLPClassifier.__init__-34"><a href="#MLPClassifier.__init__-34"><span class="linenos"> 34</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPClassifier.__init__-35"><a href="#MLPClassifier.__init__-35"><span class="linenos"> 35</span></a><span class="sd">        -----------</span>
</span><span id="MLPClassifier.__init__-36"><a href="#MLPClassifier.__init__-36"><span class="linenos"> 36</span></a><span class="sd">        hidden_layer_sizes : tuple</span>
</span><span id="MLPClassifier.__init__-37"><a href="#MLPClassifier.__init__-37"><span class="linenos"> 37</span></a><span class="sd">            The sizes of hidden layers</span>
</span><span id="MLPClassifier.__init__-38"><a href="#MLPClassifier.__init__-38"><span class="linenos"> 38</span></a><span class="sd">        activation : str</span>
</span><span id="MLPClassifier.__init__-39"><a href="#MLPClassifier.__init__-39"><span class="linenos"> 39</span></a><span class="sd">            Activation function (&#39;sigmoid&#39;, &#39;relu&#39;, &#39;tanh&#39;, &#39;leaky_relu&#39;)</span>
</span><span id="MLPClassifier.__init__-40"><a href="#MLPClassifier.__init__-40"><span class="linenos"> 40</span></a><span class="sd">        solver : str</span>
</span><span id="MLPClassifier.__init__-41"><a href="#MLPClassifier.__init__-41"><span class="linenos"> 41</span></a><span class="sd">            Optimization algorithm (&#39;sgd&#39;, &#39;adam&#39;, &#39;rmsprop&#39;, &#39;momentum&#39;)</span>
</span><span id="MLPClassifier.__init__-42"><a href="#MLPClassifier.__init__-42"><span class="linenos"> 42</span></a><span class="sd">        alpha : float</span>
</span><span id="MLPClassifier.__init__-43"><a href="#MLPClassifier.__init__-43"><span class="linenos"> 43</span></a><span class="sd">            L2 regularization parameter</span>
</span><span id="MLPClassifier.__init__-44"><a href="#MLPClassifier.__init__-44"><span class="linenos"> 44</span></a><span class="sd">        batch_size : int</span>
</span><span id="MLPClassifier.__init__-45"><a href="#MLPClassifier.__init__-45"><span class="linenos"> 45</span></a><span class="sd">            Batch size for training</span>
</span><span id="MLPClassifier.__init__-46"><a href="#MLPClassifier.__init__-46"><span class="linenos"> 46</span></a><span class="sd">        learning_rate : float</span>
</span><span id="MLPClassifier.__init__-47"><a href="#MLPClassifier.__init__-47"><span class="linenos"> 47</span></a><span class="sd">            Learning rate</span>
</span><span id="MLPClassifier.__init__-48"><a href="#MLPClassifier.__init__-48"><span class="linenos"> 48</span></a><span class="sd">        max_iter : int</span>
</span><span id="MLPClassifier.__init__-49"><a href="#MLPClassifier.__init__-49"><span class="linenos"> 49</span></a><span class="sd">            Maximum number of iterations</span>
</span><span id="MLPClassifier.__init__-50"><a href="#MLPClassifier.__init__-50"><span class="linenos"> 50</span></a><span class="sd">        shuffle : bool</span>
</span><span id="MLPClassifier.__init__-51"><a href="#MLPClassifier.__init__-51"><span class="linenos"> 51</span></a><span class="sd">            If True, shuffle data at each epoch</span>
</span><span id="MLPClassifier.__init__-52"><a href="#MLPClassifier.__init__-52"><span class="linenos"> 52</span></a><span class="sd">        random_state : int or None</span>
</span><span id="MLPClassifier.__init__-53"><a href="#MLPClassifier.__init__-53"><span class="linenos"> 53</span></a><span class="sd">            Seed for reproducibility</span>
</span><span id="MLPClassifier.__init__-54"><a href="#MLPClassifier.__init__-54"><span class="linenos"> 54</span></a><span class="sd">        beta1 : float</span>
</span><span id="MLPClassifier.__init__-55"><a href="#MLPClassifier.__init__-55"><span class="linenos"> 55</span></a><span class="sd">            Parameter for Adam (exponential decay of first moment)</span>
</span><span id="MLPClassifier.__init__-56"><a href="#MLPClassifier.__init__-56"><span class="linenos"> 56</span></a><span class="sd">        beta2 : float</span>
</span><span id="MLPClassifier.__init__-57"><a href="#MLPClassifier.__init__-57"><span class="linenos"> 57</span></a><span class="sd">            Parameter for Adam (exponential decay of second moment)</span>
</span><span id="MLPClassifier.__init__-58"><a href="#MLPClassifier.__init__-58"><span class="linenos"> 58</span></a><span class="sd">        epsilon : float</span>
</span><span id="MLPClassifier.__init__-59"><a href="#MLPClassifier.__init__-59"><span class="linenos"> 59</span></a><span class="sd">            Value to avoid division by zero</span>
</span><span id="MLPClassifier.__init__-60"><a href="#MLPClassifier.__init__-60"><span class="linenos"> 60</span></a><span class="sd">        momentum : float</span>
</span><span id="MLPClassifier.__init__-61"><a href="#MLPClassifier.__init__-61"><span class="linenos"> 61</span></a><span class="sd">            Parameter for momentum optimizer</span>
</span><span id="MLPClassifier.__init__-62"><a href="#MLPClassifier.__init__-62"><span class="linenos"> 62</span></a><span class="sd">        tol : float</span>
</span><span id="MLPClassifier.__init__-63"><a href="#MLPClassifier.__init__-63"><span class="linenos"> 63</span></a><span class="sd">            Tolerance for early stopping</span>
</span><span id="MLPClassifier.__init__-64"><a href="#MLPClassifier.__init__-64"><span class="linenos"> 64</span></a><span class="sd">        early_stopping : bool</span>
</span><span id="MLPClassifier.__init__-65"><a href="#MLPClassifier.__init__-65"><span class="linenos"> 65</span></a><span class="sd">            If True, use early stopping based on validation</span>
</span><span id="MLPClassifier.__init__-66"><a href="#MLPClassifier.__init__-66"><span class="linenos"> 66</span></a><span class="sd">        validation_fraction : float</span>
</span><span id="MLPClassifier.__init__-67"><a href="#MLPClassifier.__init__-67"><span class="linenos"> 67</span></a><span class="sd">            Fraction of training data to use as validation</span>
</span><span id="MLPClassifier.__init__-68"><a href="#MLPClassifier.__init__-68"><span class="linenos"> 68</span></a><span class="sd">        n_iter_no_change : int</span>
</span><span id="MLPClassifier.__init__-69"><a href="#MLPClassifier.__init__-69"><span class="linenos"> 69</span></a><span class="sd">            Number of iterations with no improvement for early stopping</span>
</span><span id="MLPClassifier.__init__-70"><a href="#MLPClassifier.__init__-70"><span class="linenos"> 70</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier.__init__-71"><a href="#MLPClassifier.__init__-71"><span class="linenos"> 71</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_sizes</span> <span class="o">=</span> <span class="n">hidden_layer_sizes</span>
</span><span id="MLPClassifier.__init__-72"><a href="#MLPClassifier.__init__-72"><span class="linenos"> 72</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
</span><span id="MLPClassifier.__init__-73"><a href="#MLPClassifier.__init__-73"><span class="linenos"> 73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">=</span> <span class="n">solver</span>
</span><span id="MLPClassifier.__init__-74"><a href="#MLPClassifier.__init__-74"><span class="linenos"> 74</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
</span><span id="MLPClassifier.__init__-75"><a href="#MLPClassifier.__init__-75"><span class="linenos"> 75</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
</span><span id="MLPClassifier.__init__-76"><a href="#MLPClassifier.__init__-76"><span class="linenos"> 76</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
</span><span id="MLPClassifier.__init__-77"><a href="#MLPClassifier.__init__-77"><span class="linenos"> 77</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
</span><span id="MLPClassifier.__init__-78"><a href="#MLPClassifier.__init__-78"><span class="linenos"> 78</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span>
</span><span id="MLPClassifier.__init__-79"><a href="#MLPClassifier.__init__-79"><span class="linenos"> 79</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">=</span> <span class="n">beta1</span>
</span><span id="MLPClassifier.__init__-80"><a href="#MLPClassifier.__init__-80"><span class="linenos"> 80</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">=</span> <span class="n">beta2</span>
</span><span id="MLPClassifier.__init__-81"><a href="#MLPClassifier.__init__-81"><span class="linenos"> 81</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
</span><span id="MLPClassifier.__init__-82"><a href="#MLPClassifier.__init__-82"><span class="linenos"> 82</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
</span><span id="MLPClassifier.__init__-83"><a href="#MLPClassifier.__init__-83"><span class="linenos"> 83</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
</span><span id="MLPClassifier.__init__-84"><a href="#MLPClassifier.__init__-84"><span class="linenos"> 84</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping</span> <span class="o">=</span> <span class="n">early_stopping</span>
</span><span id="MLPClassifier.__init__-85"><a href="#MLPClassifier.__init__-85"><span class="linenos"> 85</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">validation_fraction</span> <span class="o">=</span> <span class="n">validation_fraction</span>
</span><span id="MLPClassifier.__init__-86"><a href="#MLPClassifier.__init__-86"><span class="linenos"> 86</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span> <span class="o">=</span> <span class="n">n_iter_no_change</span>
</span><span id="MLPClassifier.__init__-87"><a href="#MLPClassifier.__init__-87"><span class="linenos"> 87</span></a>        
</span><span id="MLPClassifier.__init__-88"><a href="#MLPClassifier.__init__-88"><span class="linenos"> 88</span></a>        <span class="k">if</span> <span class="n">random_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="MLPClassifier.__init__-89"><a href="#MLPClassifier.__init__-89"><span class="linenos"> 89</span></a>            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
</span><span id="MLPClassifier.__init__-90"><a href="#MLPClassifier.__init__-90"><span class="linenos"> 90</span></a>        
</span><span id="MLPClassifier.__init__-91"><a href="#MLPClassifier.__init__-91"><span class="linenos"> 91</span></a>        <span class="c1"># Selection of activation functions</span>
</span><span id="MLPClassifier.__init__-92"><a href="#MLPClassifier.__init__-92"><span class="linenos"> 92</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation_functions</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="MLPClassifier.__init__-93"><a href="#MLPClassifier.__init__-93"><span class="linenos"> 93</span></a>            <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-94"><a href="#MLPClassifier.__init__-94"><span class="linenos"> 94</span></a>            <span class="s1">&#39;relu&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-95"><a href="#MLPClassifier.__init__-95"><span class="linenos"> 95</span></a>            <span class="s1">&#39;tanh&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tanh</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-96"><a href="#MLPClassifier.__init__-96"><span class="linenos"> 96</span></a>            <span class="s1">&#39;softmax&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-97"><a href="#MLPClassifier.__init__-97"><span class="linenos"> 97</span></a>            <span class="s1">&#39;leaky_relu&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaky_relu</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-98"><a href="#MLPClassifier.__init__-98"><span class="linenos"> 98</span></a>        <span class="p">}</span>
</span><span id="MLPClassifier.__init__-99"><a href="#MLPClassifier.__init__-99"><span class="linenos"> 99</span></a>        
</span><span id="MLPClassifier.__init__-100"><a href="#MLPClassifier.__init__-100"><span class="linenos">100</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation_derivatives</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="MLPClassifier.__init__-101"><a href="#MLPClassifier.__init__-101"><span class="linenos">101</span></a>            <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid_derivative</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-102"><a href="#MLPClassifier.__init__-102"><span class="linenos">102</span></a>            <span class="s1">&#39;relu&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu_derivative</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-103"><a href="#MLPClassifier.__init__-103"><span class="linenos">103</span></a>            <span class="s1">&#39;tanh&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tanh_derivative</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-104"><a href="#MLPClassifier.__init__-104"><span class="linenos">104</span></a>            <span class="s1">&#39;softmax&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax_derivative</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-105"><a href="#MLPClassifier.__init__-105"><span class="linenos">105</span></a>            <span class="s1">&#39;leaky_relu&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaky_relu_derivative</span><span class="p">,</span>
</span><span id="MLPClassifier.__init__-106"><a href="#MLPClassifier.__init__-106"><span class="linenos">106</span></a>        <span class="p">}</span>
</span><span id="MLPClassifier.__init__-107"><a href="#MLPClassifier.__init__-107"><span class="linenos">107</span></a>        
</span><span id="MLPClassifier.__init__-108"><a href="#MLPClassifier.__init__-108"><span class="linenos">108</span></a>        <span class="c1"># Selection of activation function and its derivative</span>
</span><span id="MLPClassifier.__init__-109"><a href="#MLPClassifier.__init__-109"><span class="linenos">109</span></a>        <span class="k">if</span> <span class="n">activation</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_functions</span><span class="p">:</span>
</span><span id="MLPClassifier.__init__-110"><a href="#MLPClassifier.__init__-110"><span class="linenos">110</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Activation &#39;</span><span class="si">{</span><span class="n">activation</span><span class="si">}</span><span class="s2">&#39; not recognized. Use &#39;sigmoid&#39;, &#39;relu&#39;, &#39;tanh&#39;, or &#39;leaky_relu&#39;.&quot;</span><span class="p">)</span>
</span><span id="MLPClassifier.__init__-111"><a href="#MLPClassifier.__init__-111"><span class="linenos">111</span></a>        
</span><span id="MLPClassifier.__init__-112"><a href="#MLPClassifier.__init__-112"><span class="linenos">112</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_functions</span><span class="p">[</span><span class="n">activation</span><span class="p">]</span>
</span><span id="MLPClassifier.__init__-113"><a href="#MLPClassifier.__init__-113"><span class="linenos">113</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation_derivative</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_derivatives</span><span class="p">[</span><span class="n">activation</span><span class="p">]</span>
</span><span id="MLPClassifier.__init__-114"><a href="#MLPClassifier.__init__-114"><span class="linenos">114</span></a>        
</span><span id="MLPClassifier.__init__-115"><a href="#MLPClassifier.__init__-115"><span class="linenos">115</span></a>        <span class="c1"># Weight initialization</span>
</span><span id="MLPClassifier.__init__-116"><a href="#MLPClassifier.__init__-116"><span class="linenos">116</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier.__init__-117"><a href="#MLPClassifier.__init__-117"><span class="linenos">117</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier.__init__-118"><a href="#MLPClassifier.__init__-118"><span class="linenos">118</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="MLPClassifier.__init__-119"><a href="#MLPClassifier.__init__-119"><span class="linenos">119</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="MLPClassifier.__init__-120"><a href="#MLPClassifier.__init__-120"><span class="linenos">120</span></a>        
</span><span id="MLPClassifier.__init__-121"><a href="#MLPClassifier.__init__-121"><span class="linenos">121</span></a>        <span class="c1"># For optimizers</span>
</span><span id="MLPClassifier.__init__-122"><a href="#MLPClassifier.__init__-122"><span class="linenos">122</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">velocity_weights</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># For Momentum</span>
</span><span id="MLPClassifier.__init__-123"><a href="#MLPClassifier.__init__-123"><span class="linenos">123</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">velocity_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier.__init__-124"><a href="#MLPClassifier.__init__-124"><span class="linenos">124</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">m_weights</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># For Adam</span>
</span><span id="MLPClassifier.__init__-125"><a href="#MLPClassifier.__init__-125"><span class="linenos">125</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">m_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier.__init__-126"><a href="#MLPClassifier.__init__-126"><span class="linenos">126</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># For Adam</span>
</span><span id="MLPClassifier.__init__-127"><a href="#MLPClassifier.__init__-127"><span class="linenos">127</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier.__init__-128"><a href="#MLPClassifier.__init__-128"><span class="linenos">128</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Timestep for Adam</span>
</span><span id="MLPClassifier.__init__-129"><a href="#MLPClassifier.__init__-129"><span class="linenos">129</span></a>        
</span><span id="MLPClassifier.__init__-130"><a href="#MLPClassifier.__init__-130"><span class="linenos">130</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier.__init__-131"><a href="#MLPClassifier.__init__-131"><span class="linenos">131</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier.__init__-132"><a href="#MLPClassifier.__init__-132"><span class="linenos">132</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</span><span id="MLPClassifier.__init__-133"><a href="#MLPClassifier.__init__-133"><span class="linenos">133</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="MLPClassifier.__init__-134"><a href="#MLPClassifier.__init__-134"><span class="linenos">134</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">trained</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="MLPClassifier.__init__-135"><a href="#MLPClassifier.__init__-135"><span class="linenos">135</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="kc">None</span>
</span></pre></div>


            <div class="docstring"><p>Initialize an MLP network</p>

<h2 id="parameters">Parameters:</h2>

<p>hidden_layer_sizes : tuple
    The sizes of hidden layers
activation : str
    Activation function ('sigmoid', 'relu', 'tanh', 'leaky_relu')
solver : str
    Optimization algorithm ('sgd', 'adam', 'rmsprop', 'momentum')
alpha : float
    L2 regularization parameter
batch_size : int
    Batch size for training
learning_rate : float
    Learning rate
max_iter : int
    Maximum number of iterations
shuffle : bool
    If True, shuffle data at each epoch
random_state : int or None
    Seed for reproducibility
beta1 : float
    Parameter for Adam (exponential decay of first moment)
beta2 : float
    Parameter for Adam (exponential decay of second moment)
epsilon : float
    Value to avoid division by zero
momentum : float
    Parameter for momentum optimizer
tol : float
    Tolerance for early stopping
early_stopping : bool
    If True, use early stopping based on validation
validation_fraction : float
    Fraction of training data to use as validation
n_iter_no_change : int
    Number of iterations with no improvement for early stopping</p>
</div>


                            </div>
                            <div id="MLPClassifier.hidden_layer_sizes" class="classattr">
                                <div class="attr variable">
            <span class="name">hidden_layer_sizes</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.hidden_layer_sizes"></a>
    
    

                            </div>
                            <div id="MLPClassifier.activation" class="classattr">
                                <div class="attr variable">
            <span class="name">activation</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.activation"></a>
    
    

                            </div>
                            <div id="MLPClassifier.solver" class="classattr">
                                <div class="attr variable">
            <span class="name">solver</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.solver"></a>
    
    

                            </div>
                            <div id="MLPClassifier.alpha" class="classattr">
                                <div class="attr variable">
            <span class="name">alpha</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.alpha"></a>
    
    

                            </div>
                            <div id="MLPClassifier.batch_size" class="classattr">
                                <div class="attr variable">
            <span class="name">batch_size</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.batch_size"></a>
    
    

                            </div>
                            <div id="MLPClassifier.learning_rate" class="classattr">
                                <div class="attr variable">
            <span class="name">learning_rate</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.learning_rate"></a>
    
    

                            </div>
                            <div id="MLPClassifier.max_iter" class="classattr">
                                <div class="attr variable">
            <span class="name">max_iter</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.max_iter"></a>
    
    

                            </div>
                            <div id="MLPClassifier.shuffle" class="classattr">
                                <div class="attr variable">
            <span class="name">shuffle</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.shuffle"></a>
    
    

                            </div>
                            <div id="MLPClassifier.beta1" class="classattr">
                                <div class="attr variable">
            <span class="name">beta1</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.beta1"></a>
    
    

                            </div>
                            <div id="MLPClassifier.beta2" class="classattr">
                                <div class="attr variable">
            <span class="name">beta2</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.beta2"></a>
    
    

                            </div>
                            <div id="MLPClassifier.epsilon" class="classattr">
                                <div class="attr variable">
            <span class="name">epsilon</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.epsilon"></a>
    
    

                            </div>
                            <div id="MLPClassifier.momentum" class="classattr">
                                <div class="attr variable">
            <span class="name">momentum</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.momentum"></a>
    
    

                            </div>
                            <div id="MLPClassifier.tol" class="classattr">
                                <div class="attr variable">
            <span class="name">tol</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.tol"></a>
    
    

                            </div>
                            <div id="MLPClassifier.early_stopping" class="classattr">
                                <div class="attr variable">
            <span class="name">early_stopping</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.early_stopping"></a>
    
    

                            </div>
                            <div id="MLPClassifier.validation_fraction" class="classattr">
                                <div class="attr variable">
            <span class="name">validation_fraction</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.validation_fraction"></a>
    
    

                            </div>
                            <div id="MLPClassifier.n_iter_no_change" class="classattr">
                                <div class="attr variable">
            <span class="name">n_iter_no_change</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.n_iter_no_change"></a>
    
    

                            </div>
                            <div id="MLPClassifier.activation_functions" class="classattr">
                                <div class="attr variable">
            <span class="name">activation_functions</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.activation_functions"></a>
    
    

                            </div>
                            <div id="MLPClassifier.activation_derivatives" class="classattr">
                                <div class="attr variable">
            <span class="name">activation_derivatives</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.activation_derivatives"></a>
    
    

                            </div>
                            <div id="MLPClassifier.activation_func" class="classattr">
                                <div class="attr variable">
            <span class="name">activation_func</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.activation_func"></a>
    
    

                            </div>
                            <div id="MLPClassifier.activation_derivative" class="classattr">
                                <div class="attr variable">
            <span class="name">activation_derivative</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.activation_derivative"></a>
    
    

                            </div>
                            <div id="MLPClassifier.weights" class="classattr">
                                <div class="attr variable">
            <span class="name">weights</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.weights"></a>
    
    

                            </div>
                            <div id="MLPClassifier.biases" class="classattr">
                                <div class="attr variable">
            <span class="name">biases</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.biases"></a>
    
    

                            </div>
                            <div id="MLPClassifier.n_layers" class="classattr">
                                <div class="attr variable">
            <span class="name">n_layers</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.n_layers"></a>
    
    

                            </div>
                            <div id="MLPClassifier.n_outputs" class="classattr">
                                <div class="attr variable">
            <span class="name">n_outputs</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.n_outputs"></a>
    
    

                            </div>
                            <div id="MLPClassifier.velocity_weights" class="classattr">
                                <div class="attr variable">
            <span class="name">velocity_weights</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.velocity_weights"></a>
    
    

                            </div>
                            <div id="MLPClassifier.velocity_biases" class="classattr">
                                <div class="attr variable">
            <span class="name">velocity_biases</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.velocity_biases"></a>
    
    

                            </div>
                            <div id="MLPClassifier.m_weights" class="classattr">
                                <div class="attr variable">
            <span class="name">m_weights</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.m_weights"></a>
    
    

                            </div>
                            <div id="MLPClassifier.m_biases" class="classattr">
                                <div class="attr variable">
            <span class="name">m_biases</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.m_biases"></a>
    
    

                            </div>
                            <div id="MLPClassifier.v_weights" class="classattr">
                                <div class="attr variable">
            <span class="name">v_weights</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.v_weights"></a>
    
    

                            </div>
                            <div id="MLPClassifier.v_biases" class="classattr">
                                <div class="attr variable">
            <span class="name">v_biases</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.v_biases"></a>
    
    

                            </div>
                            <div id="MLPClassifier.t" class="classattr">
                                <div class="attr variable">
            <span class="name">t</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.t"></a>
    
    

                            </div>
                            <div id="MLPClassifier.loss_history" class="classattr">
                                <div class="attr variable">
            <span class="name">loss_history</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.loss_history"></a>
    
    

                            </div>
                            <div id="MLPClassifier.val_loss_history" class="classattr">
                                <div class="attr variable">
            <span class="name">val_loss_history</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.val_loss_history"></a>
    
    

                            </div>
                            <div id="MLPClassifier.best_loss" class="classattr">
                                <div class="attr variable">
            <span class="name">best_loss</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.best_loss"></a>
    
    

                            </div>
                            <div id="MLPClassifier.no_improvement_count" class="classattr">
                                <div class="attr variable">
            <span class="name">no_improvement_count</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.no_improvement_count"></a>
    
    

                            </div>
                            <div id="MLPClassifier.trained" class="classattr">
                                <div class="attr variable">
            <span class="name">trained</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.trained"></a>
    
    

                            </div>
                            <div id="MLPClassifier.classes_" class="classattr">
                                <div class="attr variable">
            <span class="name">classes_</span>

        
    </div>
    <a class="headerlink" href="#MLPClassifier.classes_"></a>
    
    

                            </div>
                            <div id="MLPClassifier.fit" class="classattr">
                                        <input id="MLPClassifier.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">X</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>,</span><span class="param">	<span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span></span><span class="return-annotation">) -> <span class="n"><a href="#MLPClassifier">MLPClassifier</a></span>:</span></span>

                <label class="view-source-button" for="MLPClassifier.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MLPClassifier.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MLPClassifier.fit-465"><a href="#MLPClassifier.fit-465"><span class="linenos">465</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;MLPClassifier&#39;</span><span class="p">:</span>
</span><span id="MLPClassifier.fit-466"><a href="#MLPClassifier.fit-466"><span class="linenos">466</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier.fit-467"><a href="#MLPClassifier.fit-467"><span class="linenos">467</span></a><span class="sd">        Train the MLP on the provided data</span>
</span><span id="MLPClassifier.fit-468"><a href="#MLPClassifier.fit-468"><span class="linenos">468</span></a><span class="sd">        </span>
</span><span id="MLPClassifier.fit-469"><a href="#MLPClassifier.fit-469"><span class="linenos">469</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPClassifier.fit-470"><a href="#MLPClassifier.fit-470"><span class="linenos">470</span></a><span class="sd">        -----------</span>
</span><span id="MLPClassifier.fit-471"><a href="#MLPClassifier.fit-471"><span class="linenos">471</span></a><span class="sd">        X : np.ndarray of shape (n_samples, n_features)</span>
</span><span id="MLPClassifier.fit-472"><a href="#MLPClassifier.fit-472"><span class="linenos">472</span></a><span class="sd">            Training data</span>
</span><span id="MLPClassifier.fit-473"><a href="#MLPClassifier.fit-473"><span class="linenos">473</span></a><span class="sd">        y : np.ndarray of shape (n_samples,)</span>
</span><span id="MLPClassifier.fit-474"><a href="#MLPClassifier.fit-474"><span class="linenos">474</span></a><span class="sd">            Target labels</span>
</span><span id="MLPClassifier.fit-475"><a href="#MLPClassifier.fit-475"><span class="linenos">475</span></a><span class="sd">            </span>
</span><span id="MLPClassifier.fit-476"><a href="#MLPClassifier.fit-476"><span class="linenos">476</span></a><span class="sd">        Returns:</span>
</span><span id="MLPClassifier.fit-477"><a href="#MLPClassifier.fit-477"><span class="linenos">477</span></a><span class="sd">        --------</span>
</span><span id="MLPClassifier.fit-478"><a href="#MLPClassifier.fit-478"><span class="linenos">478</span></a><span class="sd">        self : object</span>
</span><span id="MLPClassifier.fit-479"><a href="#MLPClassifier.fit-479"><span class="linenos">479</span></a><span class="sd">            The trained MLP</span>
</span><span id="MLPClassifier.fit-480"><a href="#MLPClassifier.fit-480"><span class="linenos">480</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier.fit-481"><a href="#MLPClassifier.fit-481"><span class="linenos">481</span></a>        <span class="c1"># Convert arrays</span>
</span><span id="MLPClassifier.fit-482"><a href="#MLPClassifier.fit-482"><span class="linenos">482</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-483"><a href="#MLPClassifier.fit-483"><span class="linenos">483</span></a>        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-484"><a href="#MLPClassifier.fit-484"><span class="linenos">484</span></a>        
</span><span id="MLPClassifier.fit-485"><a href="#MLPClassifier.fit-485"><span class="linenos">485</span></a>        <span class="c1"># Determine number of classes</span>
</span><span id="MLPClassifier.fit-486"><a href="#MLPClassifier.fit-486"><span class="linenos">486</span></a>        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</span><span id="MLPClassifier.fit-487"><a href="#MLPClassifier.fit-487"><span class="linenos">487</span></a>        
</span><span id="MLPClassifier.fit-488"><a href="#MLPClassifier.fit-488"><span class="linenos">488</span></a>        <span class="c1"># Encode labels and determine number of classes</span>
</span><span id="MLPClassifier.fit-489"><a href="#MLPClassifier.fit-489"><span class="linenos">489</span></a>        <span class="n">y_one_hot</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_labels</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-490"><a href="#MLPClassifier.fit-490"><span class="linenos">490</span></a>        <span class="n">n_outputs</span> <span class="o">=</span> <span class="n">y_one_hot</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="MLPClassifier.fit-491"><a href="#MLPClassifier.fit-491"><span class="linenos">491</span></a>        
</span><span id="MLPClassifier.fit-492"><a href="#MLPClassifier.fit-492"><span class="linenos">492</span></a>        <span class="c1"># Initialize weights</span>
</span><span id="MLPClassifier.fit-493"><a href="#MLPClassifier.fit-493"><span class="linenos">493</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_weights</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-494"><a href="#MLPClassifier.fit-494"><span class="linenos">494</span></a>        
</span><span id="MLPClassifier.fit-495"><a href="#MLPClassifier.fit-495"><span class="linenos">495</span></a>        <span class="c1"># Split into training and validation sets if early_stopping</span>
</span><span id="MLPClassifier.fit-496"><a href="#MLPClassifier.fit-496"><span class="linenos">496</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping</span><span class="p">:</span>
</span><span id="MLPClassifier.fit-497"><a href="#MLPClassifier.fit-497"><span class="linenos">497</span></a>            <span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_train_validation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-498"><a href="#MLPClassifier.fit-498"><span class="linenos">498</span></a>            <span class="n">y_train_one_hot</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_labels</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-499"><a href="#MLPClassifier.fit-499"><span class="linenos">499</span></a>            <span class="n">y_val_one_hot</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_labels</span><span class="p">(</span><span class="n">y_val</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-500"><a href="#MLPClassifier.fit-500"><span class="linenos">500</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="MLPClassifier.fit-501"><a href="#MLPClassifier.fit-501"><span class="linenos">501</span></a>            <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</span><span id="MLPClassifier.fit-502"><a href="#MLPClassifier.fit-502"><span class="linenos">502</span></a>            <span class="n">y_train_one_hot</span> <span class="o">=</span> <span class="n">y_one_hot</span>
</span><span id="MLPClassifier.fit-503"><a href="#MLPClassifier.fit-503"><span class="linenos">503</span></a>        
</span><span id="MLPClassifier.fit-504"><a href="#MLPClassifier.fit-504"><span class="linenos">504</span></a>        <span class="c1"># Update method according to chosen optimizer</span>
</span><span id="MLPClassifier.fit-505"><a href="#MLPClassifier.fit-505"><span class="linenos">505</span></a>        <span class="n">update_methods</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="MLPClassifier.fit-506"><a href="#MLPClassifier.fit-506"><span class="linenos">506</span></a>            <span class="s1">&#39;sgd&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights_sgd</span><span class="p">,</span>
</span><span id="MLPClassifier.fit-507"><a href="#MLPClassifier.fit-507"><span class="linenos">507</span></a>            <span class="s1">&#39;momentum&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights_momentum</span><span class="p">,</span>
</span><span id="MLPClassifier.fit-508"><a href="#MLPClassifier.fit-508"><span class="linenos">508</span></a>            <span class="s1">&#39;rmsprop&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights_rmsprop</span><span class="p">,</span>
</span><span id="MLPClassifier.fit-509"><a href="#MLPClassifier.fit-509"><span class="linenos">509</span></a>            <span class="s1">&#39;adam&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights_adam</span>
</span><span id="MLPClassifier.fit-510"><a href="#MLPClassifier.fit-510"><span class="linenos">510</span></a>        <span class="p">}</span>
</span><span id="MLPClassifier.fit-511"><a href="#MLPClassifier.fit-511"><span class="linenos">511</span></a>        
</span><span id="MLPClassifier.fit-512"><a href="#MLPClassifier.fit-512"><span class="linenos">512</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">update_methods</span><span class="p">:</span>
</span><span id="MLPClassifier.fit-513"><a href="#MLPClassifier.fit-513"><span class="linenos">513</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimizer &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s2">&#39; not recognized.&quot;</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-514"><a href="#MLPClassifier.fit-514"><span class="linenos">514</span></a>        
</span><span id="MLPClassifier.fit-515"><a href="#MLPClassifier.fit-515"><span class="linenos">515</span></a>        <span class="n">update_weights</span> <span class="o">=</span> <span class="n">update_methods</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">]</span>
</span><span id="MLPClassifier.fit-516"><a href="#MLPClassifier.fit-516"><span class="linenos">516</span></a>        
</span><span id="MLPClassifier.fit-517"><a href="#MLPClassifier.fit-517"><span class="linenos">517</span></a>        <span class="c1"># Training over multiple epochs</span>
</span><span id="MLPClassifier.fit-518"><a href="#MLPClassifier.fit-518"><span class="linenos">518</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier.fit-519"><a href="#MLPClassifier.fit-519"><span class="linenos">519</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier.fit-520"><a href="#MLPClassifier.fit-520"><span class="linenos">520</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</span><span id="MLPClassifier.fit-521"><a href="#MLPClassifier.fit-521"><span class="linenos">521</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="MLPClassifier.fit-522"><a href="#MLPClassifier.fit-522"><span class="linenos">522</span></a>        
</span><span id="MLPClassifier.fit-523"><a href="#MLPClassifier.fit-523"><span class="linenos">523</span></a>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">):</span>
</span><span id="MLPClassifier.fit-524"><a href="#MLPClassifier.fit-524"><span class="linenos">524</span></a>            <span class="c1"># Shuffle data if requested</span>
</span><span id="MLPClassifier.fit-525"><a href="#MLPClassifier.fit-525"><span class="linenos">525</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
</span><span id="MLPClassifier.fit-526"><a href="#MLPClassifier.fit-526"><span class="linenos">526</span></a>                <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>
</span><span id="MLPClassifier.fit-527"><a href="#MLPClassifier.fit-527"><span class="linenos">527</span></a>                <span class="n">X_train_shuffled</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="MLPClassifier.fit-528"><a href="#MLPClassifier.fit-528"><span class="linenos">528</span></a>                <span class="n">y_train_shuffled</span> <span class="o">=</span> <span class="n">y_train_one_hot</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="MLPClassifier.fit-529"><a href="#MLPClassifier.fit-529"><span class="linenos">529</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="MLPClassifier.fit-530"><a href="#MLPClassifier.fit-530"><span class="linenos">530</span></a>                <span class="n">X_train_shuffled</span> <span class="o">=</span> <span class="n">X_train</span>
</span><span id="MLPClassifier.fit-531"><a href="#MLPClassifier.fit-531"><span class="linenos">531</span></a>                <span class="n">y_train_shuffled</span> <span class="o">=</span> <span class="n">y_train_one_hot</span>
</span><span id="MLPClassifier.fit-532"><a href="#MLPClassifier.fit-532"><span class="linenos">532</span></a>            
</span><span id="MLPClassifier.fit-533"><a href="#MLPClassifier.fit-533"><span class="linenos">533</span></a>            <span class="c1"># Training by mini-batches</span>
</span><span id="MLPClassifier.fit-534"><a href="#MLPClassifier.fit-534"><span class="linenos">534</span></a>            <span class="n">batch_losses</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPClassifier.fit-535"><a href="#MLPClassifier.fit-535"><span class="linenos">535</span></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
</span><span id="MLPClassifier.fit-536"><a href="#MLPClassifier.fit-536"><span class="linenos">536</span></a>                <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_train_shuffled</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
</span><span id="MLPClassifier.fit-537"><a href="#MLPClassifier.fit-537"><span class="linenos">537</span></a>                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_train_shuffled</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
</span><span id="MLPClassifier.fit-538"><a href="#MLPClassifier.fit-538"><span class="linenos">538</span></a>                
</span><span id="MLPClassifier.fit-539"><a href="#MLPClassifier.fit-539"><span class="linenos">539</span></a>                <span class="c1"># Forward propagation</span>
</span><span id="MLPClassifier.fit-540"><a href="#MLPClassifier.fit-540"><span class="linenos">540</span></a>                <span class="n">activations</span><span class="p">,</span> <span class="n">layer_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-541"><a href="#MLPClassifier.fit-541"><span class="linenos">541</span></a>                
</span><span id="MLPClassifier.fit-542"><a href="#MLPClassifier.fit-542"><span class="linenos">542</span></a>                <span class="c1"># Loss calculation</span>
</span><span id="MLPClassifier.fit-543"><a href="#MLPClassifier.fit-543"><span class="linenos">543</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">y_batch</span><span class="p">,</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="MLPClassifier.fit-544"><a href="#MLPClassifier.fit-544"><span class="linenos">544</span></a>                <span class="n">batch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-545"><a href="#MLPClassifier.fit-545"><span class="linenos">545</span></a>                
</span><span id="MLPClassifier.fit-546"><a href="#MLPClassifier.fit-546"><span class="linenos">546</span></a>                <span class="c1"># Backpropagation</span>
</span><span id="MLPClassifier.fit-547"><a href="#MLPClassifier.fit-547"><span class="linenos">547</span></a>                <span class="n">gradients_w</span><span class="p">,</span> <span class="n">gradients_b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pass</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">,</span> <span class="n">activations</span><span class="p">,</span> <span class="n">layer_inputs</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-548"><a href="#MLPClassifier.fit-548"><span class="linenos">548</span></a>                
</span><span id="MLPClassifier.fit-549"><a href="#MLPClassifier.fit-549"><span class="linenos">549</span></a>                <span class="c1"># Weight update</span>
</span><span id="MLPClassifier.fit-550"><a href="#MLPClassifier.fit-550"><span class="linenos">550</span></a>                <span class="n">update_weights</span><span class="p">(</span><span class="n">gradients_w</span><span class="p">,</span> <span class="n">gradients_b</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-551"><a href="#MLPClassifier.fit-551"><span class="linenos">551</span></a>            
</span><span id="MLPClassifier.fit-552"><a href="#MLPClassifier.fit-552"><span class="linenos">552</span></a>            <span class="c1"># Average loss over the epoch</span>
</span><span id="MLPClassifier.fit-553"><a href="#MLPClassifier.fit-553"><span class="linenos">553</span></a>            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">batch_losses</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-554"><a href="#MLPClassifier.fit-554"><span class="linenos">554</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-555"><a href="#MLPClassifier.fit-555"><span class="linenos">555</span></a>            
</span><span id="MLPClassifier.fit-556"><a href="#MLPClassifier.fit-556"><span class="linenos">556</span></a>            <span class="c1"># Validation if early_stopping is activated</span>
</span><span id="MLPClassifier.fit-557"><a href="#MLPClassifier.fit-557"><span class="linenos">557</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping</span><span class="p">:</span>
</span><span id="MLPClassifier.fit-558"><a href="#MLPClassifier.fit-558"><span class="linenos">558</span></a>                <span class="c1"># Calculate loss on validation set</span>
</span><span id="MLPClassifier.fit-559"><a href="#MLPClassifier.fit-559"><span class="linenos">559</span></a>                <span class="n">val_activations</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-560"><a href="#MLPClassifier.fit-560"><span class="linenos">560</span></a>                <span class="n">val_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">y_val_one_hot</span><span class="p">,</span> <span class="n">val_activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="MLPClassifier.fit-561"><a href="#MLPClassifier.fit-561"><span class="linenos">561</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">val_loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-562"><a href="#MLPClassifier.fit-562"><span class="linenos">562</span></a>                
</span><span id="MLPClassifier.fit-563"><a href="#MLPClassifier.fit-563"><span class="linenos">563</span></a>                <span class="c1"># Check for improvement</span>
</span><span id="MLPClassifier.fit-564"><a href="#MLPClassifier.fit-564"><span class="linenos">564</span></a>                <span class="k">if</span> <span class="n">val_loss</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">:</span>
</span><span id="MLPClassifier.fit-565"><a href="#MLPClassifier.fit-565"><span class="linenos">565</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="n">val_loss</span>
</span><span id="MLPClassifier.fit-566"><a href="#MLPClassifier.fit-566"><span class="linenos">566</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="MLPClassifier.fit-567"><a href="#MLPClassifier.fit-567"><span class="linenos">567</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="MLPClassifier.fit-568"><a href="#MLPClassifier.fit-568"><span class="linenos">568</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="MLPClassifier.fit-569"><a href="#MLPClassifier.fit-569"><span class="linenos">569</span></a>                
</span><span id="MLPClassifier.fit-570"><a href="#MLPClassifier.fit-570"><span class="linenos">570</span></a>                <span class="c1"># Early stopping</span>
</span><span id="MLPClassifier.fit-571"><a href="#MLPClassifier.fit-571"><span class="linenos">571</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span><span class="p">:</span>
</span><span id="MLPClassifier.fit-572"><a href="#MLPClassifier.fit-572"><span class="linenos">572</span></a>                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Early stopping at epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="MLPClassifier.fit-573"><a href="#MLPClassifier.fit-573"><span class="linenos">573</span></a>                    <span class="k">break</span>
</span><span id="MLPClassifier.fit-574"><a href="#MLPClassifier.fit-574"><span class="linenos">574</span></a>        
</span><span id="MLPClassifier.fit-575"><a href="#MLPClassifier.fit-575"><span class="linenos">575</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">trained</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="MLPClassifier.fit-576"><a href="#MLPClassifier.fit-576"><span class="linenos">576</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span></pre></div>


            <div class="docstring"><p>Train the MLP on the provided data</p>

<h2 id="parameters">Parameters:</h2>

<p>X : np.ndarray of shape (n_samples, n_features)
    Training data
y : np.ndarray of shape (n_samples,)
    Target labels</p>

<h2 id="returns">Returns:</h2>

<p>self : object
    The trained MLP</p>
</div>


                            </div>
                            <div id="MLPClassifier.predict" class="classattr">
                                        <input id="MLPClassifier.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>:</span></span>

                <label class="view-source-button" for="MLPClassifier.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MLPClassifier.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MLPClassifier.predict-578"><a href="#MLPClassifier.predict-578"><span class="linenos">578</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPClassifier.predict-579"><a href="#MLPClassifier.predict-579"><span class="linenos">579</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier.predict-580"><a href="#MLPClassifier.predict-580"><span class="linenos">580</span></a><span class="sd">        Predict classes for samples X</span>
</span><span id="MLPClassifier.predict-581"><a href="#MLPClassifier.predict-581"><span class="linenos">581</span></a><span class="sd">        </span>
</span><span id="MLPClassifier.predict-582"><a href="#MLPClassifier.predict-582"><span class="linenos">582</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPClassifier.predict-583"><a href="#MLPClassifier.predict-583"><span class="linenos">583</span></a><span class="sd">        -----------</span>
</span><span id="MLPClassifier.predict-584"><a href="#MLPClassifier.predict-584"><span class="linenos">584</span></a><span class="sd">        X : np.ndarray of shape (n_samples, n_features)</span>
</span><span id="MLPClassifier.predict-585"><a href="#MLPClassifier.predict-585"><span class="linenos">585</span></a><span class="sd">            Data for which to make predictions</span>
</span><span id="MLPClassifier.predict-586"><a href="#MLPClassifier.predict-586"><span class="linenos">586</span></a><span class="sd">            </span>
</span><span id="MLPClassifier.predict-587"><a href="#MLPClassifier.predict-587"><span class="linenos">587</span></a><span class="sd">        Returns:</span>
</span><span id="MLPClassifier.predict-588"><a href="#MLPClassifier.predict-588"><span class="linenos">588</span></a><span class="sd">        --------</span>
</span><span id="MLPClassifier.predict-589"><a href="#MLPClassifier.predict-589"><span class="linenos">589</span></a><span class="sd">        y_pred : np.ndarray of shape (n_samples,)</span>
</span><span id="MLPClassifier.predict-590"><a href="#MLPClassifier.predict-590"><span class="linenos">590</span></a><span class="sd">            Predicted classes</span>
</span><span id="MLPClassifier.predict-591"><a href="#MLPClassifier.predict-591"><span class="linenos">591</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier.predict-592"><a href="#MLPClassifier.predict-592"><span class="linenos">592</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trained</span><span class="p">:</span>
</span><span id="MLPClassifier.predict-593"><a href="#MLPClassifier.predict-593"><span class="linenos">593</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The model must be trained before making predictions.&quot;</span><span class="p">)</span>
</span><span id="MLPClassifier.predict-594"><a href="#MLPClassifier.predict-594"><span class="linenos">594</span></a>        
</span><span id="MLPClassifier.predict-595"><a href="#MLPClassifier.predict-595"><span class="linenos">595</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="MLPClassifier.predict-596"><a href="#MLPClassifier.predict-596"><span class="linenos">596</span></a>        <span class="n">activations</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="MLPClassifier.predict-597"><a href="#MLPClassifier.predict-597"><span class="linenos">597</span></a>        <span class="n">y_pred_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="MLPClassifier.predict-598"><a href="#MLPClassifier.predict-598"><span class="linenos">598</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="n">y_pred_indices</span><span class="p">]</span>
</span></pre></div>


            <div class="docstring"><p>Predict classes for samples X</p>

<h2 id="parameters">Parameters:</h2>

<p>X : np.ndarray of shape (n_samples, n_features)
    Data for which to make predictions</p>

<h2 id="returns">Returns:</h2>

<p>y_pred : np.ndarray of shape (n_samples,)
    Predicted classes</p>
</div>


                            </div>
                            <div id="MLPClassifier.predict_proba" class="classattr">
                                        <input id="MLPClassifier.predict_proba-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict_proba</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>:</span></span>

                <label class="view-source-button" for="MLPClassifier.predict_proba-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MLPClassifier.predict_proba"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MLPClassifier.predict_proba-600"><a href="#MLPClassifier.predict_proba-600"><span class="linenos">600</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPClassifier.predict_proba-601"><a href="#MLPClassifier.predict_proba-601"><span class="linenos">601</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier.predict_proba-602"><a href="#MLPClassifier.predict_proba-602"><span class="linenos">602</span></a><span class="sd">        Predict probabilities for each class</span>
</span><span id="MLPClassifier.predict_proba-603"><a href="#MLPClassifier.predict_proba-603"><span class="linenos">603</span></a><span class="sd">        </span>
</span><span id="MLPClassifier.predict_proba-604"><a href="#MLPClassifier.predict_proba-604"><span class="linenos">604</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPClassifier.predict_proba-605"><a href="#MLPClassifier.predict_proba-605"><span class="linenos">605</span></a><span class="sd">        -----------</span>
</span><span id="MLPClassifier.predict_proba-606"><a href="#MLPClassifier.predict_proba-606"><span class="linenos">606</span></a><span class="sd">        X : np.ndarray of shape (n_samples, n_features)</span>
</span><span id="MLPClassifier.predict_proba-607"><a href="#MLPClassifier.predict_proba-607"><span class="linenos">607</span></a><span class="sd">            Data for which to make predictions</span>
</span><span id="MLPClassifier.predict_proba-608"><a href="#MLPClassifier.predict_proba-608"><span class="linenos">608</span></a><span class="sd">            </span>
</span><span id="MLPClassifier.predict_proba-609"><a href="#MLPClassifier.predict_proba-609"><span class="linenos">609</span></a><span class="sd">        Returns:</span>
</span><span id="MLPClassifier.predict_proba-610"><a href="#MLPClassifier.predict_proba-610"><span class="linenos">610</span></a><span class="sd">        --------</span>
</span><span id="MLPClassifier.predict_proba-611"><a href="#MLPClassifier.predict_proba-611"><span class="linenos">611</span></a><span class="sd">        probas : np.ndarray of shape (n_samples, n_classes)</span>
</span><span id="MLPClassifier.predict_proba-612"><a href="#MLPClassifier.predict_proba-612"><span class="linenos">612</span></a><span class="sd">            Probabilities for each class</span>
</span><span id="MLPClassifier.predict_proba-613"><a href="#MLPClassifier.predict_proba-613"><span class="linenos">613</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier.predict_proba-614"><a href="#MLPClassifier.predict_proba-614"><span class="linenos">614</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trained</span><span class="p">:</span>
</span><span id="MLPClassifier.predict_proba-615"><a href="#MLPClassifier.predict_proba-615"><span class="linenos">615</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The model must be trained before making predictions.&quot;</span><span class="p">)</span>
</span><span id="MLPClassifier.predict_proba-616"><a href="#MLPClassifier.predict_proba-616"><span class="linenos">616</span></a>        
</span><span id="MLPClassifier.predict_proba-617"><a href="#MLPClassifier.predict_proba-617"><span class="linenos">617</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="MLPClassifier.predict_proba-618"><a href="#MLPClassifier.predict_proba-618"><span class="linenos">618</span></a>        <span class="n">activations</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="MLPClassifier.predict_proba-619"><a href="#MLPClassifier.predict_proba-619"><span class="linenos">619</span></a>        <span class="k">return</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></pre></div>


            <div class="docstring"><p>Predict probabilities for each class</p>

<h2 id="parameters">Parameters:</h2>

<p>X : np.ndarray of shape (n_samples, n_features)
    Data for which to make predictions</p>

<h2 id="returns">Returns:</h2>

<p>probas : np.ndarray of shape (n_samples, n_classes)
    Probabilities for each class</p>
</div>


                            </div>
                            <div id="MLPClassifier.score" class="classattr">
                                        <input id="MLPClassifier.score-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">score</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>, </span><span class="param"><span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span></span><span class="return-annotation">) -> <span class="nb">float</span>:</span></span>

                <label class="view-source-button" for="MLPClassifier.score-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MLPClassifier.score"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MLPClassifier.score-621"><a href="#MLPClassifier.score-621"><span class="linenos">621</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span><span id="MLPClassifier.score-622"><a href="#MLPClassifier.score-622"><span class="linenos">622</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPClassifier.score-623"><a href="#MLPClassifier.score-623"><span class="linenos">623</span></a><span class="sd">        Return the accuracy of the model on the provided data</span>
</span><span id="MLPClassifier.score-624"><a href="#MLPClassifier.score-624"><span class="linenos">624</span></a><span class="sd">        </span>
</span><span id="MLPClassifier.score-625"><a href="#MLPClassifier.score-625"><span class="linenos">625</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPClassifier.score-626"><a href="#MLPClassifier.score-626"><span class="linenos">626</span></a><span class="sd">        -----------</span>
</span><span id="MLPClassifier.score-627"><a href="#MLPClassifier.score-627"><span class="linenos">627</span></a><span class="sd">        X : np.ndarray of shape (n_samples, n_features)</span>
</span><span id="MLPClassifier.score-628"><a href="#MLPClassifier.score-628"><span class="linenos">628</span></a><span class="sd">            Test data</span>
</span><span id="MLPClassifier.score-629"><a href="#MLPClassifier.score-629"><span class="linenos">629</span></a><span class="sd">        y : np.ndarray of shape (n_samples,)</span>
</span><span id="MLPClassifier.score-630"><a href="#MLPClassifier.score-630"><span class="linenos">630</span></a><span class="sd">            True labels</span>
</span><span id="MLPClassifier.score-631"><a href="#MLPClassifier.score-631"><span class="linenos">631</span></a><span class="sd">            </span>
</span><span id="MLPClassifier.score-632"><a href="#MLPClassifier.score-632"><span class="linenos">632</span></a><span class="sd">        Returns:</span>
</span><span id="MLPClassifier.score-633"><a href="#MLPClassifier.score-633"><span class="linenos">633</span></a><span class="sd">        --------</span>
</span><span id="MLPClassifier.score-634"><a href="#MLPClassifier.score-634"><span class="linenos">634</span></a><span class="sd">        accuracy : float</span>
</span><span id="MLPClassifier.score-635"><a href="#MLPClassifier.score-635"><span class="linenos">635</span></a><span class="sd">            Model accuracy</span>
</span><span id="MLPClassifier.score-636"><a href="#MLPClassifier.score-636"><span class="linenos">636</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPClassifier.score-637"><a href="#MLPClassifier.score-637"><span class="linenos">637</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trained</span><span class="p">:</span>
</span><span id="MLPClassifier.score-638"><a href="#MLPClassifier.score-638"><span class="linenos">638</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The model must be trained before calculating its score.&quot;</span><span class="p">)</span>
</span><span id="MLPClassifier.score-639"><a href="#MLPClassifier.score-639"><span class="linenos">639</span></a>            
</span><span id="MLPClassifier.score-640"><a href="#MLPClassifier.score-640"><span class="linenos">640</span></a>        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="MLPClassifier.score-641"><a href="#MLPClassifier.score-641"><span class="linenos">641</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Return the accuracy of the model on the provided data</p>

<h2 id="parameters">Parameters:</h2>

<p>X : np.ndarray of shape (n_samples, n_features)
    Test data
y : np.ndarray of shape (n_samples,)
    True labels</p>

<h2 id="returns">Returns:</h2>

<p>accuracy : float
    Model accuracy</p>
</div>


                            </div>
                </section>
                <section id="MLPRegressor">
                            <input id="MLPRegressor-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">MLPRegressor</span>:

                <label class="view-source-button" for="MLPRegressor-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MLPRegressor"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MLPRegressor-6"><a href="#MLPRegressor-6"><span class="linenos">  6</span></a><span class="k">class</span><span class="w"> </span><span class="nc">MLPRegressor</span><span class="p">:</span>
</span><span id="MLPRegressor-7"><a href="#MLPRegressor-7"><span class="linenos">  7</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-8"><a href="#MLPRegressor-8"><span class="linenos">  8</span></a><span class="sd">    Multi-Layer Perceptron for regression tasks with various activation functions and optimizers</span>
</span><span id="MLPRegressor-9"><a href="#MLPRegressor-9"><span class="linenos">  9</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-10"><a href="#MLPRegressor-10"><span class="linenos"> 10</span></a>    
</span><span id="MLPRegressor-11"><a href="#MLPRegressor-11"><span class="linenos"> 11</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="MLPRegressor-12"><a href="#MLPRegressor-12"><span class="linenos"> 12</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="MLPRegressor-13"><a href="#MLPRegressor-13"><span class="linenos"> 13</span></a>        <span class="n">hidden_layer_sizes</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">100</span><span class="p">,),</span>
</span><span id="MLPRegressor-14"><a href="#MLPRegressor-14"><span class="linenos"> 14</span></a>        <span class="n">activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
</span><span id="MLPRegressor-15"><a href="#MLPRegressor-15"><span class="linenos"> 15</span></a>        <span class="n">solver</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sgd&quot;</span><span class="p">,</span>
</span><span id="MLPRegressor-16"><a href="#MLPRegressor-16"><span class="linenos"> 16</span></a>        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0001</span><span class="p">,</span>
</span><span id="MLPRegressor-17"><a href="#MLPRegressor-17"><span class="linenos"> 17</span></a>        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
</span><span id="MLPRegressor-18"><a href="#MLPRegressor-18"><span class="linenos"> 18</span></a>        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
</span><span id="MLPRegressor-19"><a href="#MLPRegressor-19"><span class="linenos"> 19</span></a>        <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
</span><span id="MLPRegressor-20"><a href="#MLPRegressor-20"><span class="linenos"> 20</span></a>        <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="MLPRegressor-21"><a href="#MLPRegressor-21"><span class="linenos"> 21</span></a>        <span class="n">random_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="MLPRegressor-22"><a href="#MLPRegressor-22"><span class="linenos"> 22</span></a>        <span class="n">beta1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
</span><span id="MLPRegressor-23"><a href="#MLPRegressor-23"><span class="linenos"> 23</span></a>        <span class="n">beta2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.999</span><span class="p">,</span>
</span><span id="MLPRegressor-24"><a href="#MLPRegressor-24"><span class="linenos"> 24</span></a>        <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
</span><span id="MLPRegressor-25"><a href="#MLPRegressor-25"><span class="linenos"> 25</span></a>        <span class="n">momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
</span><span id="MLPRegressor-26"><a href="#MLPRegressor-26"><span class="linenos"> 26</span></a>        <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
</span><span id="MLPRegressor-27"><a href="#MLPRegressor-27"><span class="linenos"> 27</span></a>        <span class="n">early_stopping</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="MLPRegressor-28"><a href="#MLPRegressor-28"><span class="linenos"> 28</span></a>        <span class="n">validation_fraction</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
</span><span id="MLPRegressor-29"><a href="#MLPRegressor-29"><span class="linenos"> 29</span></a>        <span class="n">n_iter_no_change</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>
</span><span id="MLPRegressor-30"><a href="#MLPRegressor-30"><span class="linenos"> 30</span></a>    <span class="p">):</span>
</span><span id="MLPRegressor-31"><a href="#MLPRegressor-31"><span class="linenos"> 31</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-32"><a href="#MLPRegressor-32"><span class="linenos"> 32</span></a><span class="sd">        Initialize an MLP regressor</span>
</span><span id="MLPRegressor-33"><a href="#MLPRegressor-33"><span class="linenos"> 33</span></a><span class="sd">        </span>
</span><span id="MLPRegressor-34"><a href="#MLPRegressor-34"><span class="linenos"> 34</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPRegressor-35"><a href="#MLPRegressor-35"><span class="linenos"> 35</span></a><span class="sd">        -----------</span>
</span><span id="MLPRegressor-36"><a href="#MLPRegressor-36"><span class="linenos"> 36</span></a><span class="sd">        hidden_layer_sizes : tuple</span>
</span><span id="MLPRegressor-37"><a href="#MLPRegressor-37"><span class="linenos"> 37</span></a><span class="sd">            The sizes of the hidden layers</span>
</span><span id="MLPRegressor-38"><a href="#MLPRegressor-38"><span class="linenos"> 38</span></a><span class="sd">        activation : str</span>
</span><span id="MLPRegressor-39"><a href="#MLPRegressor-39"><span class="linenos"> 39</span></a><span class="sd">            Activation function (&#39;sigmoid&#39;, &#39;relu&#39;, &#39;tanh&#39;, &#39;leaky_relu&#39;)</span>
</span><span id="MLPRegressor-40"><a href="#MLPRegressor-40"><span class="linenos"> 40</span></a><span class="sd">        solver : str</span>
</span><span id="MLPRegressor-41"><a href="#MLPRegressor-41"><span class="linenos"> 41</span></a><span class="sd">            Optimization algorithm (&#39;sgd&#39;, &#39;adam&#39;, &#39;rmsprop&#39;, &#39;momentum&#39;)</span>
</span><span id="MLPRegressor-42"><a href="#MLPRegressor-42"><span class="linenos"> 42</span></a><span class="sd">        alpha : float</span>
</span><span id="MLPRegressor-43"><a href="#MLPRegressor-43"><span class="linenos"> 43</span></a><span class="sd">            L2 regularization parameter</span>
</span><span id="MLPRegressor-44"><a href="#MLPRegressor-44"><span class="linenos"> 44</span></a><span class="sd">        batch_size : int</span>
</span><span id="MLPRegressor-45"><a href="#MLPRegressor-45"><span class="linenos"> 45</span></a><span class="sd">            Size of mini-batches for training</span>
</span><span id="MLPRegressor-46"><a href="#MLPRegressor-46"><span class="linenos"> 46</span></a><span class="sd">        learning_rate : float</span>
</span><span id="MLPRegressor-47"><a href="#MLPRegressor-47"><span class="linenos"> 47</span></a><span class="sd">            Learning rate</span>
</span><span id="MLPRegressor-48"><a href="#MLPRegressor-48"><span class="linenos"> 48</span></a><span class="sd">        max_iter : int</span>
</span><span id="MLPRegressor-49"><a href="#MLPRegressor-49"><span class="linenos"> 49</span></a><span class="sd">            Maximum number of iterations</span>
</span><span id="MLPRegressor-50"><a href="#MLPRegressor-50"><span class="linenos"> 50</span></a><span class="sd">        shuffle : bool</span>
</span><span id="MLPRegressor-51"><a href="#MLPRegressor-51"><span class="linenos"> 51</span></a><span class="sd">            If True, shuffle the data at each epoch</span>
</span><span id="MLPRegressor-52"><a href="#MLPRegressor-52"><span class="linenos"> 52</span></a><span class="sd">        random_state : int or None</span>
</span><span id="MLPRegressor-53"><a href="#MLPRegressor-53"><span class="linenos"> 53</span></a><span class="sd">            Seed for reproducibility</span>
</span><span id="MLPRegressor-54"><a href="#MLPRegressor-54"><span class="linenos"> 54</span></a><span class="sd">        beta1 : float</span>
</span><span id="MLPRegressor-55"><a href="#MLPRegressor-55"><span class="linenos"> 55</span></a><span class="sd">            Parameter for Adam (exponential decay rate for first moment)</span>
</span><span id="MLPRegressor-56"><a href="#MLPRegressor-56"><span class="linenos"> 56</span></a><span class="sd">        beta2 : float</span>
</span><span id="MLPRegressor-57"><a href="#MLPRegressor-57"><span class="linenos"> 57</span></a><span class="sd">            Parameter for Adam (exponential decay rate for second moment)</span>
</span><span id="MLPRegressor-58"><a href="#MLPRegressor-58"><span class="linenos"> 58</span></a><span class="sd">        epsilon : float</span>
</span><span id="MLPRegressor-59"><a href="#MLPRegressor-59"><span class="linenos"> 59</span></a><span class="sd">            Value to avoid division by zero</span>
</span><span id="MLPRegressor-60"><a href="#MLPRegressor-60"><span class="linenos"> 60</span></a><span class="sd">        momentum : float</span>
</span><span id="MLPRegressor-61"><a href="#MLPRegressor-61"><span class="linenos"> 61</span></a><span class="sd">            Parameter for momentum optimizer</span>
</span><span id="MLPRegressor-62"><a href="#MLPRegressor-62"><span class="linenos"> 62</span></a><span class="sd">        tol : float</span>
</span><span id="MLPRegressor-63"><a href="#MLPRegressor-63"><span class="linenos"> 63</span></a><span class="sd">            Tolerance for early stopping</span>
</span><span id="MLPRegressor-64"><a href="#MLPRegressor-64"><span class="linenos"> 64</span></a><span class="sd">        early_stopping : bool</span>
</span><span id="MLPRegressor-65"><a href="#MLPRegressor-65"><span class="linenos"> 65</span></a><span class="sd">            If True, use early stopping based on validation</span>
</span><span id="MLPRegressor-66"><a href="#MLPRegressor-66"><span class="linenos"> 66</span></a><span class="sd">        validation_fraction : float</span>
</span><span id="MLPRegressor-67"><a href="#MLPRegressor-67"><span class="linenos"> 67</span></a><span class="sd">            Fraction of training data to use as validation</span>
</span><span id="MLPRegressor-68"><a href="#MLPRegressor-68"><span class="linenos"> 68</span></a><span class="sd">        n_iter_no_change : int</span>
</span><span id="MLPRegressor-69"><a href="#MLPRegressor-69"><span class="linenos"> 69</span></a><span class="sd">            Number of iterations with no improvement for early stopping</span>
</span><span id="MLPRegressor-70"><a href="#MLPRegressor-70"><span class="linenos"> 70</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-71"><a href="#MLPRegressor-71"><span class="linenos"> 71</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_sizes</span> <span class="o">=</span> <span class="n">hidden_layer_sizes</span>
</span><span id="MLPRegressor-72"><a href="#MLPRegressor-72"><span class="linenos"> 72</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
</span><span id="MLPRegressor-73"><a href="#MLPRegressor-73"><span class="linenos"> 73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">=</span> <span class="n">solver</span>
</span><span id="MLPRegressor-74"><a href="#MLPRegressor-74"><span class="linenos"> 74</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
</span><span id="MLPRegressor-75"><a href="#MLPRegressor-75"><span class="linenos"> 75</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
</span><span id="MLPRegressor-76"><a href="#MLPRegressor-76"><span class="linenos"> 76</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
</span><span id="MLPRegressor-77"><a href="#MLPRegressor-77"><span class="linenos"> 77</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
</span><span id="MLPRegressor-78"><a href="#MLPRegressor-78"><span class="linenos"> 78</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span>
</span><span id="MLPRegressor-79"><a href="#MLPRegressor-79"><span class="linenos"> 79</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">=</span> <span class="n">beta1</span>
</span><span id="MLPRegressor-80"><a href="#MLPRegressor-80"><span class="linenos"> 80</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">=</span> <span class="n">beta2</span>
</span><span id="MLPRegressor-81"><a href="#MLPRegressor-81"><span class="linenos"> 81</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
</span><span id="MLPRegressor-82"><a href="#MLPRegressor-82"><span class="linenos"> 82</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
</span><span id="MLPRegressor-83"><a href="#MLPRegressor-83"><span class="linenos"> 83</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
</span><span id="MLPRegressor-84"><a href="#MLPRegressor-84"><span class="linenos"> 84</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping</span> <span class="o">=</span> <span class="n">early_stopping</span>
</span><span id="MLPRegressor-85"><a href="#MLPRegressor-85"><span class="linenos"> 85</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">validation_fraction</span> <span class="o">=</span> <span class="n">validation_fraction</span>
</span><span id="MLPRegressor-86"><a href="#MLPRegressor-86"><span class="linenos"> 86</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span> <span class="o">=</span> <span class="n">n_iter_no_change</span>
</span><span id="MLPRegressor-87"><a href="#MLPRegressor-87"><span class="linenos"> 87</span></a>        
</span><span id="MLPRegressor-88"><a href="#MLPRegressor-88"><span class="linenos"> 88</span></a>        <span class="k">if</span> <span class="n">random_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="MLPRegressor-89"><a href="#MLPRegressor-89"><span class="linenos"> 89</span></a>            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
</span><span id="MLPRegressor-90"><a href="#MLPRegressor-90"><span class="linenos"> 90</span></a>        
</span><span id="MLPRegressor-91"><a href="#MLPRegressor-91"><span class="linenos"> 91</span></a>        <span class="c1"># Selection of activation functions</span>
</span><span id="MLPRegressor-92"><a href="#MLPRegressor-92"><span class="linenos"> 92</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation_functions</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="MLPRegressor-93"><a href="#MLPRegressor-93"><span class="linenos"> 93</span></a>            <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid</span><span class="p">,</span>
</span><span id="MLPRegressor-94"><a href="#MLPRegressor-94"><span class="linenos"> 94</span></a>            <span class="s1">&#39;relu&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">,</span>
</span><span id="MLPRegressor-95"><a href="#MLPRegressor-95"><span class="linenos"> 95</span></a>            <span class="s1">&#39;tanh&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tanh</span><span class="p">,</span>
</span><span id="MLPRegressor-96"><a href="#MLPRegressor-96"><span class="linenos"> 96</span></a>            <span class="s1">&#39;leaky_relu&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaky_relu</span><span class="p">,</span>
</span><span id="MLPRegressor-97"><a href="#MLPRegressor-97"><span class="linenos"> 97</span></a>        <span class="p">}</span>
</span><span id="MLPRegressor-98"><a href="#MLPRegressor-98"><span class="linenos"> 98</span></a>        
</span><span id="MLPRegressor-99"><a href="#MLPRegressor-99"><span class="linenos"> 99</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation_derivatives</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="MLPRegressor-100"><a href="#MLPRegressor-100"><span class="linenos">100</span></a>            <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid_derivative</span><span class="p">,</span>
</span><span id="MLPRegressor-101"><a href="#MLPRegressor-101"><span class="linenos">101</span></a>            <span class="s1">&#39;relu&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu_derivative</span><span class="p">,</span>
</span><span id="MLPRegressor-102"><a href="#MLPRegressor-102"><span class="linenos">102</span></a>            <span class="s1">&#39;tanh&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tanh_derivative</span><span class="p">,</span>
</span><span id="MLPRegressor-103"><a href="#MLPRegressor-103"><span class="linenos">103</span></a>            <span class="s1">&#39;leaky_relu&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaky_relu_derivative</span><span class="p">,</span>
</span><span id="MLPRegressor-104"><a href="#MLPRegressor-104"><span class="linenos">104</span></a>        <span class="p">}</span>
</span><span id="MLPRegressor-105"><a href="#MLPRegressor-105"><span class="linenos">105</span></a>        
</span><span id="MLPRegressor-106"><a href="#MLPRegressor-106"><span class="linenos">106</span></a>        <span class="c1"># Selection of activation function and its derivative</span>
</span><span id="MLPRegressor-107"><a href="#MLPRegressor-107"><span class="linenos">107</span></a>        <span class="k">if</span> <span class="n">activation</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_functions</span><span class="p">:</span>
</span><span id="MLPRegressor-108"><a href="#MLPRegressor-108"><span class="linenos">108</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Activation &#39;</span><span class="si">{</span><span class="n">activation</span><span class="si">}</span><span class="s2">&#39; not recognized. Use &#39;sigmoid&#39;, &#39;relu&#39;, &#39;tanh&#39; or &#39;leaky_relu&#39;.&quot;</span><span class="p">)</span>
</span><span id="MLPRegressor-109"><a href="#MLPRegressor-109"><span class="linenos">109</span></a>        
</span><span id="MLPRegressor-110"><a href="#MLPRegressor-110"><span class="linenos">110</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_functions</span><span class="p">[</span><span class="n">activation</span><span class="p">]</span>
</span><span id="MLPRegressor-111"><a href="#MLPRegressor-111"><span class="linenos">111</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation_derivative</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_derivatives</span><span class="p">[</span><span class="n">activation</span><span class="p">]</span>
</span><span id="MLPRegressor-112"><a href="#MLPRegressor-112"><span class="linenos">112</span></a>        
</span><span id="MLPRegressor-113"><a href="#MLPRegressor-113"><span class="linenos">113</span></a>        <span class="c1"># Initialization of weights</span>
</span><span id="MLPRegressor-114"><a href="#MLPRegressor-114"><span class="linenos">114</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-115"><a href="#MLPRegressor-115"><span class="linenos">115</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-116"><a href="#MLPRegressor-116"><span class="linenos">116</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="MLPRegressor-117"><a href="#MLPRegressor-117"><span class="linenos">117</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="MLPRegressor-118"><a href="#MLPRegressor-118"><span class="linenos">118</span></a>        
</span><span id="MLPRegressor-119"><a href="#MLPRegressor-119"><span class="linenos">119</span></a>        <span class="c1"># For optimizers</span>
</span><span id="MLPRegressor-120"><a href="#MLPRegressor-120"><span class="linenos">120</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">velocity_weights</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># For Momentum</span>
</span><span id="MLPRegressor-121"><a href="#MLPRegressor-121"><span class="linenos">121</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">velocity_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-122"><a href="#MLPRegressor-122"><span class="linenos">122</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">m_weights</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># For Adam</span>
</span><span id="MLPRegressor-123"><a href="#MLPRegressor-123"><span class="linenos">123</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">m_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-124"><a href="#MLPRegressor-124"><span class="linenos">124</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># For Adam</span>
</span><span id="MLPRegressor-125"><a href="#MLPRegressor-125"><span class="linenos">125</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-126"><a href="#MLPRegressor-126"><span class="linenos">126</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Timestep for Adam</span>
</span><span id="MLPRegressor-127"><a href="#MLPRegressor-127"><span class="linenos">127</span></a>        
</span><span id="MLPRegressor-128"><a href="#MLPRegressor-128"><span class="linenos">128</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-129"><a href="#MLPRegressor-129"><span class="linenos">129</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-130"><a href="#MLPRegressor-130"><span class="linenos">130</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</span><span id="MLPRegressor-131"><a href="#MLPRegressor-131"><span class="linenos">131</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="MLPRegressor-132"><a href="#MLPRegressor-132"><span class="linenos">132</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">trained</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="MLPRegressor-133"><a href="#MLPRegressor-133"><span class="linenos">133</span></a>    
</span><span id="MLPRegressor-134"><a href="#MLPRegressor-134"><span class="linenos">134</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_initialize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="MLPRegressor-135"><a href="#MLPRegressor-135"><span class="linenos">135</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-136"><a href="#MLPRegressor-136"><span class="linenos">136</span></a><span class="sd">        Initialize the weights and biases of the network</span>
</span><span id="MLPRegressor-137"><a href="#MLPRegressor-137"><span class="linenos">137</span></a><span class="sd">        </span>
</span><span id="MLPRegressor-138"><a href="#MLPRegressor-138"><span class="linenos">138</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPRegressor-139"><a href="#MLPRegressor-139"><span class="linenos">139</span></a><span class="sd">        -----------</span>
</span><span id="MLPRegressor-140"><a href="#MLPRegressor-140"><span class="linenos">140</span></a><span class="sd">        n_features : int</span>
</span><span id="MLPRegressor-141"><a href="#MLPRegressor-141"><span class="linenos">141</span></a><span class="sd">            Number of input features</span>
</span><span id="MLPRegressor-142"><a href="#MLPRegressor-142"><span class="linenos">142</span></a><span class="sd">        n_outputs : int</span>
</span><span id="MLPRegressor-143"><a href="#MLPRegressor-143"><span class="linenos">143</span></a><span class="sd">            Number of output targets</span>
</span><span id="MLPRegressor-144"><a href="#MLPRegressor-144"><span class="linenos">144</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-145"><a href="#MLPRegressor-145"><span class="linenos">145</span></a>        <span class="c1"># Layer dimensions</span>
</span><span id="MLPRegressor-146"><a href="#MLPRegressor-146"><span class="linenos">146</span></a>        <span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_features</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_sizes</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">n_outputs</span><span class="p">]</span>
</span><span id="MLPRegressor-147"><a href="#MLPRegressor-147"><span class="linenos">147</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="MLPRegressor-148"><a href="#MLPRegressor-148"><span class="linenos">148</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span> <span class="o">=</span> <span class="n">n_outputs</span>
</span><span id="MLPRegressor-149"><a href="#MLPRegressor-149"><span class="linenos">149</span></a>        
</span><span id="MLPRegressor-150"><a href="#MLPRegressor-150"><span class="linenos">150</span></a>        <span class="c1"># Reset lists</span>
</span><span id="MLPRegressor-151"><a href="#MLPRegressor-151"><span class="linenos">151</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-152"><a href="#MLPRegressor-152"><span class="linenos">152</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-153"><a href="#MLPRegressor-153"><span class="linenos">153</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">velocity_weights</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-154"><a href="#MLPRegressor-154"><span class="linenos">154</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">velocity_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-155"><a href="#MLPRegressor-155"><span class="linenos">155</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">m_weights</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-156"><a href="#MLPRegressor-156"><span class="linenos">156</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">m_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-157"><a href="#MLPRegressor-157"><span class="linenos">157</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-158"><a href="#MLPRegressor-158"><span class="linenos">158</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-159"><a href="#MLPRegressor-159"><span class="linenos">159</span></a>        
</span><span id="MLPRegressor-160"><a href="#MLPRegressor-160"><span class="linenos">160</span></a>        <span class="c1"># Initialize weights with Xavier/Glorot method</span>
</span><span id="MLPRegressor-161"><a href="#MLPRegressor-161"><span class="linenos">161</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="MLPRegressor-162"><a href="#MLPRegressor-162"><span class="linenos">162</span></a>            <span class="n">limit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">6</span> <span class="o">/</span> <span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]))</span>
</span><span id="MLPRegressor-163"><a href="#MLPRegressor-163"><span class="linenos">163</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">limit</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])))</span>
</span><span id="MLPRegressor-164"><a href="#MLPRegressor-164"><span class="linenos">164</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]))</span>
</span><span id="MLPRegressor-165"><a href="#MLPRegressor-165"><span class="linenos">165</span></a>            
</span><span id="MLPRegressor-166"><a href="#MLPRegressor-166"><span class="linenos">166</span></a>            <span class="c1"># Initialization for optimizers</span>
</span><span id="MLPRegressor-167"><a href="#MLPRegressor-167"><span class="linenos">167</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">velocity_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>  <span class="c1"># For Momentum</span>
</span><span id="MLPRegressor-168"><a href="#MLPRegressor-168"><span class="linenos">168</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">velocity_biases</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</span><span id="MLPRegressor-169"><a href="#MLPRegressor-169"><span class="linenos">169</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">m_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>  <span class="c1"># For Adam</span>
</span><span id="MLPRegressor-170"><a href="#MLPRegressor-170"><span class="linenos">170</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">m_biases</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</span><span id="MLPRegressor-171"><a href="#MLPRegressor-171"><span class="linenos">171</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>  <span class="c1"># For Adam</span>
</span><span id="MLPRegressor-172"><a href="#MLPRegressor-172"><span class="linenos">172</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</span><span id="MLPRegressor-173"><a href="#MLPRegressor-173"><span class="linenos">173</span></a>    
</span><span id="MLPRegressor-174"><a href="#MLPRegressor-174"><span class="linenos">174</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_leaky_relu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPRegressor-175"><a href="#MLPRegressor-175"><span class="linenos">175</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-176"><a href="#MLPRegressor-176"><span class="linenos">176</span></a><span class="sd">        Leaky ReLU activation function</span>
</span><span id="MLPRegressor-177"><a href="#MLPRegressor-177"><span class="linenos">177</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-178"><a href="#MLPRegressor-178"><span class="linenos">178</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
</span><span id="MLPRegressor-179"><a href="#MLPRegressor-179"><span class="linenos">179</span></a>    
</span><span id="MLPRegressor-180"><a href="#MLPRegressor-180"><span class="linenos">180</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_leaky_relu_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPRegressor-181"><a href="#MLPRegressor-181"><span class="linenos">181</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-182"><a href="#MLPRegressor-182"><span class="linenos">182</span></a><span class="sd">        Derivative of Leaky ReLU function</span>
</span><span id="MLPRegressor-183"><a href="#MLPRegressor-183"><span class="linenos">183</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-184"><a href="#MLPRegressor-184"><span class="linenos">184</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
</span><span id="MLPRegressor-185"><a href="#MLPRegressor-185"><span class="linenos">185</span></a>    
</span><span id="MLPRegressor-186"><a href="#MLPRegressor-186"><span class="linenos">186</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPRegressor-187"><a href="#MLPRegressor-187"><span class="linenos">187</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-188"><a href="#MLPRegressor-188"><span class="linenos">188</span></a><span class="sd">        Sigmoid activation function</span>
</span><span id="MLPRegressor-189"><a href="#MLPRegressor-189"><span class="linenos">189</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-190"><a href="#MLPRegressor-190"><span class="linenos">190</span></a>        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">)))</span>
</span><span id="MLPRegressor-191"><a href="#MLPRegressor-191"><span class="linenos">191</span></a>    
</span><span id="MLPRegressor-192"><a href="#MLPRegressor-192"><span class="linenos">192</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_sigmoid_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPRegressor-193"><a href="#MLPRegressor-193"><span class="linenos">193</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-194"><a href="#MLPRegressor-194"><span class="linenos">194</span></a><span class="sd">        Derivative of sigmoid function</span>
</span><span id="MLPRegressor-195"><a href="#MLPRegressor-195"><span class="linenos">195</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-196"><a href="#MLPRegressor-196"><span class="linenos">196</span></a>        <span class="n">sigmoid_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="MLPRegressor-197"><a href="#MLPRegressor-197"><span class="linenos">197</span></a>        <span class="k">return</span> <span class="n">sigmoid_x</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigmoid_x</span><span class="p">)</span>
</span><span id="MLPRegressor-198"><a href="#MLPRegressor-198"><span class="linenos">198</span></a>    
</span><span id="MLPRegressor-199"><a href="#MLPRegressor-199"><span class="linenos">199</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_relu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPRegressor-200"><a href="#MLPRegressor-200"><span class="linenos">200</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-201"><a href="#MLPRegressor-201"><span class="linenos">201</span></a><span class="sd">        ReLU activation function</span>
</span><span id="MLPRegressor-202"><a href="#MLPRegressor-202"><span class="linenos">202</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-203"><a href="#MLPRegressor-203"><span class="linenos">203</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</span><span id="MLPRegressor-204"><a href="#MLPRegressor-204"><span class="linenos">204</span></a>    
</span><span id="MLPRegressor-205"><a href="#MLPRegressor-205"><span class="linenos">205</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_relu_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPRegressor-206"><a href="#MLPRegressor-206"><span class="linenos">206</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-207"><a href="#MLPRegressor-207"><span class="linenos">207</span></a><span class="sd">        Derivative of ReLU function</span>
</span><span id="MLPRegressor-208"><a href="#MLPRegressor-208"><span class="linenos">208</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-209"><a href="#MLPRegressor-209"><span class="linenos">209</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span id="MLPRegressor-210"><a href="#MLPRegressor-210"><span class="linenos">210</span></a>    
</span><span id="MLPRegressor-211"><a href="#MLPRegressor-211"><span class="linenos">211</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_tanh</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPRegressor-212"><a href="#MLPRegressor-212"><span class="linenos">212</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-213"><a href="#MLPRegressor-213"><span class="linenos">213</span></a><span class="sd">        Tanh activation function</span>
</span><span id="MLPRegressor-214"><a href="#MLPRegressor-214"><span class="linenos">214</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-215"><a href="#MLPRegressor-215"><span class="linenos">215</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="MLPRegressor-216"><a href="#MLPRegressor-216"><span class="linenos">216</span></a>    
</span><span id="MLPRegressor-217"><a href="#MLPRegressor-217"><span class="linenos">217</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_tanh_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPRegressor-218"><a href="#MLPRegressor-218"><span class="linenos">218</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-219"><a href="#MLPRegressor-219"><span class="linenos">219</span></a><span class="sd">        Derivative of tanh function</span>
</span><span id="MLPRegressor-220"><a href="#MLPRegressor-220"><span class="linenos">220</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-221"><a href="#MLPRegressor-221"><span class="linenos">221</span></a>        <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="MLPRegressor-222"><a href="#MLPRegressor-222"><span class="linenos">222</span></a>    
</span><span id="MLPRegressor-223"><a href="#MLPRegressor-223"><span class="linenos">223</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_forward_pass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
</span><span id="MLPRegressor-224"><a href="#MLPRegressor-224"><span class="linenos">224</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-225"><a href="#MLPRegressor-225"><span class="linenos">225</span></a><span class="sd">        Forward propagation to calculate activations</span>
</span><span id="MLPRegressor-226"><a href="#MLPRegressor-226"><span class="linenos">226</span></a><span class="sd">        </span>
</span><span id="MLPRegressor-227"><a href="#MLPRegressor-227"><span class="linenos">227</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPRegressor-228"><a href="#MLPRegressor-228"><span class="linenos">228</span></a><span class="sd">        -----------</span>
</span><span id="MLPRegressor-229"><a href="#MLPRegressor-229"><span class="linenos">229</span></a><span class="sd">        X : np.ndarray, shape (n_samples, n_features)</span>
</span><span id="MLPRegressor-230"><a href="#MLPRegressor-230"><span class="linenos">230</span></a><span class="sd">            Input data</span>
</span><span id="MLPRegressor-231"><a href="#MLPRegressor-231"><span class="linenos">231</span></a><span class="sd">            </span>
</span><span id="MLPRegressor-232"><a href="#MLPRegressor-232"><span class="linenos">232</span></a><span class="sd">        Returns:</span>
</span><span id="MLPRegressor-233"><a href="#MLPRegressor-233"><span class="linenos">233</span></a><span class="sd">        --------</span>
</span><span id="MLPRegressor-234"><a href="#MLPRegressor-234"><span class="linenos">234</span></a><span class="sd">        activations : List of activations for each layer</span>
</span><span id="MLPRegressor-235"><a href="#MLPRegressor-235"><span class="linenos">235</span></a><span class="sd">        layer_inputs : List of inputs for each layer (before activation)</span>
</span><span id="MLPRegressor-236"><a href="#MLPRegressor-236"><span class="linenos">236</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-237"><a href="#MLPRegressor-237"><span class="linenos">237</span></a>        <span class="n">activations</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="p">]</span>
</span><span id="MLPRegressor-238"><a href="#MLPRegressor-238"><span class="linenos">238</span></a>        <span class="n">layer_inputs</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-239"><a href="#MLPRegressor-239"><span class="linenos">239</span></a>        
</span><span id="MLPRegressor-240"><a href="#MLPRegressor-240"><span class="linenos">240</span></a>        <span class="c1"># Pass through all layers except the last one</span>
</span><span id="MLPRegressor-241"><a href="#MLPRegressor-241"><span class="linenos">241</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="MLPRegressor-242"><a href="#MLPRegressor-242"><span class="linenos">242</span></a>            <span class="n">layer_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPRegressor-243"><a href="#MLPRegressor-243"><span class="linenos">243</span></a>            <span class="n">layer_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer_input</span><span class="p">)</span>
</span><span id="MLPRegressor-244"><a href="#MLPRegressor-244"><span class="linenos">244</span></a>            <span class="n">activation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_func</span><span class="p">(</span><span class="n">layer_input</span><span class="p">)</span>
</span><span id="MLPRegressor-245"><a href="#MLPRegressor-245"><span class="linenos">245</span></a>            <span class="n">activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
</span><span id="MLPRegressor-246"><a href="#MLPRegressor-246"><span class="linenos">246</span></a>        
</span><span id="MLPRegressor-247"><a href="#MLPRegressor-247"><span class="linenos">247</span></a>        <span class="c1"># Output layer (linear activation for regression)</span>
</span><span id="MLPRegressor-248"><a href="#MLPRegressor-248"><span class="linenos">248</span></a>        <span class="n">last_layer_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="MLPRegressor-249"><a href="#MLPRegressor-249"><span class="linenos">249</span></a>        <span class="n">layer_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">last_layer_input</span><span class="p">)</span>
</span><span id="MLPRegressor-250"><a href="#MLPRegressor-250"><span class="linenos">250</span></a>        
</span><span id="MLPRegressor-251"><a href="#MLPRegressor-251"><span class="linenos">251</span></a>        <span class="c1"># Linear output for regression (no activation function)</span>
</span><span id="MLPRegressor-252"><a href="#MLPRegressor-252"><span class="linenos">252</span></a>        <span class="n">output_activation</span> <span class="o">=</span> <span class="n">last_layer_input</span>
</span><span id="MLPRegressor-253"><a href="#MLPRegressor-253"><span class="linenos">253</span></a>        <span class="n">activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_activation</span><span class="p">)</span>
</span><span id="MLPRegressor-254"><a href="#MLPRegressor-254"><span class="linenos">254</span></a>        
</span><span id="MLPRegressor-255"><a href="#MLPRegressor-255"><span class="linenos">255</span></a>        <span class="k">return</span> <span class="n">activations</span><span class="p">,</span> <span class="n">layer_inputs</span>
</span><span id="MLPRegressor-256"><a href="#MLPRegressor-256"><span class="linenos">256</span></a>    
</span><span id="MLPRegressor-257"><a href="#MLPRegressor-257"><span class="linenos">257</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_true</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span><span id="MLPRegressor-258"><a href="#MLPRegressor-258"><span class="linenos">258</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-259"><a href="#MLPRegressor-259"><span class="linenos">259</span></a><span class="sd">        Calculate mean squared error with L2 regularization</span>
</span><span id="MLPRegressor-260"><a href="#MLPRegressor-260"><span class="linenos">260</span></a><span class="sd">        </span>
</span><span id="MLPRegressor-261"><a href="#MLPRegressor-261"><span class="linenos">261</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPRegressor-262"><a href="#MLPRegressor-262"><span class="linenos">262</span></a><span class="sd">        -----------</span>
</span><span id="MLPRegressor-263"><a href="#MLPRegressor-263"><span class="linenos">263</span></a><span class="sd">        y_true : np.ndarray, shape (n_samples, n_outputs)</span>
</span><span id="MLPRegressor-264"><a href="#MLPRegressor-264"><span class="linenos">264</span></a><span class="sd">            True target values</span>
</span><span id="MLPRegressor-265"><a href="#MLPRegressor-265"><span class="linenos">265</span></a><span class="sd">        y_pred : np.ndarray, shape (n_samples, n_outputs)</span>
</span><span id="MLPRegressor-266"><a href="#MLPRegressor-266"><span class="linenos">266</span></a><span class="sd">            Predicted values</span>
</span><span id="MLPRegressor-267"><a href="#MLPRegressor-267"><span class="linenos">267</span></a><span class="sd">            </span>
</span><span id="MLPRegressor-268"><a href="#MLPRegressor-268"><span class="linenos">268</span></a><span class="sd">        Returns:</span>
</span><span id="MLPRegressor-269"><a href="#MLPRegressor-269"><span class="linenos">269</span></a><span class="sd">        --------</span>
</span><span id="MLPRegressor-270"><a href="#MLPRegressor-270"><span class="linenos">270</span></a><span class="sd">        loss : float</span>
</span><span id="MLPRegressor-271"><a href="#MLPRegressor-271"><span class="linenos">271</span></a><span class="sd">            Loss value</span>
</span><span id="MLPRegressor-272"><a href="#MLPRegressor-272"><span class="linenos">272</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-273"><a href="#MLPRegressor-273"><span class="linenos">273</span></a>        <span class="n">m</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="MLPRegressor-274"><a href="#MLPRegressor-274"><span class="linenos">274</span></a>        <span class="c1"># Mean squared error</span>
</span><span id="MLPRegressor-275"><a href="#MLPRegressor-275"><span class="linenos">275</span></a>        <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">))</span>
</span><span id="MLPRegressor-276"><a href="#MLPRegressor-276"><span class="linenos">276</span></a>        
</span><span id="MLPRegressor-277"><a href="#MLPRegressor-277"><span class="linenos">277</span></a>        <span class="c1"># L2 regularization</span>
</span><span id="MLPRegressor-278"><a href="#MLPRegressor-278"><span class="linenos">278</span></a>        <span class="n">l2_reg</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="MLPRegressor-279"><a href="#MLPRegressor-279"><span class="linenos">279</span></a>        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">:</span>
</span><span id="MLPRegressor-280"><a href="#MLPRegressor-280"><span class="linenos">280</span></a>            <span class="n">l2_reg</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>
</span><span id="MLPRegressor-281"><a href="#MLPRegressor-281"><span class="linenos">281</span></a>        <span class="n">l2_reg</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">)</span>
</span><span id="MLPRegressor-282"><a href="#MLPRegressor-282"><span class="linenos">282</span></a>        
</span><span id="MLPRegressor-283"><a href="#MLPRegressor-283"><span class="linenos">283</span></a>        <span class="k">return</span> <span class="n">mse</span> <span class="o">+</span> <span class="n">l2_reg</span>
</span><span id="MLPRegressor-284"><a href="#MLPRegressor-284"><span class="linenos">284</span></a>    
</span><span id="MLPRegressor-285"><a href="#MLPRegressor-285"><span class="linenos">285</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_backward_pass</span><span class="p">(</span>
</span><span id="MLPRegressor-286"><a href="#MLPRegressor-286"><span class="linenos">286</span></a>        <span class="bp">self</span><span class="p">,</span> 
</span><span id="MLPRegressor-287"><a href="#MLPRegressor-287"><span class="linenos">287</span></a>        <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
</span><span id="MLPRegressor-288"><a href="#MLPRegressor-288"><span class="linenos">288</span></a>        <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
</span><span id="MLPRegressor-289"><a href="#MLPRegressor-289"><span class="linenos">289</span></a>        <span class="n">activations</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> 
</span><span id="MLPRegressor-290"><a href="#MLPRegressor-290"><span class="linenos">290</span></a>        <span class="n">layer_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span>
</span><span id="MLPRegressor-291"><a href="#MLPRegressor-291"><span class="linenos">291</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
</span><span id="MLPRegressor-292"><a href="#MLPRegressor-292"><span class="linenos">292</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-293"><a href="#MLPRegressor-293"><span class="linenos">293</span></a><span class="sd">        Backpropagation of gradient</span>
</span><span id="MLPRegressor-294"><a href="#MLPRegressor-294"><span class="linenos">294</span></a><span class="sd">        </span>
</span><span id="MLPRegressor-295"><a href="#MLPRegressor-295"><span class="linenos">295</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPRegressor-296"><a href="#MLPRegressor-296"><span class="linenos">296</span></a><span class="sd">        -----------</span>
</span><span id="MLPRegressor-297"><a href="#MLPRegressor-297"><span class="linenos">297</span></a><span class="sd">        X : np.ndarray</span>
</span><span id="MLPRegressor-298"><a href="#MLPRegressor-298"><span class="linenos">298</span></a><span class="sd">            Input data</span>
</span><span id="MLPRegressor-299"><a href="#MLPRegressor-299"><span class="linenos">299</span></a><span class="sd">        y : np.ndarray</span>
</span><span id="MLPRegressor-300"><a href="#MLPRegressor-300"><span class="linenos">300</span></a><span class="sd">            Target values</span>
</span><span id="MLPRegressor-301"><a href="#MLPRegressor-301"><span class="linenos">301</span></a><span class="sd">        activations : List of activations for each layer</span>
</span><span id="MLPRegressor-302"><a href="#MLPRegressor-302"><span class="linenos">302</span></a><span class="sd">        layer_inputs : List of inputs for each layer</span>
</span><span id="MLPRegressor-303"><a href="#MLPRegressor-303"><span class="linenos">303</span></a><span class="sd">            </span>
</span><span id="MLPRegressor-304"><a href="#MLPRegressor-304"><span class="linenos">304</span></a><span class="sd">        Returns:</span>
</span><span id="MLPRegressor-305"><a href="#MLPRegressor-305"><span class="linenos">305</span></a><span class="sd">        --------</span>
</span><span id="MLPRegressor-306"><a href="#MLPRegressor-306"><span class="linenos">306</span></a><span class="sd">        gradients_w : List of gradients for weights</span>
</span><span id="MLPRegressor-307"><a href="#MLPRegressor-307"><span class="linenos">307</span></a><span class="sd">        gradients_b : List of gradients for biases</span>
</span><span id="MLPRegressor-308"><a href="#MLPRegressor-308"><span class="linenos">308</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-309"><a href="#MLPRegressor-309"><span class="linenos">309</span></a>        <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="MLPRegressor-310"><a href="#MLPRegressor-310"><span class="linenos">310</span></a>        <span class="n">gradients_w</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span>
</span><span id="MLPRegressor-311"><a href="#MLPRegressor-311"><span class="linenos">311</span></a>        <span class="n">gradients_b</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span>
</span><span id="MLPRegressor-312"><a href="#MLPRegressor-312"><span class="linenos">312</span></a>        
</span><span id="MLPRegressor-313"><a href="#MLPRegressor-313"><span class="linenos">313</span></a>        <span class="c1"># Gradient of output layer (derivative of MSE)</span>
</span><span id="MLPRegressor-314"><a href="#MLPRegressor-314"><span class="linenos">314</span></a>        <span class="n">delta</span> <span class="o">=</span> <span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span>  <span class="c1"># Factor of 2 from derivative of square</span>
</span><span id="MLPRegressor-315"><a href="#MLPRegressor-315"><span class="linenos">315</span></a>        
</span><span id="MLPRegressor-316"><a href="#MLPRegressor-316"><span class="linenos">316</span></a>        <span class="c1"># Backpropagate gradient through layers</span>
</span><span id="MLPRegressor-317"><a href="#MLPRegressor-317"><span class="linenos">317</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
</span><span id="MLPRegressor-318"><a href="#MLPRegressor-318"><span class="linenos">318</span></a>            <span class="c1"># Calculate gradient for weights and biases of layer i</span>
</span><span id="MLPRegressor-319"><a href="#MLPRegressor-319"><span class="linenos">319</span></a>            <span class="n">gradients_w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">delta</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPRegressor-320"><a href="#MLPRegressor-320"><span class="linenos">320</span></a>            <span class="n">gradients_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="MLPRegressor-321"><a href="#MLPRegressor-321"><span class="linenos">321</span></a>            
</span><span id="MLPRegressor-322"><a href="#MLPRegressor-322"><span class="linenos">322</span></a>            <span class="c1"># Backpropagate delta (except for first layer)</span>
</span><span id="MLPRegressor-323"><a href="#MLPRegressor-323"><span class="linenos">323</span></a>            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="MLPRegressor-324"><a href="#MLPRegressor-324"><span class="linenos">324</span></a>                <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span><span id="MLPRegressor-325"><a href="#MLPRegressor-325"><span class="linenos">325</span></a>                <span class="c1"># For other layers, apply the derivative of the activation function</span>
</span><span id="MLPRegressor-326"><a href="#MLPRegressor-326"><span class="linenos">326</span></a>                <span class="n">delta</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_derivative</span><span class="p">(</span><span class="n">layer_inputs</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="MLPRegressor-327"><a href="#MLPRegressor-327"><span class="linenos">327</span></a>        
</span><span id="MLPRegressor-328"><a href="#MLPRegressor-328"><span class="linenos">328</span></a>        <span class="k">return</span> <span class="n">gradients_w</span><span class="p">,</span> <span class="n">gradients_b</span>
</span><span id="MLPRegressor-329"><a href="#MLPRegressor-329"><span class="linenos">329</span></a>    
</span><span id="MLPRegressor-330"><a href="#MLPRegressor-330"><span class="linenos">330</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_update_weights_sgd</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients_w</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">gradients_b</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="MLPRegressor-331"><a href="#MLPRegressor-331"><span class="linenos">331</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-332"><a href="#MLPRegressor-332"><span class="linenos">332</span></a><span class="sd">        Update weights with stochastic gradient descent</span>
</span><span id="MLPRegressor-333"><a href="#MLPRegressor-333"><span class="linenos">333</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-334"><a href="#MLPRegressor-334"><span class="linenos">334</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="MLPRegressor-335"><a href="#MLPRegressor-335"><span class="linenos">335</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients_w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPRegressor-336"><a href="#MLPRegressor-336"><span class="linenos">336</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPRegressor-337"><a href="#MLPRegressor-337"><span class="linenos">337</span></a>    
</span><span id="MLPRegressor-338"><a href="#MLPRegressor-338"><span class="linenos">338</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_update_weights_momentum</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients_w</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">gradients_b</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="MLPRegressor-339"><a href="#MLPRegressor-339"><span class="linenos">339</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-340"><a href="#MLPRegressor-340"><span class="linenos">340</span></a><span class="sd">        Update weights with momentum gradient descent</span>
</span><span id="MLPRegressor-341"><a href="#MLPRegressor-341"><span class="linenos">341</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-342"><a href="#MLPRegressor-342"><span class="linenos">342</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="MLPRegressor-343"><a href="#MLPRegressor-343"><span class="linenos">343</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">velocity_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">velocity_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients_w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPRegressor-344"><a href="#MLPRegressor-344"><span class="linenos">344</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">velocity_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">velocity_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPRegressor-345"><a href="#MLPRegressor-345"><span class="linenos">345</span></a>            
</span><span id="MLPRegressor-346"><a href="#MLPRegressor-346"><span class="linenos">346</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">velocity_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPRegressor-347"><a href="#MLPRegressor-347"><span class="linenos">347</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">velocity_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPRegressor-348"><a href="#MLPRegressor-348"><span class="linenos">348</span></a>    
</span><span id="MLPRegressor-349"><a href="#MLPRegressor-349"><span class="linenos">349</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_update_weights_rmsprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients_w</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">gradients_b</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="MLPRegressor-350"><a href="#MLPRegressor-350"><span class="linenos">350</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-351"><a href="#MLPRegressor-351"><span class="linenos">351</span></a><span class="sd">        Update weights with RMSProp</span>
</span><span id="MLPRegressor-352"><a href="#MLPRegressor-352"><span class="linenos">352</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-353"><a href="#MLPRegressor-353"><span class="linenos">353</span></a>        <span class="n">decay_rate</span> <span class="o">=</span> <span class="mf">0.9</span>
</span><span id="MLPRegressor-354"><a href="#MLPRegressor-354"><span class="linenos">354</span></a>        
</span><span id="MLPRegressor-355"><a href="#MLPRegressor-355"><span class="linenos">355</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="MLPRegressor-356"><a href="#MLPRegressor-356"><span class="linenos">356</span></a>            <span class="c1"># Update accumulators</span>
</span><span id="MLPRegressor-357"><a href="#MLPRegressor-357"><span class="linenos">357</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">decay_rate</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">decay_rate</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">gradients_w</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="MLPRegressor-358"><a href="#MLPRegressor-358"><span class="linenos">358</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">decay_rate</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">decay_rate</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">gradients_b</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="MLPRegressor-359"><a href="#MLPRegressor-359"><span class="linenos">359</span></a>            
</span><span id="MLPRegressor-360"><a href="#MLPRegressor-360"><span class="linenos">360</span></a>            <span class="c1"># Update weights</span>
</span><span id="MLPRegressor-361"><a href="#MLPRegressor-361"><span class="linenos">361</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients_w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">))</span>
</span><span id="MLPRegressor-362"><a href="#MLPRegressor-362"><span class="linenos">362</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">))</span>
</span><span id="MLPRegressor-363"><a href="#MLPRegressor-363"><span class="linenos">363</span></a>    
</span><span id="MLPRegressor-364"><a href="#MLPRegressor-364"><span class="linenos">364</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_update_weights_adam</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients_w</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">gradients_b</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="MLPRegressor-365"><a href="#MLPRegressor-365"><span class="linenos">365</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-366"><a href="#MLPRegressor-366"><span class="linenos">366</span></a><span class="sd">        Update weights with Adam optimizer</span>
</span><span id="MLPRegressor-367"><a href="#MLPRegressor-367"><span class="linenos">367</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-368"><a href="#MLPRegressor-368"><span class="linenos">368</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
</span><span id="MLPRegressor-369"><a href="#MLPRegressor-369"><span class="linenos">369</span></a>            <span class="c1"># Update moments</span>
</span><span id="MLPRegressor-370"><a href="#MLPRegressor-370"><span class="linenos">370</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">m_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="p">)</span> <span class="o">*</span> <span class="n">gradients_w</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPRegressor-371"><a href="#MLPRegressor-371"><span class="linenos">371</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">m_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="p">)</span> <span class="o">*</span> <span class="n">gradients_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="MLPRegressor-372"><a href="#MLPRegressor-372"><span class="linenos">372</span></a>            
</span><span id="MLPRegressor-373"><a href="#MLPRegressor-373"><span class="linenos">373</span></a>            <span class="c1"># Update second moments</span>
</span><span id="MLPRegressor-374"><a href="#MLPRegressor-374"><span class="linenos">374</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">gradients_w</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="MLPRegressor-375"><a href="#MLPRegressor-375"><span class="linenos">375</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">gradients_b</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="MLPRegressor-376"><a href="#MLPRegressor-376"><span class="linenos">376</span></a>            
</span><span id="MLPRegressor-377"><a href="#MLPRegressor-377"><span class="linenos">377</span></a>            <span class="c1"># Bias correction</span>
</span><span id="MLPRegressor-378"><a href="#MLPRegressor-378"><span class="linenos">378</span></a>            <span class="n">m_weights_corrected</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">)</span>
</span><span id="MLPRegressor-379"><a href="#MLPRegressor-379"><span class="linenos">379</span></a>            <span class="n">m_biases_corrected</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">)</span>
</span><span id="MLPRegressor-380"><a href="#MLPRegressor-380"><span class="linenos">380</span></a>            <span class="n">v_weights_corrected</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">)</span>
</span><span id="MLPRegressor-381"><a href="#MLPRegressor-381"><span class="linenos">381</span></a>            <span class="n">v_biases_corrected</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span><span class="p">)</span>
</span><span id="MLPRegressor-382"><a href="#MLPRegressor-382"><span class="linenos">382</span></a>            
</span><span id="MLPRegressor-383"><a href="#MLPRegressor-383"><span class="linenos">383</span></a>            <span class="c1"># Update weights</span>
</span><span id="MLPRegressor-384"><a href="#MLPRegressor-384"><span class="linenos">384</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">m_weights_corrected</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v_weights_corrected</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">))</span>
</span><span id="MLPRegressor-385"><a href="#MLPRegressor-385"><span class="linenos">385</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">m_biases_corrected</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v_biases_corrected</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">))</span>
</span><span id="MLPRegressor-386"><a href="#MLPRegressor-386"><span class="linenos">386</span></a>        
</span><span id="MLPRegressor-387"><a href="#MLPRegressor-387"><span class="linenos">387</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="MLPRegressor-388"><a href="#MLPRegressor-388"><span class="linenos">388</span></a>    
</span><span id="MLPRegressor-389"><a href="#MLPRegressor-389"><span class="linenos">389</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_split_train_validation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
</span><span id="MLPRegressor-390"><a href="#MLPRegressor-390"><span class="linenos">390</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-391"><a href="#MLPRegressor-391"><span class="linenos">391</span></a><span class="sd">        Split data into training and validation sets</span>
</span><span id="MLPRegressor-392"><a href="#MLPRegressor-392"><span class="linenos">392</span></a><span class="sd">        </span>
</span><span id="MLPRegressor-393"><a href="#MLPRegressor-393"><span class="linenos">393</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPRegressor-394"><a href="#MLPRegressor-394"><span class="linenos">394</span></a><span class="sd">        -----------</span>
</span><span id="MLPRegressor-395"><a href="#MLPRegressor-395"><span class="linenos">395</span></a><span class="sd">        X : np.ndarray</span>
</span><span id="MLPRegressor-396"><a href="#MLPRegressor-396"><span class="linenos">396</span></a><span class="sd">            Input data</span>
</span><span id="MLPRegressor-397"><a href="#MLPRegressor-397"><span class="linenos">397</span></a><span class="sd">        y : np.ndarray</span>
</span><span id="MLPRegressor-398"><a href="#MLPRegressor-398"><span class="linenos">398</span></a><span class="sd">            Target values</span>
</span><span id="MLPRegressor-399"><a href="#MLPRegressor-399"><span class="linenos">399</span></a><span class="sd">            </span>
</span><span id="MLPRegressor-400"><a href="#MLPRegressor-400"><span class="linenos">400</span></a><span class="sd">        Returns:</span>
</span><span id="MLPRegressor-401"><a href="#MLPRegressor-401"><span class="linenos">401</span></a><span class="sd">        --------</span>
</span><span id="MLPRegressor-402"><a href="#MLPRegressor-402"><span class="linenos">402</span></a><span class="sd">        X_train, X_val, y_train, y_val : Split datasets</span>
</span><span id="MLPRegressor-403"><a href="#MLPRegressor-403"><span class="linenos">403</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-404"><a href="#MLPRegressor-404"><span class="linenos">404</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="MLPRegressor-405"><a href="#MLPRegressor-405"><span class="linenos">405</span></a>        <span class="n">n_val</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_fraction</span><span class="p">)</span>
</span><span id="MLPRegressor-406"><a href="#MLPRegressor-406"><span class="linenos">406</span></a>        
</span><span id="MLPRegressor-407"><a href="#MLPRegressor-407"><span class="linenos">407</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
</span><span id="MLPRegressor-408"><a href="#MLPRegressor-408"><span class="linenos">408</span></a>            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
</span><span id="MLPRegressor-409"><a href="#MLPRegressor-409"><span class="linenos">409</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="MLPRegressor-410"><a href="#MLPRegressor-410"><span class="linenos">410</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="MLPRegressor-411"><a href="#MLPRegressor-411"><span class="linenos">411</span></a>        
</span><span id="MLPRegressor-412"><a href="#MLPRegressor-412"><span class="linenos">412</span></a>        <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">n_val</span><span class="p">],</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_val</span><span class="p">]</span>
</span><span id="MLPRegressor-413"><a href="#MLPRegressor-413"><span class="linenos">413</span></a>        <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">n_val</span><span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">n_val</span><span class="p">:]</span>
</span><span id="MLPRegressor-414"><a href="#MLPRegressor-414"><span class="linenos">414</span></a>        
</span><span id="MLPRegressor-415"><a href="#MLPRegressor-415"><span class="linenos">415</span></a>        <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span>
</span><span id="MLPRegressor-416"><a href="#MLPRegressor-416"><span class="linenos">416</span></a>    
</span><span id="MLPRegressor-417"><a href="#MLPRegressor-417"><span class="linenos">417</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;MLPRegressor&#39;</span><span class="p">:</span>
</span><span id="MLPRegressor-418"><a href="#MLPRegressor-418"><span class="linenos">418</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-419"><a href="#MLPRegressor-419"><span class="linenos">419</span></a><span class="sd">        Train the MLP on the provided data</span>
</span><span id="MLPRegressor-420"><a href="#MLPRegressor-420"><span class="linenos">420</span></a><span class="sd">        </span>
</span><span id="MLPRegressor-421"><a href="#MLPRegressor-421"><span class="linenos">421</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPRegressor-422"><a href="#MLPRegressor-422"><span class="linenos">422</span></a><span class="sd">        -----------</span>
</span><span id="MLPRegressor-423"><a href="#MLPRegressor-423"><span class="linenos">423</span></a><span class="sd">        X : np.ndarray of shape (n_samples, n_features)</span>
</span><span id="MLPRegressor-424"><a href="#MLPRegressor-424"><span class="linenos">424</span></a><span class="sd">            Training data</span>
</span><span id="MLPRegressor-425"><a href="#MLPRegressor-425"><span class="linenos">425</span></a><span class="sd">        y : np.ndarray of shape (n_samples,) or (n_samples, n_outputs)</span>
</span><span id="MLPRegressor-426"><a href="#MLPRegressor-426"><span class="linenos">426</span></a><span class="sd">            Target values</span>
</span><span id="MLPRegressor-427"><a href="#MLPRegressor-427"><span class="linenos">427</span></a><span class="sd">            </span>
</span><span id="MLPRegressor-428"><a href="#MLPRegressor-428"><span class="linenos">428</span></a><span class="sd">        Returns:</span>
</span><span id="MLPRegressor-429"><a href="#MLPRegressor-429"><span class="linenos">429</span></a><span class="sd">        --------</span>
</span><span id="MLPRegressor-430"><a href="#MLPRegressor-430"><span class="linenos">430</span></a><span class="sd">        self : object</span>
</span><span id="MLPRegressor-431"><a href="#MLPRegressor-431"><span class="linenos">431</span></a><span class="sd">            Trained MLP</span>
</span><span id="MLPRegressor-432"><a href="#MLPRegressor-432"><span class="linenos">432</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-433"><a href="#MLPRegressor-433"><span class="linenos">433</span></a>        <span class="c1"># Convert arrays</span>
</span><span id="MLPRegressor-434"><a href="#MLPRegressor-434"><span class="linenos">434</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="MLPRegressor-435"><a href="#MLPRegressor-435"><span class="linenos">435</span></a>        <span class="n">y_orig</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="MLPRegressor-436"><a href="#MLPRegressor-436"><span class="linenos">436</span></a>        
</span><span id="MLPRegressor-437"><a href="#MLPRegressor-437"><span class="linenos">437</span></a>        <span class="c1"># Ensure y is 2D for multi-output regression</span>
</span><span id="MLPRegressor-438"><a href="#MLPRegressor-438"><span class="linenos">438</span></a>        <span class="k">if</span> <span class="n">y_orig</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="MLPRegressor-439"><a href="#MLPRegressor-439"><span class="linenos">439</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="n">y_orig</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="MLPRegressor-440"><a href="#MLPRegressor-440"><span class="linenos">440</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="MLPRegressor-441"><a href="#MLPRegressor-441"><span class="linenos">441</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="n">y_orig</span>
</span><span id="MLPRegressor-442"><a href="#MLPRegressor-442"><span class="linenos">442</span></a>        
</span><span id="MLPRegressor-443"><a href="#MLPRegressor-443"><span class="linenos">443</span></a>        <span class="c1"># Determine output dimensionality</span>
</span><span id="MLPRegressor-444"><a href="#MLPRegressor-444"><span class="linenos">444</span></a>        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</span><span id="MLPRegressor-445"><a href="#MLPRegressor-445"><span class="linenos">445</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">n_outputs</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</span><span id="MLPRegressor-446"><a href="#MLPRegressor-446"><span class="linenos">446</span></a>        
</span><span id="MLPRegressor-447"><a href="#MLPRegressor-447"><span class="linenos">447</span></a>        <span class="c1"># Initialize weights</span>
</span><span id="MLPRegressor-448"><a href="#MLPRegressor-448"><span class="linenos">448</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_weights</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">)</span>
</span><span id="MLPRegressor-449"><a href="#MLPRegressor-449"><span class="linenos">449</span></a>        
</span><span id="MLPRegressor-450"><a href="#MLPRegressor-450"><span class="linenos">450</span></a>        <span class="c1"># Split into training and validation sets if early_stopping is enabled</span>
</span><span id="MLPRegressor-451"><a href="#MLPRegressor-451"><span class="linenos">451</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping</span><span class="p">:</span>
</span><span id="MLPRegressor-452"><a href="#MLPRegressor-452"><span class="linenos">452</span></a>            <span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_train_validation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="MLPRegressor-453"><a href="#MLPRegressor-453"><span class="linenos">453</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="MLPRegressor-454"><a href="#MLPRegressor-454"><span class="linenos">454</span></a>            <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</span><span id="MLPRegressor-455"><a href="#MLPRegressor-455"><span class="linenos">455</span></a>        
</span><span id="MLPRegressor-456"><a href="#MLPRegressor-456"><span class="linenos">456</span></a>        <span class="c1"># Update method according to chosen optimizer</span>
</span><span id="MLPRegressor-457"><a href="#MLPRegressor-457"><span class="linenos">457</span></a>        <span class="n">update_methods</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="MLPRegressor-458"><a href="#MLPRegressor-458"><span class="linenos">458</span></a>            <span class="s1">&#39;sgd&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights_sgd</span><span class="p">,</span>
</span><span id="MLPRegressor-459"><a href="#MLPRegressor-459"><span class="linenos">459</span></a>            <span class="s1">&#39;momentum&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights_momentum</span><span class="p">,</span>
</span><span id="MLPRegressor-460"><a href="#MLPRegressor-460"><span class="linenos">460</span></a>            <span class="s1">&#39;rmsprop&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights_rmsprop</span><span class="p">,</span>
</span><span id="MLPRegressor-461"><a href="#MLPRegressor-461"><span class="linenos">461</span></a>            <span class="s1">&#39;adam&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights_adam</span>
</span><span id="MLPRegressor-462"><a href="#MLPRegressor-462"><span class="linenos">462</span></a>        <span class="p">}</span>
</span><span id="MLPRegressor-463"><a href="#MLPRegressor-463"><span class="linenos">463</span></a>        
</span><span id="MLPRegressor-464"><a href="#MLPRegressor-464"><span class="linenos">464</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">update_methods</span><span class="p">:</span>
</span><span id="MLPRegressor-465"><a href="#MLPRegressor-465"><span class="linenos">465</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimizer &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s2">&#39; not recognized.&quot;</span><span class="p">)</span>
</span><span id="MLPRegressor-466"><a href="#MLPRegressor-466"><span class="linenos">466</span></a>        
</span><span id="MLPRegressor-467"><a href="#MLPRegressor-467"><span class="linenos">467</span></a>        <span class="n">update_weights</span> <span class="o">=</span> <span class="n">update_methods</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">]</span>
</span><span id="MLPRegressor-468"><a href="#MLPRegressor-468"><span class="linenos">468</span></a>        
</span><span id="MLPRegressor-469"><a href="#MLPRegressor-469"><span class="linenos">469</span></a>        <span class="c1"># Training over multiple epochs</span>
</span><span id="MLPRegressor-470"><a href="#MLPRegressor-470"><span class="linenos">470</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-471"><a href="#MLPRegressor-471"><span class="linenos">471</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-472"><a href="#MLPRegressor-472"><span class="linenos">472</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</span><span id="MLPRegressor-473"><a href="#MLPRegressor-473"><span class="linenos">473</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="MLPRegressor-474"><a href="#MLPRegressor-474"><span class="linenos">474</span></a>        
</span><span id="MLPRegressor-475"><a href="#MLPRegressor-475"><span class="linenos">475</span></a>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">):</span>
</span><span id="MLPRegressor-476"><a href="#MLPRegressor-476"><span class="linenos">476</span></a>            <span class="c1"># Shuffle data if requested</span>
</span><span id="MLPRegressor-477"><a href="#MLPRegressor-477"><span class="linenos">477</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
</span><span id="MLPRegressor-478"><a href="#MLPRegressor-478"><span class="linenos">478</span></a>                <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>
</span><span id="MLPRegressor-479"><a href="#MLPRegressor-479"><span class="linenos">479</span></a>                <span class="n">X_train_shuffled</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="MLPRegressor-480"><a href="#MLPRegressor-480"><span class="linenos">480</span></a>                <span class="n">y_train_shuffled</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="MLPRegressor-481"><a href="#MLPRegressor-481"><span class="linenos">481</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="MLPRegressor-482"><a href="#MLPRegressor-482"><span class="linenos">482</span></a>                <span class="n">X_train_shuffled</span> <span class="o">=</span> <span class="n">X_train</span>
</span><span id="MLPRegressor-483"><a href="#MLPRegressor-483"><span class="linenos">483</span></a>                <span class="n">y_train_shuffled</span> <span class="o">=</span> <span class="n">y_train</span>
</span><span id="MLPRegressor-484"><a href="#MLPRegressor-484"><span class="linenos">484</span></a>            
</span><span id="MLPRegressor-485"><a href="#MLPRegressor-485"><span class="linenos">485</span></a>            <span class="c1"># Training by mini-batches</span>
</span><span id="MLPRegressor-486"><a href="#MLPRegressor-486"><span class="linenos">486</span></a>            <span class="n">batch_losses</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor-487"><a href="#MLPRegressor-487"><span class="linenos">487</span></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
</span><span id="MLPRegressor-488"><a href="#MLPRegressor-488"><span class="linenos">488</span></a>                <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_train_shuffled</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
</span><span id="MLPRegressor-489"><a href="#MLPRegressor-489"><span class="linenos">489</span></a>                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_train_shuffled</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
</span><span id="MLPRegressor-490"><a href="#MLPRegressor-490"><span class="linenos">490</span></a>                
</span><span id="MLPRegressor-491"><a href="#MLPRegressor-491"><span class="linenos">491</span></a>                <span class="c1"># Forward propagation</span>
</span><span id="MLPRegressor-492"><a href="#MLPRegressor-492"><span class="linenos">492</span></a>                <span class="n">activations</span><span class="p">,</span> <span class="n">layer_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
</span><span id="MLPRegressor-493"><a href="#MLPRegressor-493"><span class="linenos">493</span></a>                
</span><span id="MLPRegressor-494"><a href="#MLPRegressor-494"><span class="linenos">494</span></a>                <span class="c1"># Loss calculation</span>
</span><span id="MLPRegressor-495"><a href="#MLPRegressor-495"><span class="linenos">495</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">y_batch</span><span class="p">,</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="MLPRegressor-496"><a href="#MLPRegressor-496"><span class="linenos">496</span></a>                <span class="n">batch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</span><span id="MLPRegressor-497"><a href="#MLPRegressor-497"><span class="linenos">497</span></a>                
</span><span id="MLPRegressor-498"><a href="#MLPRegressor-498"><span class="linenos">498</span></a>                <span class="c1"># Backpropagation</span>
</span><span id="MLPRegressor-499"><a href="#MLPRegressor-499"><span class="linenos">499</span></a>                <span class="n">gradients_w</span><span class="p">,</span> <span class="n">gradients_b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pass</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">,</span> <span class="n">activations</span><span class="p">,</span> <span class="n">layer_inputs</span><span class="p">)</span>
</span><span id="MLPRegressor-500"><a href="#MLPRegressor-500"><span class="linenos">500</span></a>                
</span><span id="MLPRegressor-501"><a href="#MLPRegressor-501"><span class="linenos">501</span></a>                <span class="c1"># Update weights</span>
</span><span id="MLPRegressor-502"><a href="#MLPRegressor-502"><span class="linenos">502</span></a>                <span class="n">update_weights</span><span class="p">(</span><span class="n">gradients_w</span><span class="p">,</span> <span class="n">gradients_b</span><span class="p">)</span>
</span><span id="MLPRegressor-503"><a href="#MLPRegressor-503"><span class="linenos">503</span></a>            
</span><span id="MLPRegressor-504"><a href="#MLPRegressor-504"><span class="linenos">504</span></a>            <span class="c1"># Mean loss over the epoch</span>
</span><span id="MLPRegressor-505"><a href="#MLPRegressor-505"><span class="linenos">505</span></a>            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">batch_losses</span><span class="p">)</span>
</span><span id="MLPRegressor-506"><a href="#MLPRegressor-506"><span class="linenos">506</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)</span>
</span><span id="MLPRegressor-507"><a href="#MLPRegressor-507"><span class="linenos">507</span></a>            
</span><span id="MLPRegressor-508"><a href="#MLPRegressor-508"><span class="linenos">508</span></a>            <span class="c1"># Validation if early_stopping is enabled</span>
</span><span id="MLPRegressor-509"><a href="#MLPRegressor-509"><span class="linenos">509</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping</span><span class="p">:</span>
</span><span id="MLPRegressor-510"><a href="#MLPRegressor-510"><span class="linenos">510</span></a>                <span class="c1"># Calculate loss on validation set</span>
</span><span id="MLPRegressor-511"><a href="#MLPRegressor-511"><span class="linenos">511</span></a>                <span class="n">val_activations</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
</span><span id="MLPRegressor-512"><a href="#MLPRegressor-512"><span class="linenos">512</span></a>                <span class="n">val_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">val_activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="MLPRegressor-513"><a href="#MLPRegressor-513"><span class="linenos">513</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">val_loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
</span><span id="MLPRegressor-514"><a href="#MLPRegressor-514"><span class="linenos">514</span></a>                
</span><span id="MLPRegressor-515"><a href="#MLPRegressor-515"><span class="linenos">515</span></a>                <span class="c1"># Check for improvement</span>
</span><span id="MLPRegressor-516"><a href="#MLPRegressor-516"><span class="linenos">516</span></a>                <span class="k">if</span> <span class="n">val_loss</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">:</span>
</span><span id="MLPRegressor-517"><a href="#MLPRegressor-517"><span class="linenos">517</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="n">val_loss</span>
</span><span id="MLPRegressor-518"><a href="#MLPRegressor-518"><span class="linenos">518</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="MLPRegressor-519"><a href="#MLPRegressor-519"><span class="linenos">519</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="MLPRegressor-520"><a href="#MLPRegressor-520"><span class="linenos">520</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="MLPRegressor-521"><a href="#MLPRegressor-521"><span class="linenos">521</span></a>                
</span><span id="MLPRegressor-522"><a href="#MLPRegressor-522"><span class="linenos">522</span></a>                <span class="c1"># Early stopping</span>
</span><span id="MLPRegressor-523"><a href="#MLPRegressor-523"><span class="linenos">523</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span><span class="p">:</span>
</span><span id="MLPRegressor-524"><a href="#MLPRegressor-524"><span class="linenos">524</span></a>                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Early stopping at epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="MLPRegressor-525"><a href="#MLPRegressor-525"><span class="linenos">525</span></a>                    <span class="k">break</span>
</span><span id="MLPRegressor-526"><a href="#MLPRegressor-526"><span class="linenos">526</span></a>        
</span><span id="MLPRegressor-527"><a href="#MLPRegressor-527"><span class="linenos">527</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">trained</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="MLPRegressor-528"><a href="#MLPRegressor-528"><span class="linenos">528</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="MLPRegressor-529"><a href="#MLPRegressor-529"><span class="linenos">529</span></a>    
</span><span id="MLPRegressor-530"><a href="#MLPRegressor-530"><span class="linenos">530</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPRegressor-531"><a href="#MLPRegressor-531"><span class="linenos">531</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-532"><a href="#MLPRegressor-532"><span class="linenos">532</span></a><span class="sd">        Predict target values for samples in X</span>
</span><span id="MLPRegressor-533"><a href="#MLPRegressor-533"><span class="linenos">533</span></a><span class="sd">        </span>
</span><span id="MLPRegressor-534"><a href="#MLPRegressor-534"><span class="linenos">534</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPRegressor-535"><a href="#MLPRegressor-535"><span class="linenos">535</span></a><span class="sd">        -----------</span>
</span><span id="MLPRegressor-536"><a href="#MLPRegressor-536"><span class="linenos">536</span></a><span class="sd">        X : np.ndarray of shape (n_samples, n_features)</span>
</span><span id="MLPRegressor-537"><a href="#MLPRegressor-537"><span class="linenos">537</span></a><span class="sd">            The data to predict</span>
</span><span id="MLPRegressor-538"><a href="#MLPRegressor-538"><span class="linenos">538</span></a><span class="sd">            </span>
</span><span id="MLPRegressor-539"><a href="#MLPRegressor-539"><span class="linenos">539</span></a><span class="sd">        Returns:</span>
</span><span id="MLPRegressor-540"><a href="#MLPRegressor-540"><span class="linenos">540</span></a><span class="sd">        --------</span>
</span><span id="MLPRegressor-541"><a href="#MLPRegressor-541"><span class="linenos">541</span></a><span class="sd">        y_pred : np.ndarray of shape (n_samples, n_outputs) or (n_samples,)</span>
</span><span id="MLPRegressor-542"><a href="#MLPRegressor-542"><span class="linenos">542</span></a><span class="sd">            The predicted values</span>
</span><span id="MLPRegressor-543"><a href="#MLPRegressor-543"><span class="linenos">543</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-544"><a href="#MLPRegressor-544"><span class="linenos">544</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trained</span><span class="p">:</span>
</span><span id="MLPRegressor-545"><a href="#MLPRegressor-545"><span class="linenos">545</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The model must be trained before making predictions.&quot;</span><span class="p">)</span>
</span><span id="MLPRegressor-546"><a href="#MLPRegressor-546"><span class="linenos">546</span></a>        
</span><span id="MLPRegressor-547"><a href="#MLPRegressor-547"><span class="linenos">547</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="MLPRegressor-548"><a href="#MLPRegressor-548"><span class="linenos">548</span></a>        <span class="n">activations</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="MLPRegressor-549"><a href="#MLPRegressor-549"><span class="linenos">549</span></a>        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="MLPRegressor-550"><a href="#MLPRegressor-550"><span class="linenos">550</span></a>        
</span><span id="MLPRegressor-551"><a href="#MLPRegressor-551"><span class="linenos">551</span></a>        <span class="c1"># If only one output, return 1D array for consistency with sklearn</span>
</span><span id="MLPRegressor-552"><a href="#MLPRegressor-552"><span class="linenos">552</span></a>        <span class="k">if</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="MLPRegressor-553"><a href="#MLPRegressor-553"><span class="linenos">553</span></a>            <span class="k">return</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
</span><span id="MLPRegressor-554"><a href="#MLPRegressor-554"><span class="linenos">554</span></a>        <span class="k">return</span> <span class="n">y_pred</span>
</span><span id="MLPRegressor-555"><a href="#MLPRegressor-555"><span class="linenos">555</span></a>    
</span><span id="MLPRegressor-556"><a href="#MLPRegressor-556"><span class="linenos">556</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span><span id="MLPRegressor-557"><a href="#MLPRegressor-557"><span class="linenos">557</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor-558"><a href="#MLPRegressor-558"><span class="linenos">558</span></a><span class="sd">        Return the coefficient of determination R^2 of the prediction</span>
</span><span id="MLPRegressor-559"><a href="#MLPRegressor-559"><span class="linenos">559</span></a><span class="sd">        </span>
</span><span id="MLPRegressor-560"><a href="#MLPRegressor-560"><span class="linenos">560</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPRegressor-561"><a href="#MLPRegressor-561"><span class="linenos">561</span></a><span class="sd">        -----------</span>
</span><span id="MLPRegressor-562"><a href="#MLPRegressor-562"><span class="linenos">562</span></a><span class="sd">        X : np.ndarray of shape (n_samples, n_features)</span>
</span><span id="MLPRegressor-563"><a href="#MLPRegressor-563"><span class="linenos">563</span></a><span class="sd">            Test data</span>
</span><span id="MLPRegressor-564"><a href="#MLPRegressor-564"><span class="linenos">564</span></a><span class="sd">        y : np.ndarray of shape (n_samples,) or (n_samples, n_outputs)</span>
</span><span id="MLPRegressor-565"><a href="#MLPRegressor-565"><span class="linenos">565</span></a><span class="sd">            True values</span>
</span><span id="MLPRegressor-566"><a href="#MLPRegressor-566"><span class="linenos">566</span></a><span class="sd">            </span>
</span><span id="MLPRegressor-567"><a href="#MLPRegressor-567"><span class="linenos">567</span></a><span class="sd">        Returns:</span>
</span><span id="MLPRegressor-568"><a href="#MLPRegressor-568"><span class="linenos">568</span></a><span class="sd">        --------</span>
</span><span id="MLPRegressor-569"><a href="#MLPRegressor-569"><span class="linenos">569</span></a><span class="sd">        score : float</span>
</span><span id="MLPRegressor-570"><a href="#MLPRegressor-570"><span class="linenos">570</span></a><span class="sd">            R^2 score</span>
</span><span id="MLPRegressor-571"><a href="#MLPRegressor-571"><span class="linenos">571</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor-572"><a href="#MLPRegressor-572"><span class="linenos">572</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trained</span><span class="p">:</span>
</span><span id="MLPRegressor-573"><a href="#MLPRegressor-573"><span class="linenos">573</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The model must be trained before calculating its score.&quot;</span><span class="p">)</span>
</span><span id="MLPRegressor-574"><a href="#MLPRegressor-574"><span class="linenos">574</span></a>        
</span><span id="MLPRegressor-575"><a href="#MLPRegressor-575"><span class="linenos">575</span></a>        <span class="c1"># Ensure y is in the right shape</span>
</span><span id="MLPRegressor-576"><a href="#MLPRegressor-576"><span class="linenos">576</span></a>        <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="MLPRegressor-577"><a href="#MLPRegressor-577"><span class="linenos">577</span></a>        <span class="k">if</span> <span class="n">y_true</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="MLPRegressor-578"><a href="#MLPRegressor-578"><span class="linenos">578</span></a>            <span class="n">y_true</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="MLPRegressor-579"><a href="#MLPRegressor-579"><span class="linenos">579</span></a>        
</span><span id="MLPRegressor-580"><a href="#MLPRegressor-580"><span class="linenos">580</span></a>        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="MLPRegressor-581"><a href="#MLPRegressor-581"><span class="linenos">581</span></a>        <span class="k">if</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="MLPRegressor-582"><a href="#MLPRegressor-582"><span class="linenos">582</span></a>            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="MLPRegressor-583"><a href="#MLPRegressor-583"><span class="linenos">583</span></a>        
</span><span id="MLPRegressor-584"><a href="#MLPRegressor-584"><span class="linenos">584</span></a>        <span class="c1"># Calculate R^2 score</span>
</span><span id="MLPRegressor-585"><a href="#MLPRegressor-585"><span class="linenos">585</span></a>        <span class="n">u</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="MLPRegressor-586"><a href="#MLPRegressor-586"><span class="linenos">586</span></a>        <span class="n">v</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_true</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="MLPRegressor-587"><a href="#MLPRegressor-587"><span class="linenos">587</span></a>        
</span><span id="MLPRegressor-588"><a href="#MLPRegressor-588"><span class="linenos">588</span></a>        <span class="c1"># Avoid division by zero</span>
</span><span id="MLPRegressor-589"><a href="#MLPRegressor-589"><span class="linenos">589</span></a>        <span class="k">if</span> <span class="n">v</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="MLPRegressor-590"><a href="#MLPRegressor-590"><span class="linenos">590</span></a>            <span class="k">return</span> <span class="mf">0.0</span>
</span><span id="MLPRegressor-591"><a href="#MLPRegressor-591"><span class="linenos">591</span></a>        
</span><span id="MLPRegressor-592"><a href="#MLPRegressor-592"><span class="linenos">592</span></a>        <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">u</span> <span class="o">/</span> <span class="n">v</span>
</span></pre></div>


            <div class="docstring"><p>Multi-Layer Perceptron for regression tasks with various activation functions and optimizers</p>
</div>


                            <div id="MLPRegressor.__init__" class="classattr">
                                        <input id="MLPRegressor.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">MLPRegressor</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">hidden_layer_sizes</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">100</span><span class="p">,)</span>,</span><span class="param">	<span class="n">activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span>,</span><span class="param">	<span class="n">solver</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;sgd&#39;</span>,</span><span class="param">	<span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0001</span>,</span><span class="param">	<span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span>,</span><span class="param">	<span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span>,</span><span class="param">	<span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">200</span>,</span><span class="param">	<span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>,</span><span class="param">	<span class="n">random_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">beta1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span>,</span><span class="param">	<span class="n">beta2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.999</span>,</span><span class="param">	<span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-08</span>,</span><span class="param">	<span class="n">momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span>,</span><span class="param">	<span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0001</span>,</span><span class="param">	<span class="n">early_stopping</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">validation_fraction</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span>,</span><span class="param">	<span class="n">n_iter_no_change</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span></span>)</span>

                <label class="view-source-button" for="MLPRegressor.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MLPRegressor.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MLPRegressor.__init__-11"><a href="#MLPRegressor.__init__-11"><span class="linenos"> 11</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="MLPRegressor.__init__-12"><a href="#MLPRegressor.__init__-12"><span class="linenos"> 12</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-13"><a href="#MLPRegressor.__init__-13"><span class="linenos"> 13</span></a>        <span class="n">hidden_layer_sizes</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">100</span><span class="p">,),</span>
</span><span id="MLPRegressor.__init__-14"><a href="#MLPRegressor.__init__-14"><span class="linenos"> 14</span></a>        <span class="n">activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-15"><a href="#MLPRegressor.__init__-15"><span class="linenos"> 15</span></a>        <span class="n">solver</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sgd&quot;</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-16"><a href="#MLPRegressor.__init__-16"><span class="linenos"> 16</span></a>        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0001</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-17"><a href="#MLPRegressor.__init__-17"><span class="linenos"> 17</span></a>        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-18"><a href="#MLPRegressor.__init__-18"><span class="linenos"> 18</span></a>        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-19"><a href="#MLPRegressor.__init__-19"><span class="linenos"> 19</span></a>        <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-20"><a href="#MLPRegressor.__init__-20"><span class="linenos"> 20</span></a>        <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-21"><a href="#MLPRegressor.__init__-21"><span class="linenos"> 21</span></a>        <span class="n">random_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-22"><a href="#MLPRegressor.__init__-22"><span class="linenos"> 22</span></a>        <span class="n">beta1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-23"><a href="#MLPRegressor.__init__-23"><span class="linenos"> 23</span></a>        <span class="n">beta2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.999</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-24"><a href="#MLPRegressor.__init__-24"><span class="linenos"> 24</span></a>        <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-25"><a href="#MLPRegressor.__init__-25"><span class="linenos"> 25</span></a>        <span class="n">momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-26"><a href="#MLPRegressor.__init__-26"><span class="linenos"> 26</span></a>        <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-27"><a href="#MLPRegressor.__init__-27"><span class="linenos"> 27</span></a>        <span class="n">early_stopping</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-28"><a href="#MLPRegressor.__init__-28"><span class="linenos"> 28</span></a>        <span class="n">validation_fraction</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-29"><a href="#MLPRegressor.__init__-29"><span class="linenos"> 29</span></a>        <span class="n">n_iter_no_change</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>
</span><span id="MLPRegressor.__init__-30"><a href="#MLPRegressor.__init__-30"><span class="linenos"> 30</span></a>    <span class="p">):</span>
</span><span id="MLPRegressor.__init__-31"><a href="#MLPRegressor.__init__-31"><span class="linenos"> 31</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor.__init__-32"><a href="#MLPRegressor.__init__-32"><span class="linenos"> 32</span></a><span class="sd">        Initialize an MLP regressor</span>
</span><span id="MLPRegressor.__init__-33"><a href="#MLPRegressor.__init__-33"><span class="linenos"> 33</span></a><span class="sd">        </span>
</span><span id="MLPRegressor.__init__-34"><a href="#MLPRegressor.__init__-34"><span class="linenos"> 34</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPRegressor.__init__-35"><a href="#MLPRegressor.__init__-35"><span class="linenos"> 35</span></a><span class="sd">        -----------</span>
</span><span id="MLPRegressor.__init__-36"><a href="#MLPRegressor.__init__-36"><span class="linenos"> 36</span></a><span class="sd">        hidden_layer_sizes : tuple</span>
</span><span id="MLPRegressor.__init__-37"><a href="#MLPRegressor.__init__-37"><span class="linenos"> 37</span></a><span class="sd">            The sizes of the hidden layers</span>
</span><span id="MLPRegressor.__init__-38"><a href="#MLPRegressor.__init__-38"><span class="linenos"> 38</span></a><span class="sd">        activation : str</span>
</span><span id="MLPRegressor.__init__-39"><a href="#MLPRegressor.__init__-39"><span class="linenos"> 39</span></a><span class="sd">            Activation function (&#39;sigmoid&#39;, &#39;relu&#39;, &#39;tanh&#39;, &#39;leaky_relu&#39;)</span>
</span><span id="MLPRegressor.__init__-40"><a href="#MLPRegressor.__init__-40"><span class="linenos"> 40</span></a><span class="sd">        solver : str</span>
</span><span id="MLPRegressor.__init__-41"><a href="#MLPRegressor.__init__-41"><span class="linenos"> 41</span></a><span class="sd">            Optimization algorithm (&#39;sgd&#39;, &#39;adam&#39;, &#39;rmsprop&#39;, &#39;momentum&#39;)</span>
</span><span id="MLPRegressor.__init__-42"><a href="#MLPRegressor.__init__-42"><span class="linenos"> 42</span></a><span class="sd">        alpha : float</span>
</span><span id="MLPRegressor.__init__-43"><a href="#MLPRegressor.__init__-43"><span class="linenos"> 43</span></a><span class="sd">            L2 regularization parameter</span>
</span><span id="MLPRegressor.__init__-44"><a href="#MLPRegressor.__init__-44"><span class="linenos"> 44</span></a><span class="sd">        batch_size : int</span>
</span><span id="MLPRegressor.__init__-45"><a href="#MLPRegressor.__init__-45"><span class="linenos"> 45</span></a><span class="sd">            Size of mini-batches for training</span>
</span><span id="MLPRegressor.__init__-46"><a href="#MLPRegressor.__init__-46"><span class="linenos"> 46</span></a><span class="sd">        learning_rate : float</span>
</span><span id="MLPRegressor.__init__-47"><a href="#MLPRegressor.__init__-47"><span class="linenos"> 47</span></a><span class="sd">            Learning rate</span>
</span><span id="MLPRegressor.__init__-48"><a href="#MLPRegressor.__init__-48"><span class="linenos"> 48</span></a><span class="sd">        max_iter : int</span>
</span><span id="MLPRegressor.__init__-49"><a href="#MLPRegressor.__init__-49"><span class="linenos"> 49</span></a><span class="sd">            Maximum number of iterations</span>
</span><span id="MLPRegressor.__init__-50"><a href="#MLPRegressor.__init__-50"><span class="linenos"> 50</span></a><span class="sd">        shuffle : bool</span>
</span><span id="MLPRegressor.__init__-51"><a href="#MLPRegressor.__init__-51"><span class="linenos"> 51</span></a><span class="sd">            If True, shuffle the data at each epoch</span>
</span><span id="MLPRegressor.__init__-52"><a href="#MLPRegressor.__init__-52"><span class="linenos"> 52</span></a><span class="sd">        random_state : int or None</span>
</span><span id="MLPRegressor.__init__-53"><a href="#MLPRegressor.__init__-53"><span class="linenos"> 53</span></a><span class="sd">            Seed for reproducibility</span>
</span><span id="MLPRegressor.__init__-54"><a href="#MLPRegressor.__init__-54"><span class="linenos"> 54</span></a><span class="sd">        beta1 : float</span>
</span><span id="MLPRegressor.__init__-55"><a href="#MLPRegressor.__init__-55"><span class="linenos"> 55</span></a><span class="sd">            Parameter for Adam (exponential decay rate for first moment)</span>
</span><span id="MLPRegressor.__init__-56"><a href="#MLPRegressor.__init__-56"><span class="linenos"> 56</span></a><span class="sd">        beta2 : float</span>
</span><span id="MLPRegressor.__init__-57"><a href="#MLPRegressor.__init__-57"><span class="linenos"> 57</span></a><span class="sd">            Parameter for Adam (exponential decay rate for second moment)</span>
</span><span id="MLPRegressor.__init__-58"><a href="#MLPRegressor.__init__-58"><span class="linenos"> 58</span></a><span class="sd">        epsilon : float</span>
</span><span id="MLPRegressor.__init__-59"><a href="#MLPRegressor.__init__-59"><span class="linenos"> 59</span></a><span class="sd">            Value to avoid division by zero</span>
</span><span id="MLPRegressor.__init__-60"><a href="#MLPRegressor.__init__-60"><span class="linenos"> 60</span></a><span class="sd">        momentum : float</span>
</span><span id="MLPRegressor.__init__-61"><a href="#MLPRegressor.__init__-61"><span class="linenos"> 61</span></a><span class="sd">            Parameter for momentum optimizer</span>
</span><span id="MLPRegressor.__init__-62"><a href="#MLPRegressor.__init__-62"><span class="linenos"> 62</span></a><span class="sd">        tol : float</span>
</span><span id="MLPRegressor.__init__-63"><a href="#MLPRegressor.__init__-63"><span class="linenos"> 63</span></a><span class="sd">            Tolerance for early stopping</span>
</span><span id="MLPRegressor.__init__-64"><a href="#MLPRegressor.__init__-64"><span class="linenos"> 64</span></a><span class="sd">        early_stopping : bool</span>
</span><span id="MLPRegressor.__init__-65"><a href="#MLPRegressor.__init__-65"><span class="linenos"> 65</span></a><span class="sd">            If True, use early stopping based on validation</span>
</span><span id="MLPRegressor.__init__-66"><a href="#MLPRegressor.__init__-66"><span class="linenos"> 66</span></a><span class="sd">        validation_fraction : float</span>
</span><span id="MLPRegressor.__init__-67"><a href="#MLPRegressor.__init__-67"><span class="linenos"> 67</span></a><span class="sd">            Fraction of training data to use as validation</span>
</span><span id="MLPRegressor.__init__-68"><a href="#MLPRegressor.__init__-68"><span class="linenos"> 68</span></a><span class="sd">        n_iter_no_change : int</span>
</span><span id="MLPRegressor.__init__-69"><a href="#MLPRegressor.__init__-69"><span class="linenos"> 69</span></a><span class="sd">            Number of iterations with no improvement for early stopping</span>
</span><span id="MLPRegressor.__init__-70"><a href="#MLPRegressor.__init__-70"><span class="linenos"> 70</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor.__init__-71"><a href="#MLPRegressor.__init__-71"><span class="linenos"> 71</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_sizes</span> <span class="o">=</span> <span class="n">hidden_layer_sizes</span>
</span><span id="MLPRegressor.__init__-72"><a href="#MLPRegressor.__init__-72"><span class="linenos"> 72</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
</span><span id="MLPRegressor.__init__-73"><a href="#MLPRegressor.__init__-73"><span class="linenos"> 73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">=</span> <span class="n">solver</span>
</span><span id="MLPRegressor.__init__-74"><a href="#MLPRegressor.__init__-74"><span class="linenos"> 74</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
</span><span id="MLPRegressor.__init__-75"><a href="#MLPRegressor.__init__-75"><span class="linenos"> 75</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
</span><span id="MLPRegressor.__init__-76"><a href="#MLPRegressor.__init__-76"><span class="linenos"> 76</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
</span><span id="MLPRegressor.__init__-77"><a href="#MLPRegressor.__init__-77"><span class="linenos"> 77</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
</span><span id="MLPRegressor.__init__-78"><a href="#MLPRegressor.__init__-78"><span class="linenos"> 78</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span>
</span><span id="MLPRegressor.__init__-79"><a href="#MLPRegressor.__init__-79"><span class="linenos"> 79</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">=</span> <span class="n">beta1</span>
</span><span id="MLPRegressor.__init__-80"><a href="#MLPRegressor.__init__-80"><span class="linenos"> 80</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">=</span> <span class="n">beta2</span>
</span><span id="MLPRegressor.__init__-81"><a href="#MLPRegressor.__init__-81"><span class="linenos"> 81</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
</span><span id="MLPRegressor.__init__-82"><a href="#MLPRegressor.__init__-82"><span class="linenos"> 82</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
</span><span id="MLPRegressor.__init__-83"><a href="#MLPRegressor.__init__-83"><span class="linenos"> 83</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
</span><span id="MLPRegressor.__init__-84"><a href="#MLPRegressor.__init__-84"><span class="linenos"> 84</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping</span> <span class="o">=</span> <span class="n">early_stopping</span>
</span><span id="MLPRegressor.__init__-85"><a href="#MLPRegressor.__init__-85"><span class="linenos"> 85</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">validation_fraction</span> <span class="o">=</span> <span class="n">validation_fraction</span>
</span><span id="MLPRegressor.__init__-86"><a href="#MLPRegressor.__init__-86"><span class="linenos"> 86</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span> <span class="o">=</span> <span class="n">n_iter_no_change</span>
</span><span id="MLPRegressor.__init__-87"><a href="#MLPRegressor.__init__-87"><span class="linenos"> 87</span></a>        
</span><span id="MLPRegressor.__init__-88"><a href="#MLPRegressor.__init__-88"><span class="linenos"> 88</span></a>        <span class="k">if</span> <span class="n">random_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="MLPRegressor.__init__-89"><a href="#MLPRegressor.__init__-89"><span class="linenos"> 89</span></a>            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
</span><span id="MLPRegressor.__init__-90"><a href="#MLPRegressor.__init__-90"><span class="linenos"> 90</span></a>        
</span><span id="MLPRegressor.__init__-91"><a href="#MLPRegressor.__init__-91"><span class="linenos"> 91</span></a>        <span class="c1"># Selection of activation functions</span>
</span><span id="MLPRegressor.__init__-92"><a href="#MLPRegressor.__init__-92"><span class="linenos"> 92</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation_functions</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="MLPRegressor.__init__-93"><a href="#MLPRegressor.__init__-93"><span class="linenos"> 93</span></a>            <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-94"><a href="#MLPRegressor.__init__-94"><span class="linenos"> 94</span></a>            <span class="s1">&#39;relu&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-95"><a href="#MLPRegressor.__init__-95"><span class="linenos"> 95</span></a>            <span class="s1">&#39;tanh&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tanh</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-96"><a href="#MLPRegressor.__init__-96"><span class="linenos"> 96</span></a>            <span class="s1">&#39;leaky_relu&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaky_relu</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-97"><a href="#MLPRegressor.__init__-97"><span class="linenos"> 97</span></a>        <span class="p">}</span>
</span><span id="MLPRegressor.__init__-98"><a href="#MLPRegressor.__init__-98"><span class="linenos"> 98</span></a>        
</span><span id="MLPRegressor.__init__-99"><a href="#MLPRegressor.__init__-99"><span class="linenos"> 99</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation_derivatives</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="MLPRegressor.__init__-100"><a href="#MLPRegressor.__init__-100"><span class="linenos">100</span></a>            <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid_derivative</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-101"><a href="#MLPRegressor.__init__-101"><span class="linenos">101</span></a>            <span class="s1">&#39;relu&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_relu_derivative</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-102"><a href="#MLPRegressor.__init__-102"><span class="linenos">102</span></a>            <span class="s1">&#39;tanh&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tanh_derivative</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-103"><a href="#MLPRegressor.__init__-103"><span class="linenos">103</span></a>            <span class="s1">&#39;leaky_relu&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaky_relu_derivative</span><span class="p">,</span>
</span><span id="MLPRegressor.__init__-104"><a href="#MLPRegressor.__init__-104"><span class="linenos">104</span></a>        <span class="p">}</span>
</span><span id="MLPRegressor.__init__-105"><a href="#MLPRegressor.__init__-105"><span class="linenos">105</span></a>        
</span><span id="MLPRegressor.__init__-106"><a href="#MLPRegressor.__init__-106"><span class="linenos">106</span></a>        <span class="c1"># Selection of activation function and its derivative</span>
</span><span id="MLPRegressor.__init__-107"><a href="#MLPRegressor.__init__-107"><span class="linenos">107</span></a>        <span class="k">if</span> <span class="n">activation</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_functions</span><span class="p">:</span>
</span><span id="MLPRegressor.__init__-108"><a href="#MLPRegressor.__init__-108"><span class="linenos">108</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Activation &#39;</span><span class="si">{</span><span class="n">activation</span><span class="si">}</span><span class="s2">&#39; not recognized. Use &#39;sigmoid&#39;, &#39;relu&#39;, &#39;tanh&#39; or &#39;leaky_relu&#39;.&quot;</span><span class="p">)</span>
</span><span id="MLPRegressor.__init__-109"><a href="#MLPRegressor.__init__-109"><span class="linenos">109</span></a>        
</span><span id="MLPRegressor.__init__-110"><a href="#MLPRegressor.__init__-110"><span class="linenos">110</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation_func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_functions</span><span class="p">[</span><span class="n">activation</span><span class="p">]</span>
</span><span id="MLPRegressor.__init__-111"><a href="#MLPRegressor.__init__-111"><span class="linenos">111</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation_derivative</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_derivatives</span><span class="p">[</span><span class="n">activation</span><span class="p">]</span>
</span><span id="MLPRegressor.__init__-112"><a href="#MLPRegressor.__init__-112"><span class="linenos">112</span></a>        
</span><span id="MLPRegressor.__init__-113"><a href="#MLPRegressor.__init__-113"><span class="linenos">113</span></a>        <span class="c1"># Initialization of weights</span>
</span><span id="MLPRegressor.__init__-114"><a href="#MLPRegressor.__init__-114"><span class="linenos">114</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor.__init__-115"><a href="#MLPRegressor.__init__-115"><span class="linenos">115</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor.__init__-116"><a href="#MLPRegressor.__init__-116"><span class="linenos">116</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="MLPRegressor.__init__-117"><a href="#MLPRegressor.__init__-117"><span class="linenos">117</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_outputs</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="MLPRegressor.__init__-118"><a href="#MLPRegressor.__init__-118"><span class="linenos">118</span></a>        
</span><span id="MLPRegressor.__init__-119"><a href="#MLPRegressor.__init__-119"><span class="linenos">119</span></a>        <span class="c1"># For optimizers</span>
</span><span id="MLPRegressor.__init__-120"><a href="#MLPRegressor.__init__-120"><span class="linenos">120</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">velocity_weights</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># For Momentum</span>
</span><span id="MLPRegressor.__init__-121"><a href="#MLPRegressor.__init__-121"><span class="linenos">121</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">velocity_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor.__init__-122"><a href="#MLPRegressor.__init__-122"><span class="linenos">122</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">m_weights</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># For Adam</span>
</span><span id="MLPRegressor.__init__-123"><a href="#MLPRegressor.__init__-123"><span class="linenos">123</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">m_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor.__init__-124"><a href="#MLPRegressor.__init__-124"><span class="linenos">124</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">v_weights</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># For Adam</span>
</span><span id="MLPRegressor.__init__-125"><a href="#MLPRegressor.__init__-125"><span class="linenos">125</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">v_biases</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor.__init__-126"><a href="#MLPRegressor.__init__-126"><span class="linenos">126</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Timestep for Adam</span>
</span><span id="MLPRegressor.__init__-127"><a href="#MLPRegressor.__init__-127"><span class="linenos">127</span></a>        
</span><span id="MLPRegressor.__init__-128"><a href="#MLPRegressor.__init__-128"><span class="linenos">128</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor.__init__-129"><a href="#MLPRegressor.__init__-129"><span class="linenos">129</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor.__init__-130"><a href="#MLPRegressor.__init__-130"><span class="linenos">130</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</span><span id="MLPRegressor.__init__-131"><a href="#MLPRegressor.__init__-131"><span class="linenos">131</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="MLPRegressor.__init__-132"><a href="#MLPRegressor.__init__-132"><span class="linenos">132</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">trained</span> <span class="o">=</span> <span class="kc">False</span>
</span></pre></div>


            <div class="docstring"><p>Initialize an MLP regressor</p>

<h2 id="parameters">Parameters:</h2>

<p>hidden_layer_sizes : tuple
    The sizes of the hidden layers
activation : str
    Activation function ('sigmoid', 'relu', 'tanh', 'leaky_relu')
solver : str
    Optimization algorithm ('sgd', 'adam', 'rmsprop', 'momentum')
alpha : float
    L2 regularization parameter
batch_size : int
    Size of mini-batches for training
learning_rate : float
    Learning rate
max_iter : int
    Maximum number of iterations
shuffle : bool
    If True, shuffle the data at each epoch
random_state : int or None
    Seed for reproducibility
beta1 : float
    Parameter for Adam (exponential decay rate for first moment)
beta2 : float
    Parameter for Adam (exponential decay rate for second moment)
epsilon : float
    Value to avoid division by zero
momentum : float
    Parameter for momentum optimizer
tol : float
    Tolerance for early stopping
early_stopping : bool
    If True, use early stopping based on validation
validation_fraction : float
    Fraction of training data to use as validation
n_iter_no_change : int
    Number of iterations with no improvement for early stopping</p>
</div>


                            </div>
                            <div id="MLPRegressor.hidden_layer_sizes" class="classattr">
                                <div class="attr variable">
            <span class="name">hidden_layer_sizes</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.hidden_layer_sizes"></a>
    
    

                            </div>
                            <div id="MLPRegressor.activation" class="classattr">
                                <div class="attr variable">
            <span class="name">activation</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.activation"></a>
    
    

                            </div>
                            <div id="MLPRegressor.solver" class="classattr">
                                <div class="attr variable">
            <span class="name">solver</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.solver"></a>
    
    

                            </div>
                            <div id="MLPRegressor.alpha" class="classattr">
                                <div class="attr variable">
            <span class="name">alpha</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.alpha"></a>
    
    

                            </div>
                            <div id="MLPRegressor.batch_size" class="classattr">
                                <div class="attr variable">
            <span class="name">batch_size</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.batch_size"></a>
    
    

                            </div>
                            <div id="MLPRegressor.learning_rate" class="classattr">
                                <div class="attr variable">
            <span class="name">learning_rate</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.learning_rate"></a>
    
    

                            </div>
                            <div id="MLPRegressor.max_iter" class="classattr">
                                <div class="attr variable">
            <span class="name">max_iter</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.max_iter"></a>
    
    

                            </div>
                            <div id="MLPRegressor.shuffle" class="classattr">
                                <div class="attr variable">
            <span class="name">shuffle</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.shuffle"></a>
    
    

                            </div>
                            <div id="MLPRegressor.beta1" class="classattr">
                                <div class="attr variable">
            <span class="name">beta1</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.beta1"></a>
    
    

                            </div>
                            <div id="MLPRegressor.beta2" class="classattr">
                                <div class="attr variable">
            <span class="name">beta2</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.beta2"></a>
    
    

                            </div>
                            <div id="MLPRegressor.epsilon" class="classattr">
                                <div class="attr variable">
            <span class="name">epsilon</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.epsilon"></a>
    
    

                            </div>
                            <div id="MLPRegressor.momentum" class="classattr">
                                <div class="attr variable">
            <span class="name">momentum</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.momentum"></a>
    
    

                            </div>
                            <div id="MLPRegressor.tol" class="classattr">
                                <div class="attr variable">
            <span class="name">tol</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.tol"></a>
    
    

                            </div>
                            <div id="MLPRegressor.early_stopping" class="classattr">
                                <div class="attr variable">
            <span class="name">early_stopping</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.early_stopping"></a>
    
    

                            </div>
                            <div id="MLPRegressor.validation_fraction" class="classattr">
                                <div class="attr variable">
            <span class="name">validation_fraction</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.validation_fraction"></a>
    
    

                            </div>
                            <div id="MLPRegressor.n_iter_no_change" class="classattr">
                                <div class="attr variable">
            <span class="name">n_iter_no_change</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.n_iter_no_change"></a>
    
    

                            </div>
                            <div id="MLPRegressor.activation_functions" class="classattr">
                                <div class="attr variable">
            <span class="name">activation_functions</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.activation_functions"></a>
    
    

                            </div>
                            <div id="MLPRegressor.activation_derivatives" class="classattr">
                                <div class="attr variable">
            <span class="name">activation_derivatives</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.activation_derivatives"></a>
    
    

                            </div>
                            <div id="MLPRegressor.activation_func" class="classattr">
                                <div class="attr variable">
            <span class="name">activation_func</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.activation_func"></a>
    
    

                            </div>
                            <div id="MLPRegressor.activation_derivative" class="classattr">
                                <div class="attr variable">
            <span class="name">activation_derivative</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.activation_derivative"></a>
    
    

                            </div>
                            <div id="MLPRegressor.weights" class="classattr">
                                <div class="attr variable">
            <span class="name">weights</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.weights"></a>
    
    

                            </div>
                            <div id="MLPRegressor.biases" class="classattr">
                                <div class="attr variable">
            <span class="name">biases</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.biases"></a>
    
    

                            </div>
                            <div id="MLPRegressor.n_layers" class="classattr">
                                <div class="attr variable">
            <span class="name">n_layers</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.n_layers"></a>
    
    

                            </div>
                            <div id="MLPRegressor.n_outputs" class="classattr">
                                <div class="attr variable">
            <span class="name">n_outputs</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.n_outputs"></a>
    
    

                            </div>
                            <div id="MLPRegressor.velocity_weights" class="classattr">
                                <div class="attr variable">
            <span class="name">velocity_weights</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.velocity_weights"></a>
    
    

                            </div>
                            <div id="MLPRegressor.velocity_biases" class="classattr">
                                <div class="attr variable">
            <span class="name">velocity_biases</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.velocity_biases"></a>
    
    

                            </div>
                            <div id="MLPRegressor.m_weights" class="classattr">
                                <div class="attr variable">
            <span class="name">m_weights</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.m_weights"></a>
    
    

                            </div>
                            <div id="MLPRegressor.m_biases" class="classattr">
                                <div class="attr variable">
            <span class="name">m_biases</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.m_biases"></a>
    
    

                            </div>
                            <div id="MLPRegressor.v_weights" class="classattr">
                                <div class="attr variable">
            <span class="name">v_weights</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.v_weights"></a>
    
    

                            </div>
                            <div id="MLPRegressor.v_biases" class="classattr">
                                <div class="attr variable">
            <span class="name">v_biases</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.v_biases"></a>
    
    

                            </div>
                            <div id="MLPRegressor.t" class="classattr">
                                <div class="attr variable">
            <span class="name">t</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.t"></a>
    
    

                            </div>
                            <div id="MLPRegressor.loss_history" class="classattr">
                                <div class="attr variable">
            <span class="name">loss_history</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.loss_history"></a>
    
    

                            </div>
                            <div id="MLPRegressor.val_loss_history" class="classattr">
                                <div class="attr variable">
            <span class="name">val_loss_history</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.val_loss_history"></a>
    
    

                            </div>
                            <div id="MLPRegressor.best_loss" class="classattr">
                                <div class="attr variable">
            <span class="name">best_loss</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.best_loss"></a>
    
    

                            </div>
                            <div id="MLPRegressor.no_improvement_count" class="classattr">
                                <div class="attr variable">
            <span class="name">no_improvement_count</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.no_improvement_count"></a>
    
    

                            </div>
                            <div id="MLPRegressor.trained" class="classattr">
                                <div class="attr variable">
            <span class="name">trained</span>

        
    </div>
    <a class="headerlink" href="#MLPRegressor.trained"></a>
    
    

                            </div>
                            <div id="MLPRegressor.fit" class="classattr">
                                        <input id="MLPRegressor.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">X</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>,</span><span class="param">	<span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span></span><span class="return-annotation">) -> <span class="n"><a href="#MLPRegressor">MLPRegressor</a></span>:</span></span>

                <label class="view-source-button" for="MLPRegressor.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MLPRegressor.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MLPRegressor.fit-417"><a href="#MLPRegressor.fit-417"><span class="linenos">417</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;MLPRegressor&#39;</span><span class="p">:</span>
</span><span id="MLPRegressor.fit-418"><a href="#MLPRegressor.fit-418"><span class="linenos">418</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor.fit-419"><a href="#MLPRegressor.fit-419"><span class="linenos">419</span></a><span class="sd">        Train the MLP on the provided data</span>
</span><span id="MLPRegressor.fit-420"><a href="#MLPRegressor.fit-420"><span class="linenos">420</span></a><span class="sd">        </span>
</span><span id="MLPRegressor.fit-421"><a href="#MLPRegressor.fit-421"><span class="linenos">421</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPRegressor.fit-422"><a href="#MLPRegressor.fit-422"><span class="linenos">422</span></a><span class="sd">        -----------</span>
</span><span id="MLPRegressor.fit-423"><a href="#MLPRegressor.fit-423"><span class="linenos">423</span></a><span class="sd">        X : np.ndarray of shape (n_samples, n_features)</span>
</span><span id="MLPRegressor.fit-424"><a href="#MLPRegressor.fit-424"><span class="linenos">424</span></a><span class="sd">            Training data</span>
</span><span id="MLPRegressor.fit-425"><a href="#MLPRegressor.fit-425"><span class="linenos">425</span></a><span class="sd">        y : np.ndarray of shape (n_samples,) or (n_samples, n_outputs)</span>
</span><span id="MLPRegressor.fit-426"><a href="#MLPRegressor.fit-426"><span class="linenos">426</span></a><span class="sd">            Target values</span>
</span><span id="MLPRegressor.fit-427"><a href="#MLPRegressor.fit-427"><span class="linenos">427</span></a><span class="sd">            </span>
</span><span id="MLPRegressor.fit-428"><a href="#MLPRegressor.fit-428"><span class="linenos">428</span></a><span class="sd">        Returns:</span>
</span><span id="MLPRegressor.fit-429"><a href="#MLPRegressor.fit-429"><span class="linenos">429</span></a><span class="sd">        --------</span>
</span><span id="MLPRegressor.fit-430"><a href="#MLPRegressor.fit-430"><span class="linenos">430</span></a><span class="sd">        self : object</span>
</span><span id="MLPRegressor.fit-431"><a href="#MLPRegressor.fit-431"><span class="linenos">431</span></a><span class="sd">            Trained MLP</span>
</span><span id="MLPRegressor.fit-432"><a href="#MLPRegressor.fit-432"><span class="linenos">432</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor.fit-433"><a href="#MLPRegressor.fit-433"><span class="linenos">433</span></a>        <span class="c1"># Convert arrays</span>
</span><span id="MLPRegressor.fit-434"><a href="#MLPRegressor.fit-434"><span class="linenos">434</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="MLPRegressor.fit-435"><a href="#MLPRegressor.fit-435"><span class="linenos">435</span></a>        <span class="n">y_orig</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="MLPRegressor.fit-436"><a href="#MLPRegressor.fit-436"><span class="linenos">436</span></a>        
</span><span id="MLPRegressor.fit-437"><a href="#MLPRegressor.fit-437"><span class="linenos">437</span></a>        <span class="c1"># Ensure y is 2D for multi-output regression</span>
</span><span id="MLPRegressor.fit-438"><a href="#MLPRegressor.fit-438"><span class="linenos">438</span></a>        <span class="k">if</span> <span class="n">y_orig</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="MLPRegressor.fit-439"><a href="#MLPRegressor.fit-439"><span class="linenos">439</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="n">y_orig</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="MLPRegressor.fit-440"><a href="#MLPRegressor.fit-440"><span class="linenos">440</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="MLPRegressor.fit-441"><a href="#MLPRegressor.fit-441"><span class="linenos">441</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="n">y_orig</span>
</span><span id="MLPRegressor.fit-442"><a href="#MLPRegressor.fit-442"><span class="linenos">442</span></a>        
</span><span id="MLPRegressor.fit-443"><a href="#MLPRegressor.fit-443"><span class="linenos">443</span></a>        <span class="c1"># Determine output dimensionality</span>
</span><span id="MLPRegressor.fit-444"><a href="#MLPRegressor.fit-444"><span class="linenos">444</span></a>        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</span><span id="MLPRegressor.fit-445"><a href="#MLPRegressor.fit-445"><span class="linenos">445</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">n_outputs</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</span><span id="MLPRegressor.fit-446"><a href="#MLPRegressor.fit-446"><span class="linenos">446</span></a>        
</span><span id="MLPRegressor.fit-447"><a href="#MLPRegressor.fit-447"><span class="linenos">447</span></a>        <span class="c1"># Initialize weights</span>
</span><span id="MLPRegressor.fit-448"><a href="#MLPRegressor.fit-448"><span class="linenos">448</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_weights</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">)</span>
</span><span id="MLPRegressor.fit-449"><a href="#MLPRegressor.fit-449"><span class="linenos">449</span></a>        
</span><span id="MLPRegressor.fit-450"><a href="#MLPRegressor.fit-450"><span class="linenos">450</span></a>        <span class="c1"># Split into training and validation sets if early_stopping is enabled</span>
</span><span id="MLPRegressor.fit-451"><a href="#MLPRegressor.fit-451"><span class="linenos">451</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping</span><span class="p">:</span>
</span><span id="MLPRegressor.fit-452"><a href="#MLPRegressor.fit-452"><span class="linenos">452</span></a>            <span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_train_validation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="MLPRegressor.fit-453"><a href="#MLPRegressor.fit-453"><span class="linenos">453</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="MLPRegressor.fit-454"><a href="#MLPRegressor.fit-454"><span class="linenos">454</span></a>            <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</span><span id="MLPRegressor.fit-455"><a href="#MLPRegressor.fit-455"><span class="linenos">455</span></a>        
</span><span id="MLPRegressor.fit-456"><a href="#MLPRegressor.fit-456"><span class="linenos">456</span></a>        <span class="c1"># Update method according to chosen optimizer</span>
</span><span id="MLPRegressor.fit-457"><a href="#MLPRegressor.fit-457"><span class="linenos">457</span></a>        <span class="n">update_methods</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="MLPRegressor.fit-458"><a href="#MLPRegressor.fit-458"><span class="linenos">458</span></a>            <span class="s1">&#39;sgd&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights_sgd</span><span class="p">,</span>
</span><span id="MLPRegressor.fit-459"><a href="#MLPRegressor.fit-459"><span class="linenos">459</span></a>            <span class="s1">&#39;momentum&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights_momentum</span><span class="p">,</span>
</span><span id="MLPRegressor.fit-460"><a href="#MLPRegressor.fit-460"><span class="linenos">460</span></a>            <span class="s1">&#39;rmsprop&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights_rmsprop</span><span class="p">,</span>
</span><span id="MLPRegressor.fit-461"><a href="#MLPRegressor.fit-461"><span class="linenos">461</span></a>            <span class="s1">&#39;adam&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_weights_adam</span>
</span><span id="MLPRegressor.fit-462"><a href="#MLPRegressor.fit-462"><span class="linenos">462</span></a>        <span class="p">}</span>
</span><span id="MLPRegressor.fit-463"><a href="#MLPRegressor.fit-463"><span class="linenos">463</span></a>        
</span><span id="MLPRegressor.fit-464"><a href="#MLPRegressor.fit-464"><span class="linenos">464</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">update_methods</span><span class="p">:</span>
</span><span id="MLPRegressor.fit-465"><a href="#MLPRegressor.fit-465"><span class="linenos">465</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimizer &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s2">&#39; not recognized.&quot;</span><span class="p">)</span>
</span><span id="MLPRegressor.fit-466"><a href="#MLPRegressor.fit-466"><span class="linenos">466</span></a>        
</span><span id="MLPRegressor.fit-467"><a href="#MLPRegressor.fit-467"><span class="linenos">467</span></a>        <span class="n">update_weights</span> <span class="o">=</span> <span class="n">update_methods</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">]</span>
</span><span id="MLPRegressor.fit-468"><a href="#MLPRegressor.fit-468"><span class="linenos">468</span></a>        
</span><span id="MLPRegressor.fit-469"><a href="#MLPRegressor.fit-469"><span class="linenos">469</span></a>        <span class="c1"># Training over multiple epochs</span>
</span><span id="MLPRegressor.fit-470"><a href="#MLPRegressor.fit-470"><span class="linenos">470</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor.fit-471"><a href="#MLPRegressor.fit-471"><span class="linenos">471</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_loss_history</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor.fit-472"><a href="#MLPRegressor.fit-472"><span class="linenos">472</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</span><span id="MLPRegressor.fit-473"><a href="#MLPRegressor.fit-473"><span class="linenos">473</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="MLPRegressor.fit-474"><a href="#MLPRegressor.fit-474"><span class="linenos">474</span></a>        
</span><span id="MLPRegressor.fit-475"><a href="#MLPRegressor.fit-475"><span class="linenos">475</span></a>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">):</span>
</span><span id="MLPRegressor.fit-476"><a href="#MLPRegressor.fit-476"><span class="linenos">476</span></a>            <span class="c1"># Shuffle data if requested</span>
</span><span id="MLPRegressor.fit-477"><a href="#MLPRegressor.fit-477"><span class="linenos">477</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
</span><span id="MLPRegressor.fit-478"><a href="#MLPRegressor.fit-478"><span class="linenos">478</span></a>                <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>
</span><span id="MLPRegressor.fit-479"><a href="#MLPRegressor.fit-479"><span class="linenos">479</span></a>                <span class="n">X_train_shuffled</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="MLPRegressor.fit-480"><a href="#MLPRegressor.fit-480"><span class="linenos">480</span></a>                <span class="n">y_train_shuffled</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="MLPRegressor.fit-481"><a href="#MLPRegressor.fit-481"><span class="linenos">481</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="MLPRegressor.fit-482"><a href="#MLPRegressor.fit-482"><span class="linenos">482</span></a>                <span class="n">X_train_shuffled</span> <span class="o">=</span> <span class="n">X_train</span>
</span><span id="MLPRegressor.fit-483"><a href="#MLPRegressor.fit-483"><span class="linenos">483</span></a>                <span class="n">y_train_shuffled</span> <span class="o">=</span> <span class="n">y_train</span>
</span><span id="MLPRegressor.fit-484"><a href="#MLPRegressor.fit-484"><span class="linenos">484</span></a>            
</span><span id="MLPRegressor.fit-485"><a href="#MLPRegressor.fit-485"><span class="linenos">485</span></a>            <span class="c1"># Training by mini-batches</span>
</span><span id="MLPRegressor.fit-486"><a href="#MLPRegressor.fit-486"><span class="linenos">486</span></a>            <span class="n">batch_losses</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="MLPRegressor.fit-487"><a href="#MLPRegressor.fit-487"><span class="linenos">487</span></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
</span><span id="MLPRegressor.fit-488"><a href="#MLPRegressor.fit-488"><span class="linenos">488</span></a>                <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_train_shuffled</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
</span><span id="MLPRegressor.fit-489"><a href="#MLPRegressor.fit-489"><span class="linenos">489</span></a>                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_train_shuffled</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
</span><span id="MLPRegressor.fit-490"><a href="#MLPRegressor.fit-490"><span class="linenos">490</span></a>                
</span><span id="MLPRegressor.fit-491"><a href="#MLPRegressor.fit-491"><span class="linenos">491</span></a>                <span class="c1"># Forward propagation</span>
</span><span id="MLPRegressor.fit-492"><a href="#MLPRegressor.fit-492"><span class="linenos">492</span></a>                <span class="n">activations</span><span class="p">,</span> <span class="n">layer_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
</span><span id="MLPRegressor.fit-493"><a href="#MLPRegressor.fit-493"><span class="linenos">493</span></a>                
</span><span id="MLPRegressor.fit-494"><a href="#MLPRegressor.fit-494"><span class="linenos">494</span></a>                <span class="c1"># Loss calculation</span>
</span><span id="MLPRegressor.fit-495"><a href="#MLPRegressor.fit-495"><span class="linenos">495</span></a>                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">y_batch</span><span class="p">,</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="MLPRegressor.fit-496"><a href="#MLPRegressor.fit-496"><span class="linenos">496</span></a>                <span class="n">batch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</span><span id="MLPRegressor.fit-497"><a href="#MLPRegressor.fit-497"><span class="linenos">497</span></a>                
</span><span id="MLPRegressor.fit-498"><a href="#MLPRegressor.fit-498"><span class="linenos">498</span></a>                <span class="c1"># Backpropagation</span>
</span><span id="MLPRegressor.fit-499"><a href="#MLPRegressor.fit-499"><span class="linenos">499</span></a>                <span class="n">gradients_w</span><span class="p">,</span> <span class="n">gradients_b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pass</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">,</span> <span class="n">activations</span><span class="p">,</span> <span class="n">layer_inputs</span><span class="p">)</span>
</span><span id="MLPRegressor.fit-500"><a href="#MLPRegressor.fit-500"><span class="linenos">500</span></a>                
</span><span id="MLPRegressor.fit-501"><a href="#MLPRegressor.fit-501"><span class="linenos">501</span></a>                <span class="c1"># Update weights</span>
</span><span id="MLPRegressor.fit-502"><a href="#MLPRegressor.fit-502"><span class="linenos">502</span></a>                <span class="n">update_weights</span><span class="p">(</span><span class="n">gradients_w</span><span class="p">,</span> <span class="n">gradients_b</span><span class="p">)</span>
</span><span id="MLPRegressor.fit-503"><a href="#MLPRegressor.fit-503"><span class="linenos">503</span></a>            
</span><span id="MLPRegressor.fit-504"><a href="#MLPRegressor.fit-504"><span class="linenos">504</span></a>            <span class="c1"># Mean loss over the epoch</span>
</span><span id="MLPRegressor.fit-505"><a href="#MLPRegressor.fit-505"><span class="linenos">505</span></a>            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">batch_losses</span><span class="p">)</span>
</span><span id="MLPRegressor.fit-506"><a href="#MLPRegressor.fit-506"><span class="linenos">506</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)</span>
</span><span id="MLPRegressor.fit-507"><a href="#MLPRegressor.fit-507"><span class="linenos">507</span></a>            
</span><span id="MLPRegressor.fit-508"><a href="#MLPRegressor.fit-508"><span class="linenos">508</span></a>            <span class="c1"># Validation if early_stopping is enabled</span>
</span><span id="MLPRegressor.fit-509"><a href="#MLPRegressor.fit-509"><span class="linenos">509</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping</span><span class="p">:</span>
</span><span id="MLPRegressor.fit-510"><a href="#MLPRegressor.fit-510"><span class="linenos">510</span></a>                <span class="c1"># Calculate loss on validation set</span>
</span><span id="MLPRegressor.fit-511"><a href="#MLPRegressor.fit-511"><span class="linenos">511</span></a>                <span class="n">val_activations</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
</span><span id="MLPRegressor.fit-512"><a href="#MLPRegressor.fit-512"><span class="linenos">512</span></a>                <span class="n">val_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">val_activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="MLPRegressor.fit-513"><a href="#MLPRegressor.fit-513"><span class="linenos">513</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">val_loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
</span><span id="MLPRegressor.fit-514"><a href="#MLPRegressor.fit-514"><span class="linenos">514</span></a>                
</span><span id="MLPRegressor.fit-515"><a href="#MLPRegressor.fit-515"><span class="linenos">515</span></a>                <span class="c1"># Check for improvement</span>
</span><span id="MLPRegressor.fit-516"><a href="#MLPRegressor.fit-516"><span class="linenos">516</span></a>                <span class="k">if</span> <span class="n">val_loss</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">:</span>
</span><span id="MLPRegressor.fit-517"><a href="#MLPRegressor.fit-517"><span class="linenos">517</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="n">val_loss</span>
</span><span id="MLPRegressor.fit-518"><a href="#MLPRegressor.fit-518"><span class="linenos">518</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="MLPRegressor.fit-519"><a href="#MLPRegressor.fit-519"><span class="linenos">519</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="MLPRegressor.fit-520"><a href="#MLPRegressor.fit-520"><span class="linenos">520</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="MLPRegressor.fit-521"><a href="#MLPRegressor.fit-521"><span class="linenos">521</span></a>                
</span><span id="MLPRegressor.fit-522"><a href="#MLPRegressor.fit-522"><span class="linenos">522</span></a>                <span class="c1"># Early stopping</span>
</span><span id="MLPRegressor.fit-523"><a href="#MLPRegressor.fit-523"><span class="linenos">523</span></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_improvement_count</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_no_change</span><span class="p">:</span>
</span><span id="MLPRegressor.fit-524"><a href="#MLPRegressor.fit-524"><span class="linenos">524</span></a>                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Early stopping at epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="MLPRegressor.fit-525"><a href="#MLPRegressor.fit-525"><span class="linenos">525</span></a>                    <span class="k">break</span>
</span><span id="MLPRegressor.fit-526"><a href="#MLPRegressor.fit-526"><span class="linenos">526</span></a>        
</span><span id="MLPRegressor.fit-527"><a href="#MLPRegressor.fit-527"><span class="linenos">527</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">trained</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="MLPRegressor.fit-528"><a href="#MLPRegressor.fit-528"><span class="linenos">528</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span></pre></div>


            <div class="docstring"><p>Train the MLP on the provided data</p>

<h2 id="parameters">Parameters:</h2>

<p>X : np.ndarray of shape (n_samples, n_features)
    Training data
y : np.ndarray of shape (n_samples,) or (n_samples, n_outputs)
    Target values</p>

<h2 id="returns">Returns:</h2>

<p>self : object
    Trained MLP</p>
</div>


                            </div>
                            <div id="MLPRegressor.predict" class="classattr">
                                        <input id="MLPRegressor.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>:</span></span>

                <label class="view-source-button" for="MLPRegressor.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MLPRegressor.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MLPRegressor.predict-530"><a href="#MLPRegressor.predict-530"><span class="linenos">530</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="MLPRegressor.predict-531"><a href="#MLPRegressor.predict-531"><span class="linenos">531</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor.predict-532"><a href="#MLPRegressor.predict-532"><span class="linenos">532</span></a><span class="sd">        Predict target values for samples in X</span>
</span><span id="MLPRegressor.predict-533"><a href="#MLPRegressor.predict-533"><span class="linenos">533</span></a><span class="sd">        </span>
</span><span id="MLPRegressor.predict-534"><a href="#MLPRegressor.predict-534"><span class="linenos">534</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPRegressor.predict-535"><a href="#MLPRegressor.predict-535"><span class="linenos">535</span></a><span class="sd">        -----------</span>
</span><span id="MLPRegressor.predict-536"><a href="#MLPRegressor.predict-536"><span class="linenos">536</span></a><span class="sd">        X : np.ndarray of shape (n_samples, n_features)</span>
</span><span id="MLPRegressor.predict-537"><a href="#MLPRegressor.predict-537"><span class="linenos">537</span></a><span class="sd">            The data to predict</span>
</span><span id="MLPRegressor.predict-538"><a href="#MLPRegressor.predict-538"><span class="linenos">538</span></a><span class="sd">            </span>
</span><span id="MLPRegressor.predict-539"><a href="#MLPRegressor.predict-539"><span class="linenos">539</span></a><span class="sd">        Returns:</span>
</span><span id="MLPRegressor.predict-540"><a href="#MLPRegressor.predict-540"><span class="linenos">540</span></a><span class="sd">        --------</span>
</span><span id="MLPRegressor.predict-541"><a href="#MLPRegressor.predict-541"><span class="linenos">541</span></a><span class="sd">        y_pred : np.ndarray of shape (n_samples, n_outputs) or (n_samples,)</span>
</span><span id="MLPRegressor.predict-542"><a href="#MLPRegressor.predict-542"><span class="linenos">542</span></a><span class="sd">            The predicted values</span>
</span><span id="MLPRegressor.predict-543"><a href="#MLPRegressor.predict-543"><span class="linenos">543</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor.predict-544"><a href="#MLPRegressor.predict-544"><span class="linenos">544</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trained</span><span class="p">:</span>
</span><span id="MLPRegressor.predict-545"><a href="#MLPRegressor.predict-545"><span class="linenos">545</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The model must be trained before making predictions.&quot;</span><span class="p">)</span>
</span><span id="MLPRegressor.predict-546"><a href="#MLPRegressor.predict-546"><span class="linenos">546</span></a>        
</span><span id="MLPRegressor.predict-547"><a href="#MLPRegressor.predict-547"><span class="linenos">547</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="MLPRegressor.predict-548"><a href="#MLPRegressor.predict-548"><span class="linenos">548</span></a>        <span class="n">activations</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="MLPRegressor.predict-549"><a href="#MLPRegressor.predict-549"><span class="linenos">549</span></a>        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="MLPRegressor.predict-550"><a href="#MLPRegressor.predict-550"><span class="linenos">550</span></a>        
</span><span id="MLPRegressor.predict-551"><a href="#MLPRegressor.predict-551"><span class="linenos">551</span></a>        <span class="c1"># If only one output, return 1D array for consistency with sklearn</span>
</span><span id="MLPRegressor.predict-552"><a href="#MLPRegressor.predict-552"><span class="linenos">552</span></a>        <span class="k">if</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="MLPRegressor.predict-553"><a href="#MLPRegressor.predict-553"><span class="linenos">553</span></a>            <span class="k">return</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
</span><span id="MLPRegressor.predict-554"><a href="#MLPRegressor.predict-554"><span class="linenos">554</span></a>        <span class="k">return</span> <span class="n">y_pred</span>
</span></pre></div>


            <div class="docstring"><p>Predict target values for samples in X</p>

<h2 id="parameters">Parameters:</h2>

<p>X : np.ndarray of shape (n_samples, n_features)
    The data to predict</p>

<h2 id="returns">Returns:</h2>

<p>y_pred : np.ndarray of shape (n_samples, n_outputs) or (n_samples,)
    The predicted values</p>
</div>


                            </div>
                            <div id="MLPRegressor.score" class="classattr">
                                        <input id="MLPRegressor.score-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">score</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>, </span><span class="param"><span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span></span><span class="return-annotation">) -> <span class="nb">float</span>:</span></span>

                <label class="view-source-button" for="MLPRegressor.score-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MLPRegressor.score"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MLPRegressor.score-556"><a href="#MLPRegressor.score-556"><span class="linenos">556</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span><span id="MLPRegressor.score-557"><a href="#MLPRegressor.score-557"><span class="linenos">557</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="MLPRegressor.score-558"><a href="#MLPRegressor.score-558"><span class="linenos">558</span></a><span class="sd">        Return the coefficient of determination R^2 of the prediction</span>
</span><span id="MLPRegressor.score-559"><a href="#MLPRegressor.score-559"><span class="linenos">559</span></a><span class="sd">        </span>
</span><span id="MLPRegressor.score-560"><a href="#MLPRegressor.score-560"><span class="linenos">560</span></a><span class="sd">        Parameters:</span>
</span><span id="MLPRegressor.score-561"><a href="#MLPRegressor.score-561"><span class="linenos">561</span></a><span class="sd">        -----------</span>
</span><span id="MLPRegressor.score-562"><a href="#MLPRegressor.score-562"><span class="linenos">562</span></a><span class="sd">        X : np.ndarray of shape (n_samples, n_features)</span>
</span><span id="MLPRegressor.score-563"><a href="#MLPRegressor.score-563"><span class="linenos">563</span></a><span class="sd">            Test data</span>
</span><span id="MLPRegressor.score-564"><a href="#MLPRegressor.score-564"><span class="linenos">564</span></a><span class="sd">        y : np.ndarray of shape (n_samples,) or (n_samples, n_outputs)</span>
</span><span id="MLPRegressor.score-565"><a href="#MLPRegressor.score-565"><span class="linenos">565</span></a><span class="sd">            True values</span>
</span><span id="MLPRegressor.score-566"><a href="#MLPRegressor.score-566"><span class="linenos">566</span></a><span class="sd">            </span>
</span><span id="MLPRegressor.score-567"><a href="#MLPRegressor.score-567"><span class="linenos">567</span></a><span class="sd">        Returns:</span>
</span><span id="MLPRegressor.score-568"><a href="#MLPRegressor.score-568"><span class="linenos">568</span></a><span class="sd">        --------</span>
</span><span id="MLPRegressor.score-569"><a href="#MLPRegressor.score-569"><span class="linenos">569</span></a><span class="sd">        score : float</span>
</span><span id="MLPRegressor.score-570"><a href="#MLPRegressor.score-570"><span class="linenos">570</span></a><span class="sd">            R^2 score</span>
</span><span id="MLPRegressor.score-571"><a href="#MLPRegressor.score-571"><span class="linenos">571</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MLPRegressor.score-572"><a href="#MLPRegressor.score-572"><span class="linenos">572</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trained</span><span class="p">:</span>
</span><span id="MLPRegressor.score-573"><a href="#MLPRegressor.score-573"><span class="linenos">573</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The model must be trained before calculating its score.&quot;</span><span class="p">)</span>
</span><span id="MLPRegressor.score-574"><a href="#MLPRegressor.score-574"><span class="linenos">574</span></a>        
</span><span id="MLPRegressor.score-575"><a href="#MLPRegressor.score-575"><span class="linenos">575</span></a>        <span class="c1"># Ensure y is in the right shape</span>
</span><span id="MLPRegressor.score-576"><a href="#MLPRegressor.score-576"><span class="linenos">576</span></a>        <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="MLPRegressor.score-577"><a href="#MLPRegressor.score-577"><span class="linenos">577</span></a>        <span class="k">if</span> <span class="n">y_true</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="MLPRegressor.score-578"><a href="#MLPRegressor.score-578"><span class="linenos">578</span></a>            <span class="n">y_true</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="MLPRegressor.score-579"><a href="#MLPRegressor.score-579"><span class="linenos">579</span></a>        
</span><span id="MLPRegressor.score-580"><a href="#MLPRegressor.score-580"><span class="linenos">580</span></a>        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="MLPRegressor.score-581"><a href="#MLPRegressor.score-581"><span class="linenos">581</span></a>        <span class="k">if</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="MLPRegressor.score-582"><a href="#MLPRegressor.score-582"><span class="linenos">582</span></a>            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="MLPRegressor.score-583"><a href="#MLPRegressor.score-583"><span class="linenos">583</span></a>        
</span><span id="MLPRegressor.score-584"><a href="#MLPRegressor.score-584"><span class="linenos">584</span></a>        <span class="c1"># Calculate R^2 score</span>
</span><span id="MLPRegressor.score-585"><a href="#MLPRegressor.score-585"><span class="linenos">585</span></a>        <span class="n">u</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="MLPRegressor.score-586"><a href="#MLPRegressor.score-586"><span class="linenos">586</span></a>        <span class="n">v</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_true</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="MLPRegressor.score-587"><a href="#MLPRegressor.score-587"><span class="linenos">587</span></a>        
</span><span id="MLPRegressor.score-588"><a href="#MLPRegressor.score-588"><span class="linenos">588</span></a>        <span class="c1"># Avoid division by zero</span>
</span><span id="MLPRegressor.score-589"><a href="#MLPRegressor.score-589"><span class="linenos">589</span></a>        <span class="k">if</span> <span class="n">v</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="MLPRegressor.score-590"><a href="#MLPRegressor.score-590"><span class="linenos">590</span></a>            <span class="k">return</span> <span class="mf">0.0</span>
</span><span id="MLPRegressor.score-591"><a href="#MLPRegressor.score-591"><span class="linenos">591</span></a>        
</span><span id="MLPRegressor.score-592"><a href="#MLPRegressor.score-592"><span class="linenos">592</span></a>        <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">u</span> <span class="o">/</span> <span class="n">v</span>
</span></pre></div>


            <div class="docstring"><p>Return the coefficient of determination R^2 of the prediction</p>

<h2 id="parameters">Parameters:</h2>

<p>X : np.ndarray of shape (n_samples, n_features)
    Test data
y : np.ndarray of shape (n_samples,) or (n_samples, n_outputs)
    True values</p>

<h2 id="returns">Returns:</h2>

<p>score : float
    R^2 score</p>
</div>


                            </div>
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>