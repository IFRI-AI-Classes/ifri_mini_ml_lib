<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 15.0.3"/>
    <title>ifri_mini_ml_lib.model_selection API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:.75rem center;margin-bottom:1rem;}.pdoc .alert > em{display:none;}.pdoc .alert > *:last-child{margin-bottom:0;}.pdoc .alert.note{color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .alert.tip{color:#0a3622;background-color:#d1e7dd;border-color:#a3cfbb;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%230a3622%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%206a6%206%200%201%201%2010.174%204.31c-.203.196-.359.4-.453.619l-.762%201.769A.5.5%200%200%201%2010.5%2013a.5.5%200%200%201%200%201%20.5.5%200%200%201%200%201l-.224.447a1%201%200%200%201-.894.553H6.618a1%201%200%200%201-.894-.553L5.5%2015a.5.5%200%200%201%200-1%20.5.5%200%200%201%200-1%20.5.5%200%200%201-.46-.302l-.761-1.77a2%202%200%200%200-.453-.618A5.98%205.98%200%200%201%202%206m6-5a5%205%200%200%200-3.479%208.592c.263.254.514.564.676.941L5.83%2012h4.342l.632-1.467c.162-.377.413-.687.676-.941A5%205%200%200%200%208%201%22/%3E%3C/svg%3E");}.pdoc .alert.important{color:#055160;background-color:#cff4fc;border-color:#9eeaf9;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23055160%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%200a2%202%200%200%200-2%202v12a2%202%200%200%200%202%202h12a2%202%200%200%200%202-2V2a2%202%200%200%200-2-2zm6%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .alert.caution{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M11.46.146A.5.5%200%200%200%2011.107%200H4.893a.5.5%200%200%200-.353.146L.146%204.54A.5.5%200%200%200%200%204.893v6.214a.5.5%200%200%200%20.146.353l4.394%204.394a.5.5%200%200%200%20.353.146h6.214a.5.5%200%200%200%20.353-.146l4.394-4.394a.5.5%200%200%200%20.146-.353V4.893a.5.5%200%200%200-.146-.353zM8%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .decorator-deprecated{color:#842029;}.pdoc .decorator-deprecated ~ span{filter:grayscale(1) opacity(0.8);}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../ifri_mini_ml_lib.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;ifri_mini_ml_lib</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="class" href="#BaggingClassifier">BaggingClassifier</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#BaggingClassifier.__init__">BaggingClassifier</a>
                        </li>
                        <li>
                                <a class="variable" href="#BaggingClassifier.base_model">base_model</a>
                        </li>
                        <li>
                                <a class="variable" href="#BaggingClassifier.n_estimators">n_estimators</a>
                        </li>
                        <li>
                                <a class="variable" href="#BaggingClassifier.random_state">random_state</a>
                        </li>
                        <li>
                                <a class="variable" href="#BaggingClassifier.models">models</a>
                        </li>
                        <li>
                                <a class="variable" href="#BaggingClassifier.pretrained">pretrained</a>
                        </li>
                        <li>
                                <a class="function" href="#BaggingClassifier.fit">fit</a>
                        </li>
                        <li>
                                <a class="function" href="#BaggingClassifier.predict">predict</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#BaggingRegressor">BaggingRegressor</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#BaggingRegressor.__init__">BaggingRegressor</a>
                        </li>
                        <li>
                                <a class="variable" href="#BaggingRegressor.base_model">base_model</a>
                        </li>
                        <li>
                                <a class="variable" href="#BaggingRegressor.n_estimators">n_estimators</a>
                        </li>
                        <li>
                                <a class="variable" href="#BaggingRegressor.random_state">random_state</a>
                        </li>
                        <li>
                                <a class="variable" href="#BaggingRegressor.models">models</a>
                        </li>
                        <li>
                                <a class="variable" href="#BaggingRegressor.pretrained">pretrained</a>
                        </li>
                        <li>
                                <a class="function" href="#BaggingRegressor.fit">fit</a>
                        </li>
                        <li>
                                <a class="function" href="#BaggingRegressor.predict">predict</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#BayesianSearchCV">BayesianSearchCV</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#BayesianSearchCV.__init__">BayesianSearchCV</a>
                        </li>
                        <li>
                                <a class="variable" href="#BayesianSearchCV.estimator">estimator</a>
                        </li>
                        <li>
                                <a class="variable" href="#BayesianSearchCV.param_bounds">param_bounds</a>
                        </li>
                        <li>
                                <a class="variable" href="#BayesianSearchCV.n_iter">n_iter</a>
                        </li>
                        <li>
                                <a class="variable" href="#BayesianSearchCV.init_points">init_points</a>
                        </li>
                        <li>
                                <a class="variable" href="#BayesianSearchCV.cv">cv</a>
                        </li>
                        <li>
                                <a class="variable" href="#BayesianSearchCV.scoring">scoring</a>
                        </li>
                        <li>
                                <a class="variable" href="#BayesianSearchCV.stratified">stratified</a>
                        </li>
                        <li>
                                <a class="variable" href="#BayesianSearchCV.param_types">param_types</a>
                        </li>
                        <li>
                                <a class="variable" href="#BayesianSearchCV.random_state">random_state</a>
                        </li>
                        <li>
                                <a class="variable" href="#BayesianSearchCV.X_obs">X_obs</a>
                        </li>
                        <li>
                                <a class="variable" href="#BayesianSearchCV.y_obs">y_obs</a>
                        </li>
                        <li>
                                <a class="variable" href="#BayesianSearchCV.gp">gp</a>
                        </li>
                        <li>
                                <a class="variable" href="#BayesianSearchCV.maximize">maximize</a>
                        </li>
                        <li>
                                <a class="variable" href="#BayesianSearchCV.history_">history_</a>
                        </li>
                        <li>
                                <a class="function" href="#BayesianSearchCV.fit">fit</a>
                        </li>
                        <li>
                                <a class="function" href="#BayesianSearchCV.get_best_params">get_best_params</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#GridSearchCV">GridSearchCV</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#GridSearchCV.__init__">GridSearchCV</a>
                        </li>
                        <li>
                                <a class="variable" href="#GridSearchCV.model">model</a>
                        </li>
                        <li>
                                <a class="variable" href="#GridSearchCV.param_grid">param_grid</a>
                        </li>
                        <li>
                                <a class="variable" href="#GridSearchCV.k">k</a>
                        </li>
                        <li>
                                <a class="variable" href="#GridSearchCV.scoring">scoring</a>
                        </li>
                        <li>
                                <a class="variable" href="#GridSearchCV.stratified">stratified</a>
                        </li>
                        <li>
                                <a class="variable" href="#GridSearchCV.best_params_">best_params_</a>
                        </li>
                        <li>
                                <a class="variable" href="#GridSearchCV.best_score_">best_score_</a>
                        </li>
                        <li>
                                <a class="variable" href="#GridSearchCV.best_estimator_">best_estimator_</a>
                        </li>
                        <li>
                                <a class="function" href="#GridSearchCV.fit">fit</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#RandomSearchCV">RandomSearchCV</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#RandomSearchCV.__init__">RandomSearchCV</a>
                        </li>
                        <li>
                                <a class="variable" href="#RandomSearchCV.model">model</a>
                        </li>
                        <li>
                                <a class="variable" href="#RandomSearchCV.param_grid">param_grid</a>
                        </li>
                        <li>
                                <a class="variable" href="#RandomSearchCV.n_iter">n_iter</a>
                        </li>
                        <li>
                                <a class="variable" href="#RandomSearchCV.k">k</a>
                        </li>
                        <li>
                                <a class="variable" href="#RandomSearchCV.scoring">scoring</a>
                        </li>
                        <li>
                                <a class="variable" href="#RandomSearchCV.stratified">stratified</a>
                        </li>
                        <li>
                                <a class="variable" href="#RandomSearchCV.random_state">random_state</a>
                        </li>
                        <li>
                                <a class="variable" href="#RandomSearchCV.best_params_">best_params_</a>
                        </li>
                        <li>
                                <a class="variable" href="#RandomSearchCV.best_score_">best_score_</a>
                        </li>
                        <li>
                                <a class="variable" href="#RandomSearchCV.best_estimator_">best_estimator_</a>
                        </li>
                        <li>
                                <a class="function" href="#RandomSearchCV.fit">fit</a>
                        </li>
                </ul>

            </li>
    </ul>


            <footer>Â© 2025 IFRI Machine Learning Library</footer>

        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../ifri_mini_ml_lib.html">ifri_mini_ml_lib</a><wbr>.model_selection    </h1>

                
                        <input id="mod-model_selection-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-model_selection-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos"> 1</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.bagging</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaggingClassifier</span><span class="p">,</span> <span class="n">BaggingRegressor</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos"> 2</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.bayesian_searchCV</span><span class="w"> </span><span class="kn">import</span> <span class="n">BayesianSearchCV</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos"> 3</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.grid_searchCV</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos"> 4</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.random_searchCV</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomSearchCV</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos"> 5</span></a>
</span><span id="L-6"><a href="#L-6"><span class="linenos"> 6</span></a><span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos"> 7</span></a>    <span class="s2">&quot;BaggingClassifier&quot;</span><span class="p">,</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos"> 8</span></a>    <span class="s2">&quot;BaggingRegressor&quot;</span><span class="p">,</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos"> 9</span></a>    <span class="s2">&quot;BayesianSearchCV&quot;</span><span class="p">,</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos">10</span></a>    <span class="s2">&quot;GridSearchCV&quot;</span><span class="p">,</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos">11</span></a>    <span class="s2">&quot;RandomSearchCV&quot;</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos">12</span></a><span class="p">]</span>
</span></pre></div>


            </section>
                <section id="BaggingClassifier">
                            <input id="BaggingClassifier-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">BaggingClassifier</span>:

                <label class="view-source-button" for="BaggingClassifier-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaggingClassifier"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaggingClassifier-104"><a href="#BaggingClassifier-104"><span class="linenos">104</span></a><span class="k">class</span><span class="w"> </span><span class="nc">BaggingClassifier</span><span class="p">:</span>
</span><span id="BaggingClassifier-105"><a href="#BaggingClassifier-105"><span class="linenos">105</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaggingClassifier-106"><a href="#BaggingClassifier-106"><span class="linenos">106</span></a><span class="sd">    Description:</span>
</span><span id="BaggingClassifier-107"><a href="#BaggingClassifier-107"><span class="linenos">107</span></a><span class="sd">        BaggingClassifier is an implementation of the Bagging (Bootstrap Aggregating) technique for classification tasks.</span>
</span><span id="BaggingClassifier-108"><a href="#BaggingClassifier-108"><span class="linenos">108</span></a><span class="sd">        It trains multiple copies of a base classifier on bootstrap samples of the training set, and </span>
</span><span id="BaggingClassifier-109"><a href="#BaggingClassifier-109"><span class="linenos">109</span></a><span class="sd">        aggregates predictions using majority voting.</span>
</span><span id="BaggingClassifier-110"><a href="#BaggingClassifier-110"><span class="linenos">110</span></a>
</span><span id="BaggingClassifier-111"><a href="#BaggingClassifier-111"><span class="linenos">111</span></a><span class="sd">    Args:</span>
</span><span id="BaggingClassifier-112"><a href="#BaggingClassifier-112"><span class="linenos">112</span></a><span class="sd">        base_model (object): A classification model implementing `fit()` and `predict()` methods.</span>
</span><span id="BaggingClassifier-113"><a href="#BaggingClassifier-113"><span class="linenos">113</span></a><span class="sd">        n_estimators (int): Number of models to train. Default is 10.</span>
</span><span id="BaggingClassifier-114"><a href="#BaggingClassifier-114"><span class="linenos">114</span></a><span class="sd">        random_state (int, optional): Seed for reproducibility. Default is None.</span>
</span><span id="BaggingClassifier-115"><a href="#BaggingClassifier-115"><span class="linenos">115</span></a><span class="sd">        pretrained_models (list, optional): A list of already trained models to use instead of training new ones.</span>
</span><span id="BaggingClassifier-116"><a href="#BaggingClassifier-116"><span class="linenos">116</span></a>
</span><span id="BaggingClassifier-117"><a href="#BaggingClassifier-117"><span class="linenos">117</span></a><span class="sd">    Returns:</span>
</span><span id="BaggingClassifier-118"><a href="#BaggingClassifier-118"><span class="linenos">118</span></a><span class="sd">        None</span>
</span><span id="BaggingClassifier-119"><a href="#BaggingClassifier-119"><span class="linenos">119</span></a>
</span><span id="BaggingClassifier-120"><a href="#BaggingClassifier-120"><span class="linenos">120</span></a><span class="sd">    Example:</span>
</span><span id="BaggingClassifier-121"><a href="#BaggingClassifier-121"><span class="linenos">121</span></a><span class="sd">        Case 1 - base model which need fitting</span>
</span><span id="BaggingClassifier-122"><a href="#BaggingClassifier-122"><span class="linenos">122</span></a><span class="sd">        &gt;&gt;&gt; model = BaggingClassifier(base_model=DecisionTreeClassifier(), n_estimators=5, random_state=123)</span>
</span><span id="BaggingClassifier-123"><a href="#BaggingClassifier-123"><span class="linenos">123</span></a><span class="sd">        &gt;&gt;&gt; model.fit(X_train, y_train)</span>
</span><span id="BaggingClassifier-124"><a href="#BaggingClassifier-124"><span class="linenos">124</span></a><span class="sd">        &gt;&gt;&gt; y_pred = model.predict(X_test)</span>
</span><span id="BaggingClassifier-125"><a href="#BaggingClassifier-125"><span class="linenos">125</span></a>
</span><span id="BaggingClassifier-126"><a href="#BaggingClassifier-126"><span class="linenos">126</span></a><span class="sd">        Case 2 - base models already trained which don&#39;t need fitting</span>
</span><span id="BaggingClassifier-127"><a href="#BaggingClassifier-127"><span class="linenos">127</span></a><span class="sd">        &gt;&gt;&gt; trained_models = [trained_model1, trained_model2, trained_model3]</span>
</span><span id="BaggingClassifier-128"><a href="#BaggingClassifier-128"><span class="linenos">128</span></a><span class="sd">        &gt;&gt;&gt; model = BaggingClassifier(pretrained_models=trained_models)</span>
</span><span id="BaggingClassifier-129"><a href="#BaggingClassifier-129"><span class="linenos">129</span></a><span class="sd">        &gt;&gt;&gt; y_pred = model.predict(X_test)</span>
</span><span id="BaggingClassifier-130"><a href="#BaggingClassifier-130"><span class="linenos">130</span></a>
</span><span id="BaggingClassifier-131"><a href="#BaggingClassifier-131"><span class="linenos">131</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="BaggingClassifier-132"><a href="#BaggingClassifier-132"><span class="linenos">132</span></a>
</span><span id="BaggingClassifier-133"><a href="#BaggingClassifier-133"><span class="linenos">133</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">pretrained_models</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
</span><span id="BaggingClassifier-134"><a href="#BaggingClassifier-134"><span class="linenos">134</span></a>        
</span><span id="BaggingClassifier-135"><a href="#BaggingClassifier-135"><span class="linenos">135</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">base_model</span>
</span><span id="BaggingClassifier-136"><a href="#BaggingClassifier-136"><span class="linenos">136</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="n">n_estimators</span>
</span><span id="BaggingClassifier-137"><a href="#BaggingClassifier-137"><span class="linenos">137</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
</span><span id="BaggingClassifier-138"><a href="#BaggingClassifier-138"><span class="linenos">138</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">models</span> <span class="o">=</span> <span class="n">pretrained_models</span> <span class="k">if</span> <span class="n">pretrained_models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[]</span>
</span><span id="BaggingClassifier-139"><a href="#BaggingClassifier-139"><span class="linenos">139</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pretrained</span> <span class="o">=</span> <span class="n">pretrained_models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="BaggingClassifier-140"><a href="#BaggingClassifier-140"><span class="linenos">140</span></a>
</span><span id="BaggingClassifier-141"><a href="#BaggingClassifier-141"><span class="linenos">141</span></a>
</span><span id="BaggingClassifier-142"><a href="#BaggingClassifier-142"><span class="linenos">142</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="BaggingClassifier-143"><a href="#BaggingClassifier-143"><span class="linenos">143</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaggingClassifier-144"><a href="#BaggingClassifier-144"><span class="linenos">144</span></a><span class="sd">        Description:</span>
</span><span id="BaggingClassifier-145"><a href="#BaggingClassifier-145"><span class="linenos">145</span></a><span class="sd">            Trains multiple instances of the base model on bootstrap samples of the training data.</span>
</span><span id="BaggingClassifier-146"><a href="#BaggingClassifier-146"><span class="linenos">146</span></a>
</span><span id="BaggingClassifier-147"><a href="#BaggingClassifier-147"><span class="linenos">147</span></a><span class="sd">        Args:</span>
</span><span id="BaggingClassifier-148"><a href="#BaggingClassifier-148"><span class="linenos">148</span></a><span class="sd">            X (array-like): Feature matrix of shape (n_samples, n_features).</span>
</span><span id="BaggingClassifier-149"><a href="#BaggingClassifier-149"><span class="linenos">149</span></a><span class="sd">            y (array-like): Target vector of shape (n_samples,).</span>
</span><span id="BaggingClassifier-150"><a href="#BaggingClassifier-150"><span class="linenos">150</span></a>
</span><span id="BaggingClassifier-151"><a href="#BaggingClassifier-151"><span class="linenos">151</span></a><span class="sd">        Returns:</span>
</span><span id="BaggingClassifier-152"><a href="#BaggingClassifier-152"><span class="linenos">152</span></a><span class="sd">            None</span>
</span><span id="BaggingClassifier-153"><a href="#BaggingClassifier-153"><span class="linenos">153</span></a>
</span><span id="BaggingClassifier-154"><a href="#BaggingClassifier-154"><span class="linenos">154</span></a><span class="sd">        Example:</span>
</span><span id="BaggingClassifier-155"><a href="#BaggingClassifier-155"><span class="linenos">155</span></a><span class="sd">            &gt;&gt;&gt; model.fit(X_train, y_train)</span>
</span><span id="BaggingClassifier-156"><a href="#BaggingClassifier-156"><span class="linenos">156</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaggingClassifier-157"><a href="#BaggingClassifier-157"><span class="linenos">157</span></a>
</span><span id="BaggingClassifier-158"><a href="#BaggingClassifier-158"><span class="linenos">158</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pretrained</span><span class="p">:</span>
</span><span id="BaggingClassifier-159"><a href="#BaggingClassifier-159"><span class="linenos">159</span></a>            <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">:</span>
</span><span id="BaggingClassifier-160"><a href="#BaggingClassifier-160"><span class="linenos">160</span></a>                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;predict&#39;</span><span class="p">):</span>
</span><span id="BaggingClassifier-161"><a href="#BaggingClassifier-161"><span class="linenos">161</span></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Each pretrained model must implement the predict() method.&quot;</span><span class="p">)</span>
</span><span id="BaggingClassifier-162"><a href="#BaggingClassifier-162"><span class="linenos">162</span></a>            <span class="k">return</span>  <span class="c1"># Skip training</span>
</span><span id="BaggingClassifier-163"><a href="#BaggingClassifier-163"><span class="linenos">163</span></a>        
</span><span id="BaggingClassifier-164"><a href="#BaggingClassifier-164"><span class="linenos">164</span></a>        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="BaggingClassifier-165"><a href="#BaggingClassifier-165"><span class="linenos">165</span></a>        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span><span id="BaggingClassifier-166"><a href="#BaggingClassifier-166"><span class="linenos">166</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X and y must have the same number of samples.&quot;</span><span class="p">)</span>
</span><span id="BaggingClassifier-167"><a href="#BaggingClassifier-167"><span class="linenos">167</span></a>            
</span><span id="BaggingClassifier-168"><a href="#BaggingClassifier-168"><span class="linenos">168</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">,</span> <span class="s1">&#39;fit&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">,</span> <span class="s1">&#39;predict&#39;</span><span class="p">)):</span>
</span><span id="BaggingClassifier-169"><a href="#BaggingClassifier-169"><span class="linenos">169</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The base model must implement both fit() and predict() methods&quot;</span><span class="p">)</span>
</span><span id="BaggingClassifier-170"><a href="#BaggingClassifier-170"><span class="linenos">170</span></a>        
</span><span id="BaggingClassifier-171"><a href="#BaggingClassifier-171"><span class="linenos">171</span></a>        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
</span><span id="BaggingClassifier-172"><a href="#BaggingClassifier-172"><span class="linenos">172</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="BaggingClassifier-173"><a href="#BaggingClassifier-173"><span class="linenos">173</span></a>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">):</span>
</span><span id="BaggingClassifier-174"><a href="#BaggingClassifier-174"><span class="linenos">174</span></a>            <span class="c1"># Ãchantillonner avec remise</span>
</span><span id="BaggingClassifier-175"><a href="#BaggingClassifier-175"><span class="linenos">175</span></a>            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="BaggingClassifier-176"><a href="#BaggingClassifier-176"><span class="linenos">176</span></a>            <span class="n">X_sample</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="BaggingClassifier-177"><a href="#BaggingClassifier-177"><span class="linenos">177</span></a>            <span class="n">y_sample</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="BaggingClassifier-178"><a href="#BaggingClassifier-178"><span class="linenos">178</span></a>
</span><span id="BaggingClassifier-179"><a href="#BaggingClassifier-179"><span class="linenos">179</span></a>            <span class="n">model</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">)</span>
</span><span id="BaggingClassifier-180"><a href="#BaggingClassifier-180"><span class="linenos">180</span></a>            
</span><span id="BaggingClassifier-181"><a href="#BaggingClassifier-181"><span class="linenos">181</span></a>            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sample</span><span class="p">,</span> <span class="n">y_sample</span><span class="p">)</span>
</span><span id="BaggingClassifier-182"><a href="#BaggingClassifier-182"><span class="linenos">182</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span><span id="BaggingClassifier-183"><a href="#BaggingClassifier-183"><span class="linenos">183</span></a>
</span><span id="BaggingClassifier-184"><a href="#BaggingClassifier-184"><span class="linenos">184</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="BaggingClassifier-185"><a href="#BaggingClassifier-185"><span class="linenos">185</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaggingClassifier-186"><a href="#BaggingClassifier-186"><span class="linenos">186</span></a><span class="sd">        Description:</span>
</span><span id="BaggingClassifier-187"><a href="#BaggingClassifier-187"><span class="linenos">187</span></a><span class="sd">            Predicts target classes for given input samples using majority voting across all models.</span>
</span><span id="BaggingClassifier-188"><a href="#BaggingClassifier-188"><span class="linenos">188</span></a>
</span><span id="BaggingClassifier-189"><a href="#BaggingClassifier-189"><span class="linenos">189</span></a><span class="sd">        Args:</span>
</span><span id="BaggingClassifier-190"><a href="#BaggingClassifier-190"><span class="linenos">190</span></a><span class="sd">            X (array-like): Feature matrix of shape (n_samples, n_features).</span>
</span><span id="BaggingClassifier-191"><a href="#BaggingClassifier-191"><span class="linenos">191</span></a>
</span><span id="BaggingClassifier-192"><a href="#BaggingClassifier-192"><span class="linenos">192</span></a><span class="sd">        Returns:</span>
</span><span id="BaggingClassifier-193"><a href="#BaggingClassifier-193"><span class="linenos">193</span></a><span class="sd">            np.ndarray: Predicted class labels for all samples.</span>
</span><span id="BaggingClassifier-194"><a href="#BaggingClassifier-194"><span class="linenos">194</span></a>
</span><span id="BaggingClassifier-195"><a href="#BaggingClassifier-195"><span class="linenos">195</span></a><span class="sd">        Example:</span>
</span><span id="BaggingClassifier-196"><a href="#BaggingClassifier-196"><span class="linenos">196</span></a><span class="sd">            &gt;&gt;&gt; y_pred = model.predict(X_test)</span>
</span><span id="BaggingClassifier-197"><a href="#BaggingClassifier-197"><span class="linenos">197</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaggingClassifier-198"><a href="#BaggingClassifier-198"><span class="linenos">198</span></a>
</span><span id="BaggingClassifier-199"><a href="#BaggingClassifier-199"><span class="linenos">199</span></a>        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</span><span id="BaggingClassifier-200"><a href="#BaggingClassifier-200"><span class="linenos">200</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">):</span>
</span><span id="BaggingClassifier-201"><a href="#BaggingClassifier-201"><span class="linenos">201</span></a>            <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="BaggingClassifier-202"><a href="#BaggingClassifier-202"><span class="linenos">202</span></a>
</span><span id="BaggingClassifier-203"><a href="#BaggingClassifier-203"><span class="linenos">203</span></a>        <span class="c1">#return np.array([np.argmax(np.bincount(predictions[:, i].astype(int))) for i in range(X.shape[0])])</span>
</span><span id="BaggingClassifier-204"><a href="#BaggingClassifier-204"><span class="linenos">204</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">mode</span>
</span><span id="BaggingClassifier-205"><a href="#BaggingClassifier-205"><span class="linenos">205</span></a>        <span class="k">return</span> <span class="n">mode</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Description:
    BaggingClassifier is an implementation of the Bagging (Bootstrap Aggregating) technique for classification tasks.
    It trains multiple copies of a base classifier on bootstrap samples of the training set, and 
    aggregates predictions using majority voting.</p>

<p>Args:
    base_model (object): A classification model implementing <code><a href="#BaggingClassifier.fit">fit()</a></code> and <code><a href="#BaggingClassifier.predict">predict()</a></code> methods.
    n_estimators (int): Number of models to train. Default is 10.
    random_state (int, optional): Seed for reproducibility. Default is None.
    pretrained_models (list, optional): A list of already trained models to use instead of training new ones.</p>

<p>Returns:
    None</p>

<p>Example:
    Case 1 - base model which need fitting</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>model = BaggingClassifier(base_model=DecisionTreeClassifier(), n_estimators=5, random_state=123)
      model.fit(X_train, y_train)
      y_pred = model.predict(X_test)</p>

<pre><code>Case 2 - base models already trained which don't need fitting
&gt;&gt;&gt; trained_models = [trained_model1, trained_model2, trained_model3]
&gt;&gt;&gt; model = BaggingClassifier(pretrained_models=trained_models)
&gt;&gt;&gt; y_pred = model.predict(X_test)
</code></pre>
    </blockquote>
  </blockquote>
</blockquote>
</div>


                            <div id="BaggingClassifier.__init__" class="classattr">
                                        <input id="BaggingClassifier.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">BaggingClassifier</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">base_model</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span>,</span><span class="param">	<span class="n">random_state</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">pretrained_models</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="BaggingClassifier.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaggingClassifier.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaggingClassifier.__init__-133"><a href="#BaggingClassifier.__init__-133"><span class="linenos">133</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">pretrained_models</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
</span><span id="BaggingClassifier.__init__-134"><a href="#BaggingClassifier.__init__-134"><span class="linenos">134</span></a>        
</span><span id="BaggingClassifier.__init__-135"><a href="#BaggingClassifier.__init__-135"><span class="linenos">135</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">base_model</span>
</span><span id="BaggingClassifier.__init__-136"><a href="#BaggingClassifier.__init__-136"><span class="linenos">136</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="n">n_estimators</span>
</span><span id="BaggingClassifier.__init__-137"><a href="#BaggingClassifier.__init__-137"><span class="linenos">137</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
</span><span id="BaggingClassifier.__init__-138"><a href="#BaggingClassifier.__init__-138"><span class="linenos">138</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">models</span> <span class="o">=</span> <span class="n">pretrained_models</span> <span class="k">if</span> <span class="n">pretrained_models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[]</span>
</span><span id="BaggingClassifier.__init__-139"><a href="#BaggingClassifier.__init__-139"><span class="linenos">139</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pretrained</span> <span class="o">=</span> <span class="n">pretrained_models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span></pre></div>


    

                            </div>
                            <div id="BaggingClassifier.base_model" class="classattr">
                                <div class="attr variable">
            <span class="name">base_model</span>

        
    </div>
    <a class="headerlink" href="#BaggingClassifier.base_model"></a>
    
    

                            </div>
                            <div id="BaggingClassifier.n_estimators" class="classattr">
                                <div class="attr variable">
            <span class="name">n_estimators</span>

        
    </div>
    <a class="headerlink" href="#BaggingClassifier.n_estimators"></a>
    
    

                            </div>
                            <div id="BaggingClassifier.random_state" class="classattr">
                                <div class="attr variable">
            <span class="name">random_state</span>

        
    </div>
    <a class="headerlink" href="#BaggingClassifier.random_state"></a>
    
    

                            </div>
                            <div id="BaggingClassifier.models" class="classattr">
                                <div class="attr variable">
            <span class="name">models</span>

        
    </div>
    <a class="headerlink" href="#BaggingClassifier.models"></a>
    
    

                            </div>
                            <div id="BaggingClassifier.pretrained" class="classattr">
                                <div class="attr variable">
            <span class="name">pretrained</span>

        
    </div>
    <a class="headerlink" href="#BaggingClassifier.pretrained"></a>
    
    

                            </div>
                            <div id="BaggingClassifier.fit" class="classattr">
                                        <input id="BaggingClassifier.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="n">y</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="BaggingClassifier.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaggingClassifier.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaggingClassifier.fit-142"><a href="#BaggingClassifier.fit-142"><span class="linenos">142</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="BaggingClassifier.fit-143"><a href="#BaggingClassifier.fit-143"><span class="linenos">143</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaggingClassifier.fit-144"><a href="#BaggingClassifier.fit-144"><span class="linenos">144</span></a><span class="sd">        Description:</span>
</span><span id="BaggingClassifier.fit-145"><a href="#BaggingClassifier.fit-145"><span class="linenos">145</span></a><span class="sd">            Trains multiple instances of the base model on bootstrap samples of the training data.</span>
</span><span id="BaggingClassifier.fit-146"><a href="#BaggingClassifier.fit-146"><span class="linenos">146</span></a>
</span><span id="BaggingClassifier.fit-147"><a href="#BaggingClassifier.fit-147"><span class="linenos">147</span></a><span class="sd">        Args:</span>
</span><span id="BaggingClassifier.fit-148"><a href="#BaggingClassifier.fit-148"><span class="linenos">148</span></a><span class="sd">            X (array-like): Feature matrix of shape (n_samples, n_features).</span>
</span><span id="BaggingClassifier.fit-149"><a href="#BaggingClassifier.fit-149"><span class="linenos">149</span></a><span class="sd">            y (array-like): Target vector of shape (n_samples,).</span>
</span><span id="BaggingClassifier.fit-150"><a href="#BaggingClassifier.fit-150"><span class="linenos">150</span></a>
</span><span id="BaggingClassifier.fit-151"><a href="#BaggingClassifier.fit-151"><span class="linenos">151</span></a><span class="sd">        Returns:</span>
</span><span id="BaggingClassifier.fit-152"><a href="#BaggingClassifier.fit-152"><span class="linenos">152</span></a><span class="sd">            None</span>
</span><span id="BaggingClassifier.fit-153"><a href="#BaggingClassifier.fit-153"><span class="linenos">153</span></a>
</span><span id="BaggingClassifier.fit-154"><a href="#BaggingClassifier.fit-154"><span class="linenos">154</span></a><span class="sd">        Example:</span>
</span><span id="BaggingClassifier.fit-155"><a href="#BaggingClassifier.fit-155"><span class="linenos">155</span></a><span class="sd">            &gt;&gt;&gt; model.fit(X_train, y_train)</span>
</span><span id="BaggingClassifier.fit-156"><a href="#BaggingClassifier.fit-156"><span class="linenos">156</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaggingClassifier.fit-157"><a href="#BaggingClassifier.fit-157"><span class="linenos">157</span></a>
</span><span id="BaggingClassifier.fit-158"><a href="#BaggingClassifier.fit-158"><span class="linenos">158</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pretrained</span><span class="p">:</span>
</span><span id="BaggingClassifier.fit-159"><a href="#BaggingClassifier.fit-159"><span class="linenos">159</span></a>            <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">:</span>
</span><span id="BaggingClassifier.fit-160"><a href="#BaggingClassifier.fit-160"><span class="linenos">160</span></a>                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;predict&#39;</span><span class="p">):</span>
</span><span id="BaggingClassifier.fit-161"><a href="#BaggingClassifier.fit-161"><span class="linenos">161</span></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Each pretrained model must implement the predict() method.&quot;</span><span class="p">)</span>
</span><span id="BaggingClassifier.fit-162"><a href="#BaggingClassifier.fit-162"><span class="linenos">162</span></a>            <span class="k">return</span>  <span class="c1"># Skip training</span>
</span><span id="BaggingClassifier.fit-163"><a href="#BaggingClassifier.fit-163"><span class="linenos">163</span></a>        
</span><span id="BaggingClassifier.fit-164"><a href="#BaggingClassifier.fit-164"><span class="linenos">164</span></a>        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="BaggingClassifier.fit-165"><a href="#BaggingClassifier.fit-165"><span class="linenos">165</span></a>        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span><span id="BaggingClassifier.fit-166"><a href="#BaggingClassifier.fit-166"><span class="linenos">166</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X and y must have the same number of samples.&quot;</span><span class="p">)</span>
</span><span id="BaggingClassifier.fit-167"><a href="#BaggingClassifier.fit-167"><span class="linenos">167</span></a>            
</span><span id="BaggingClassifier.fit-168"><a href="#BaggingClassifier.fit-168"><span class="linenos">168</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">,</span> <span class="s1">&#39;fit&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">,</span> <span class="s1">&#39;predict&#39;</span><span class="p">)):</span>
</span><span id="BaggingClassifier.fit-169"><a href="#BaggingClassifier.fit-169"><span class="linenos">169</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The base model must implement both fit() and predict() methods&quot;</span><span class="p">)</span>
</span><span id="BaggingClassifier.fit-170"><a href="#BaggingClassifier.fit-170"><span class="linenos">170</span></a>        
</span><span id="BaggingClassifier.fit-171"><a href="#BaggingClassifier.fit-171"><span class="linenos">171</span></a>        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
</span><span id="BaggingClassifier.fit-172"><a href="#BaggingClassifier.fit-172"><span class="linenos">172</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="BaggingClassifier.fit-173"><a href="#BaggingClassifier.fit-173"><span class="linenos">173</span></a>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">):</span>
</span><span id="BaggingClassifier.fit-174"><a href="#BaggingClassifier.fit-174"><span class="linenos">174</span></a>            <span class="c1"># Ãchantillonner avec remise</span>
</span><span id="BaggingClassifier.fit-175"><a href="#BaggingClassifier.fit-175"><span class="linenos">175</span></a>            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="BaggingClassifier.fit-176"><a href="#BaggingClassifier.fit-176"><span class="linenos">176</span></a>            <span class="n">X_sample</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="BaggingClassifier.fit-177"><a href="#BaggingClassifier.fit-177"><span class="linenos">177</span></a>            <span class="n">y_sample</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="BaggingClassifier.fit-178"><a href="#BaggingClassifier.fit-178"><span class="linenos">178</span></a>
</span><span id="BaggingClassifier.fit-179"><a href="#BaggingClassifier.fit-179"><span class="linenos">179</span></a>            <span class="n">model</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">)</span>
</span><span id="BaggingClassifier.fit-180"><a href="#BaggingClassifier.fit-180"><span class="linenos">180</span></a>            
</span><span id="BaggingClassifier.fit-181"><a href="#BaggingClassifier.fit-181"><span class="linenos">181</span></a>            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sample</span><span class="p">,</span> <span class="n">y_sample</span><span class="p">)</span>
</span><span id="BaggingClassifier.fit-182"><a href="#BaggingClassifier.fit-182"><span class="linenos">182</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Description:
    Trains multiple instances of the base model on bootstrap samples of the training data.</p>

<p>Args:
    X (array-like): Feature matrix of shape (n_samples, n_features).
    y (array-like): Target vector of shape (n_samples,).</p>

<p>Returns:
    None</p>

<p>Example:</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>model.fit(X_train, y_train)</p>
    </blockquote>
  </blockquote>
</blockquote>
</div>


                            </div>
                            <div id="BaggingClassifier.predict" class="classattr">
                                        <input id="BaggingClassifier.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="BaggingClassifier.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaggingClassifier.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaggingClassifier.predict-184"><a href="#BaggingClassifier.predict-184"><span class="linenos">184</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="BaggingClassifier.predict-185"><a href="#BaggingClassifier.predict-185"><span class="linenos">185</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaggingClassifier.predict-186"><a href="#BaggingClassifier.predict-186"><span class="linenos">186</span></a><span class="sd">        Description:</span>
</span><span id="BaggingClassifier.predict-187"><a href="#BaggingClassifier.predict-187"><span class="linenos">187</span></a><span class="sd">            Predicts target classes for given input samples using majority voting across all models.</span>
</span><span id="BaggingClassifier.predict-188"><a href="#BaggingClassifier.predict-188"><span class="linenos">188</span></a>
</span><span id="BaggingClassifier.predict-189"><a href="#BaggingClassifier.predict-189"><span class="linenos">189</span></a><span class="sd">        Args:</span>
</span><span id="BaggingClassifier.predict-190"><a href="#BaggingClassifier.predict-190"><span class="linenos">190</span></a><span class="sd">            X (array-like): Feature matrix of shape (n_samples, n_features).</span>
</span><span id="BaggingClassifier.predict-191"><a href="#BaggingClassifier.predict-191"><span class="linenos">191</span></a>
</span><span id="BaggingClassifier.predict-192"><a href="#BaggingClassifier.predict-192"><span class="linenos">192</span></a><span class="sd">        Returns:</span>
</span><span id="BaggingClassifier.predict-193"><a href="#BaggingClassifier.predict-193"><span class="linenos">193</span></a><span class="sd">            np.ndarray: Predicted class labels for all samples.</span>
</span><span id="BaggingClassifier.predict-194"><a href="#BaggingClassifier.predict-194"><span class="linenos">194</span></a>
</span><span id="BaggingClassifier.predict-195"><a href="#BaggingClassifier.predict-195"><span class="linenos">195</span></a><span class="sd">        Example:</span>
</span><span id="BaggingClassifier.predict-196"><a href="#BaggingClassifier.predict-196"><span class="linenos">196</span></a><span class="sd">            &gt;&gt;&gt; y_pred = model.predict(X_test)</span>
</span><span id="BaggingClassifier.predict-197"><a href="#BaggingClassifier.predict-197"><span class="linenos">197</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaggingClassifier.predict-198"><a href="#BaggingClassifier.predict-198"><span class="linenos">198</span></a>
</span><span id="BaggingClassifier.predict-199"><a href="#BaggingClassifier.predict-199"><span class="linenos">199</span></a>        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</span><span id="BaggingClassifier.predict-200"><a href="#BaggingClassifier.predict-200"><span class="linenos">200</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">):</span>
</span><span id="BaggingClassifier.predict-201"><a href="#BaggingClassifier.predict-201"><span class="linenos">201</span></a>            <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="BaggingClassifier.predict-202"><a href="#BaggingClassifier.predict-202"><span class="linenos">202</span></a>
</span><span id="BaggingClassifier.predict-203"><a href="#BaggingClassifier.predict-203"><span class="linenos">203</span></a>        <span class="c1">#return np.array([np.argmax(np.bincount(predictions[:, i].astype(int))) for i in range(X.shape[0])])</span>
</span><span id="BaggingClassifier.predict-204"><a href="#BaggingClassifier.predict-204"><span class="linenos">204</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">mode</span>
</span><span id="BaggingClassifier.predict-205"><a href="#BaggingClassifier.predict-205"><span class="linenos">205</span></a>        <span class="k">return</span> <span class="n">mode</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Description:
    Predicts target classes for given input samples using majority voting across all models.</p>

<p>Args:
    X (array-like): Feature matrix of shape (n_samples, n_features).</p>

<p>Returns:
    np.ndarray: Predicted class labels for all samples.</p>

<p>Example:</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>y_pred = model.predict(X_test)</p>
    </blockquote>
  </blockquote>
</blockquote>
</div>


                            </div>
                </section>
                <section id="BaggingRegressor">
                            <input id="BaggingRegressor-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">BaggingRegressor</span>:

                <label class="view-source-button" for="BaggingRegressor-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaggingRegressor"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaggingRegressor-5"><a href="#BaggingRegressor-5"><span class="linenos">  5</span></a><span class="k">class</span><span class="w"> </span><span class="nc">BaggingRegressor</span><span class="p">:</span>
</span><span id="BaggingRegressor-6"><a href="#BaggingRegressor-6"><span class="linenos">  6</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaggingRegressor-7"><a href="#BaggingRegressor-7"><span class="linenos">  7</span></a><span class="sd">    Description:</span>
</span><span id="BaggingRegressor-8"><a href="#BaggingRegressor-8"><span class="linenos">  8</span></a><span class="sd">        BaggingRegressor is an implementation of the Bagging (Bootstrap Aggregating) technique for regression tasks.</span>
</span><span id="BaggingRegressor-9"><a href="#BaggingRegressor-9"><span class="linenos">  9</span></a><span class="sd">        It trains multiple copies of a base model on different bootstrap samples of the training set, and </span>
</span><span id="BaggingRegressor-10"><a href="#BaggingRegressor-10"><span class="linenos"> 10</span></a><span class="sd">        aggregates predictions by averaging them.</span>
</span><span id="BaggingRegressor-11"><a href="#BaggingRegressor-11"><span class="linenos"> 11</span></a>
</span><span id="BaggingRegressor-12"><a href="#BaggingRegressor-12"><span class="linenos"> 12</span></a><span class="sd">    Args:</span>
</span><span id="BaggingRegressor-13"><a href="#BaggingRegressor-13"><span class="linenos"> 13</span></a><span class="sd">        base_model (object): A regression model implementing `fit()` and `predict()` methods.</span>
</span><span id="BaggingRegressor-14"><a href="#BaggingRegressor-14"><span class="linenos"> 14</span></a><span class="sd">        n_estimators (int): Number of models to train. Default is 10.</span>
</span><span id="BaggingRegressor-15"><a href="#BaggingRegressor-15"><span class="linenos"> 15</span></a><span class="sd">        random_state (int, optional): Seed for reproducibility. Default is None.</span>
</span><span id="BaggingRegressor-16"><a href="#BaggingRegressor-16"><span class="linenos"> 16</span></a><span class="sd">        pretrained_models (list, optional): A list of already trained models to use instead of training new ones.</span>
</span><span id="BaggingRegressor-17"><a href="#BaggingRegressor-17"><span class="linenos"> 17</span></a>
</span><span id="BaggingRegressor-18"><a href="#BaggingRegressor-18"><span class="linenos"> 18</span></a><span class="sd">    Returns:</span>
</span><span id="BaggingRegressor-19"><a href="#BaggingRegressor-19"><span class="linenos"> 19</span></a><span class="sd">        None</span>
</span><span id="BaggingRegressor-20"><a href="#BaggingRegressor-20"><span class="linenos"> 20</span></a>
</span><span id="BaggingRegressor-21"><a href="#BaggingRegressor-21"><span class="linenos"> 21</span></a><span class="sd">    Example:</span>
</span><span id="BaggingRegressor-22"><a href="#BaggingRegressor-22"><span class="linenos"> 22</span></a><span class="sd">        Case 1 - base model which need fitting</span>
</span><span id="BaggingRegressor-23"><a href="#BaggingRegressor-23"><span class="linenos"> 23</span></a><span class="sd">        &gt;&gt;&gt; model = BaggingRegressor(base_model=DecisionTreeRegressor(), n_estimators=5, random_state=123)</span>
</span><span id="BaggingRegressor-24"><a href="#BaggingRegressor-24"><span class="linenos"> 24</span></a><span class="sd">        &gt;&gt;&gt; model.fit(X_train, y_train)</span>
</span><span id="BaggingRegressor-25"><a href="#BaggingRegressor-25"><span class="linenos"> 25</span></a><span class="sd">        &gt;&gt;&gt; y_pred = model.predict(X_test)</span>
</span><span id="BaggingRegressor-26"><a href="#BaggingRegressor-26"><span class="linenos"> 26</span></a>
</span><span id="BaggingRegressor-27"><a href="#BaggingRegressor-27"><span class="linenos"> 27</span></a><span class="sd">        Case 2 - base models already trained which don&#39;t need fitting</span>
</span><span id="BaggingRegressor-28"><a href="#BaggingRegressor-28"><span class="linenos"> 28</span></a><span class="sd">        &gt;&gt;&gt; trained_models = [trained_model1, trained_model2, trained_model3]</span>
</span><span id="BaggingRegressor-29"><a href="#BaggingRegressor-29"><span class="linenos"> 29</span></a><span class="sd">        &gt;&gt;&gt; model = BaggingRegressor(pretrained_models=trained_models)</span>
</span><span id="BaggingRegressor-30"><a href="#BaggingRegressor-30"><span class="linenos"> 30</span></a><span class="sd">        &gt;&gt;&gt; y_pred = model.predict(X_test)</span>
</span><span id="BaggingRegressor-31"><a href="#BaggingRegressor-31"><span class="linenos"> 31</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="BaggingRegressor-32"><a href="#BaggingRegressor-32"><span class="linenos"> 32</span></a>
</span><span id="BaggingRegressor-33"><a href="#BaggingRegressor-33"><span class="linenos"> 33</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_model</span><span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pretrained_models</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
</span><span id="BaggingRegressor-34"><a href="#BaggingRegressor-34"><span class="linenos"> 34</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">base_model</span>
</span><span id="BaggingRegressor-35"><a href="#BaggingRegressor-35"><span class="linenos"> 35</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="n">n_estimators</span>
</span><span id="BaggingRegressor-36"><a href="#BaggingRegressor-36"><span class="linenos"> 36</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
</span><span id="BaggingRegressor-37"><a href="#BaggingRegressor-37"><span class="linenos"> 37</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">models</span> <span class="o">=</span> <span class="n">pretrained_models</span> <span class="k">if</span> <span class="n">pretrained_models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[]</span>
</span><span id="BaggingRegressor-38"><a href="#BaggingRegressor-38"><span class="linenos"> 38</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pretrained</span> <span class="o">=</span> <span class="n">pretrained_models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="BaggingRegressor-39"><a href="#BaggingRegressor-39"><span class="linenos"> 39</span></a>
</span><span id="BaggingRegressor-40"><a href="#BaggingRegressor-40"><span class="linenos"> 40</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="BaggingRegressor-41"><a href="#BaggingRegressor-41"><span class="linenos"> 41</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaggingRegressor-42"><a href="#BaggingRegressor-42"><span class="linenos"> 42</span></a><span class="sd">        Description:</span>
</span><span id="BaggingRegressor-43"><a href="#BaggingRegressor-43"><span class="linenos"> 43</span></a><span class="sd">            Trains multiple instances of the base model on bootstrap samples of the training data.</span>
</span><span id="BaggingRegressor-44"><a href="#BaggingRegressor-44"><span class="linenos"> 44</span></a>
</span><span id="BaggingRegressor-45"><a href="#BaggingRegressor-45"><span class="linenos"> 45</span></a><span class="sd">        Args:</span>
</span><span id="BaggingRegressor-46"><a href="#BaggingRegressor-46"><span class="linenos"> 46</span></a><span class="sd">            X (array-like): Feature matrix of shape (n_samples, n_features).</span>
</span><span id="BaggingRegressor-47"><a href="#BaggingRegressor-47"><span class="linenos"> 47</span></a><span class="sd">            y (array-like): Target vector of shape (n_samples,).</span>
</span><span id="BaggingRegressor-48"><a href="#BaggingRegressor-48"><span class="linenos"> 48</span></a>
</span><span id="BaggingRegressor-49"><a href="#BaggingRegressor-49"><span class="linenos"> 49</span></a><span class="sd">        Returns:</span>
</span><span id="BaggingRegressor-50"><a href="#BaggingRegressor-50"><span class="linenos"> 50</span></a><span class="sd">            None</span>
</span><span id="BaggingRegressor-51"><a href="#BaggingRegressor-51"><span class="linenos"> 51</span></a>
</span><span id="BaggingRegressor-52"><a href="#BaggingRegressor-52"><span class="linenos"> 52</span></a><span class="sd">        Example:</span>
</span><span id="BaggingRegressor-53"><a href="#BaggingRegressor-53"><span class="linenos"> 53</span></a><span class="sd">            &gt;&gt;&gt; model.fit(X_train, y_train)</span>
</span><span id="BaggingRegressor-54"><a href="#BaggingRegressor-54"><span class="linenos"> 54</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaggingRegressor-55"><a href="#BaggingRegressor-55"><span class="linenos"> 55</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pretrained</span><span class="p">:</span>
</span><span id="BaggingRegressor-56"><a href="#BaggingRegressor-56"><span class="linenos"> 56</span></a>            <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">:</span>
</span><span id="BaggingRegressor-57"><a href="#BaggingRegressor-57"><span class="linenos"> 57</span></a>                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;predict&#39;</span><span class="p">):</span>
</span><span id="BaggingRegressor-58"><a href="#BaggingRegressor-58"><span class="linenos"> 58</span></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Each pretrained model must implement the predict() method.&quot;</span><span class="p">)</span>
</span><span id="BaggingRegressor-59"><a href="#BaggingRegressor-59"><span class="linenos"> 59</span></a>            <span class="k">return</span> <span class="c1">#We skip training</span>
</span><span id="BaggingRegressor-60"><a href="#BaggingRegressor-60"><span class="linenos"> 60</span></a>        
</span><span id="BaggingRegressor-61"><a href="#BaggingRegressor-61"><span class="linenos"> 61</span></a>
</span><span id="BaggingRegressor-62"><a href="#BaggingRegressor-62"><span class="linenos"> 62</span></a>        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="BaggingRegressor-63"><a href="#BaggingRegressor-63"><span class="linenos"> 63</span></a>        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span><span id="BaggingRegressor-64"><a href="#BaggingRegressor-64"><span class="linenos"> 64</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X and y must have the same number of samples.&quot;</span><span class="p">)</span>
</span><span id="BaggingRegressor-65"><a href="#BaggingRegressor-65"><span class="linenos"> 65</span></a>            
</span><span id="BaggingRegressor-66"><a href="#BaggingRegressor-66"><span class="linenos"> 66</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">,</span> <span class="s1">&#39;fit&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">,</span> <span class="s1">&#39;predict&#39;</span><span class="p">)):</span>
</span><span id="BaggingRegressor-67"><a href="#BaggingRegressor-67"><span class="linenos"> 67</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The base model must implement both fit() and predict() methods.&quot;</span><span class="p">)</span>
</span><span id="BaggingRegressor-68"><a href="#BaggingRegressor-68"><span class="linenos"> 68</span></a>        
</span><span id="BaggingRegressor-69"><a href="#BaggingRegressor-69"><span class="linenos"> 69</span></a>        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
</span><span id="BaggingRegressor-70"><a href="#BaggingRegressor-70"><span class="linenos"> 70</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="BaggingRegressor-71"><a href="#BaggingRegressor-71"><span class="linenos"> 71</span></a>        
</span><span id="BaggingRegressor-72"><a href="#BaggingRegressor-72"><span class="linenos"> 72</span></a>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">):</span>
</span><span id="BaggingRegressor-73"><a href="#BaggingRegressor-73"><span class="linenos"> 73</span></a>            <span class="c1"># Ãchantillonner avec remise</span>
</span><span id="BaggingRegressor-74"><a href="#BaggingRegressor-74"><span class="linenos"> 74</span></a>            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="BaggingRegressor-75"><a href="#BaggingRegressor-75"><span class="linenos"> 75</span></a>            <span class="n">X_sample</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="BaggingRegressor-76"><a href="#BaggingRegressor-76"><span class="linenos"> 76</span></a>            <span class="n">y_sample</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="BaggingRegressor-77"><a href="#BaggingRegressor-77"><span class="linenos"> 77</span></a>
</span><span id="BaggingRegressor-78"><a href="#BaggingRegressor-78"><span class="linenos"> 78</span></a>            <span class="c1">#model = self.base_model</span>
</span><span id="BaggingRegressor-79"><a href="#BaggingRegressor-79"><span class="linenos"> 79</span></a>            <span class="n">model</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">)</span>            
</span><span id="BaggingRegressor-80"><a href="#BaggingRegressor-80"><span class="linenos"> 80</span></a>            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sample</span><span class="p">,</span> <span class="n">y_sample</span><span class="p">)</span>
</span><span id="BaggingRegressor-81"><a href="#BaggingRegressor-81"><span class="linenos"> 81</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span><span id="BaggingRegressor-82"><a href="#BaggingRegressor-82"><span class="linenos"> 82</span></a>
</span><span id="BaggingRegressor-83"><a href="#BaggingRegressor-83"><span class="linenos"> 83</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="BaggingRegressor-84"><a href="#BaggingRegressor-84"><span class="linenos"> 84</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaggingRegressor-85"><a href="#BaggingRegressor-85"><span class="linenos"> 85</span></a><span class="sd">        Description:</span>
</span><span id="BaggingRegressor-86"><a href="#BaggingRegressor-86"><span class="linenos"> 86</span></a><span class="sd">            Predicts target values for given input samples by averaging the predictions of all models.</span>
</span><span id="BaggingRegressor-87"><a href="#BaggingRegressor-87"><span class="linenos"> 87</span></a>
</span><span id="BaggingRegressor-88"><a href="#BaggingRegressor-88"><span class="linenos"> 88</span></a><span class="sd">        Args:</span>
</span><span id="BaggingRegressor-89"><a href="#BaggingRegressor-89"><span class="linenos"> 89</span></a><span class="sd">            X (array-like): Feature matrix of shape (n_samples, n_features).</span>
</span><span id="BaggingRegressor-90"><a href="#BaggingRegressor-90"><span class="linenos"> 90</span></a>
</span><span id="BaggingRegressor-91"><a href="#BaggingRegressor-91"><span class="linenos"> 91</span></a><span class="sd">        Returns:</span>
</span><span id="BaggingRegressor-92"><a href="#BaggingRegressor-92"><span class="linenos"> 92</span></a><span class="sd">            np.ndarray: Averaged predictions for all samples.</span>
</span><span id="BaggingRegressor-93"><a href="#BaggingRegressor-93"><span class="linenos"> 93</span></a>
</span><span id="BaggingRegressor-94"><a href="#BaggingRegressor-94"><span class="linenos"> 94</span></a><span class="sd">        Example:</span>
</span><span id="BaggingRegressor-95"><a href="#BaggingRegressor-95"><span class="linenos"> 95</span></a><span class="sd">            &gt;&gt;&gt; y_pred = model.predict(X_test)</span>
</span><span id="BaggingRegressor-96"><a href="#BaggingRegressor-96"><span class="linenos"> 96</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaggingRegressor-97"><a href="#BaggingRegressor-97"><span class="linenos"> 97</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="BaggingRegressor-98"><a href="#BaggingRegressor-98"><span class="linenos"> 98</span></a>        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</span><span id="BaggingRegressor-99"><a href="#BaggingRegressor-99"><span class="linenos"> 99</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">):</span>
</span><span id="BaggingRegressor-100"><a href="#BaggingRegressor-100"><span class="linenos">100</span></a>            <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="BaggingRegressor-101"><a href="#BaggingRegressor-101"><span class="linenos">101</span></a>
</span><span id="BaggingRegressor-102"><a href="#BaggingRegressor-102"><span class="linenos">102</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Description:
    BaggingRegressor is an implementation of the Bagging (Bootstrap Aggregating) technique for regression tasks.
    It trains multiple copies of a base model on different bootstrap samples of the training set, and 
    aggregates predictions by averaging them.</p>

<p>Args:
    base_model (object): A regression model implementing <code><a href="#BaggingRegressor.fit">fit()</a></code> and <code><a href="#BaggingRegressor.predict">predict()</a></code> methods.
    n_estimators (int): Number of models to train. Default is 10.
    random_state (int, optional): Seed for reproducibility. Default is None.
    pretrained_models (list, optional): A list of already trained models to use instead of training new ones.</p>

<p>Returns:
    None</p>

<p>Example:
    Case 1 - base model which need fitting</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>model = BaggingRegressor(base_model=DecisionTreeRegressor(), n_estimators=5, random_state=123)
      model.fit(X_train, y_train)
      y_pred = model.predict(X_test)</p>

<pre><code>Case 2 - base models already trained which don't need fitting
&gt;&gt;&gt; trained_models = [trained_model1, trained_model2, trained_model3]
&gt;&gt;&gt; model = BaggingRegressor(pretrained_models=trained_models)
&gt;&gt;&gt; y_pred = model.predict(X_test)
</code></pre>
    </blockquote>
  </blockquote>
</blockquote>
</div>


                            <div id="BaggingRegressor.__init__" class="classattr">
                                        <input id="BaggingRegressor.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">BaggingRegressor</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">base_model</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span>,</span><span class="param">	<span class="n">random_state</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">pretrained_models</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="BaggingRegressor.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaggingRegressor.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaggingRegressor.__init__-33"><a href="#BaggingRegressor.__init__-33"><span class="linenos">33</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_model</span><span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pretrained_models</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
</span><span id="BaggingRegressor.__init__-34"><a href="#BaggingRegressor.__init__-34"><span class="linenos">34</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">base_model</span>
</span><span id="BaggingRegressor.__init__-35"><a href="#BaggingRegressor.__init__-35"><span class="linenos">35</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="n">n_estimators</span>
</span><span id="BaggingRegressor.__init__-36"><a href="#BaggingRegressor.__init__-36"><span class="linenos">36</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
</span><span id="BaggingRegressor.__init__-37"><a href="#BaggingRegressor.__init__-37"><span class="linenos">37</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">models</span> <span class="o">=</span> <span class="n">pretrained_models</span> <span class="k">if</span> <span class="n">pretrained_models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[]</span>
</span><span id="BaggingRegressor.__init__-38"><a href="#BaggingRegressor.__init__-38"><span class="linenos">38</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pretrained</span> <span class="o">=</span> <span class="n">pretrained_models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span></pre></div>


    

                            </div>
                            <div id="BaggingRegressor.base_model" class="classattr">
                                <div class="attr variable">
            <span class="name">base_model</span>

        
    </div>
    <a class="headerlink" href="#BaggingRegressor.base_model"></a>
    
    

                            </div>
                            <div id="BaggingRegressor.n_estimators" class="classattr">
                                <div class="attr variable">
            <span class="name">n_estimators</span>

        
    </div>
    <a class="headerlink" href="#BaggingRegressor.n_estimators"></a>
    
    

                            </div>
                            <div id="BaggingRegressor.random_state" class="classattr">
                                <div class="attr variable">
            <span class="name">random_state</span>

        
    </div>
    <a class="headerlink" href="#BaggingRegressor.random_state"></a>
    
    

                            </div>
                            <div id="BaggingRegressor.models" class="classattr">
                                <div class="attr variable">
            <span class="name">models</span>

        
    </div>
    <a class="headerlink" href="#BaggingRegressor.models"></a>
    
    

                            </div>
                            <div id="BaggingRegressor.pretrained" class="classattr">
                                <div class="attr variable">
            <span class="name">pretrained</span>

        
    </div>
    <a class="headerlink" href="#BaggingRegressor.pretrained"></a>
    
    

                            </div>
                            <div id="BaggingRegressor.fit" class="classattr">
                                        <input id="BaggingRegressor.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="n">y</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="BaggingRegressor.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaggingRegressor.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaggingRegressor.fit-40"><a href="#BaggingRegressor.fit-40"><span class="linenos">40</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="BaggingRegressor.fit-41"><a href="#BaggingRegressor.fit-41"><span class="linenos">41</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaggingRegressor.fit-42"><a href="#BaggingRegressor.fit-42"><span class="linenos">42</span></a><span class="sd">        Description:</span>
</span><span id="BaggingRegressor.fit-43"><a href="#BaggingRegressor.fit-43"><span class="linenos">43</span></a><span class="sd">            Trains multiple instances of the base model on bootstrap samples of the training data.</span>
</span><span id="BaggingRegressor.fit-44"><a href="#BaggingRegressor.fit-44"><span class="linenos">44</span></a>
</span><span id="BaggingRegressor.fit-45"><a href="#BaggingRegressor.fit-45"><span class="linenos">45</span></a><span class="sd">        Args:</span>
</span><span id="BaggingRegressor.fit-46"><a href="#BaggingRegressor.fit-46"><span class="linenos">46</span></a><span class="sd">            X (array-like): Feature matrix of shape (n_samples, n_features).</span>
</span><span id="BaggingRegressor.fit-47"><a href="#BaggingRegressor.fit-47"><span class="linenos">47</span></a><span class="sd">            y (array-like): Target vector of shape (n_samples,).</span>
</span><span id="BaggingRegressor.fit-48"><a href="#BaggingRegressor.fit-48"><span class="linenos">48</span></a>
</span><span id="BaggingRegressor.fit-49"><a href="#BaggingRegressor.fit-49"><span class="linenos">49</span></a><span class="sd">        Returns:</span>
</span><span id="BaggingRegressor.fit-50"><a href="#BaggingRegressor.fit-50"><span class="linenos">50</span></a><span class="sd">            None</span>
</span><span id="BaggingRegressor.fit-51"><a href="#BaggingRegressor.fit-51"><span class="linenos">51</span></a>
</span><span id="BaggingRegressor.fit-52"><a href="#BaggingRegressor.fit-52"><span class="linenos">52</span></a><span class="sd">        Example:</span>
</span><span id="BaggingRegressor.fit-53"><a href="#BaggingRegressor.fit-53"><span class="linenos">53</span></a><span class="sd">            &gt;&gt;&gt; model.fit(X_train, y_train)</span>
</span><span id="BaggingRegressor.fit-54"><a href="#BaggingRegressor.fit-54"><span class="linenos">54</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaggingRegressor.fit-55"><a href="#BaggingRegressor.fit-55"><span class="linenos">55</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pretrained</span><span class="p">:</span>
</span><span id="BaggingRegressor.fit-56"><a href="#BaggingRegressor.fit-56"><span class="linenos">56</span></a>            <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">:</span>
</span><span id="BaggingRegressor.fit-57"><a href="#BaggingRegressor.fit-57"><span class="linenos">57</span></a>                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;predict&#39;</span><span class="p">):</span>
</span><span id="BaggingRegressor.fit-58"><a href="#BaggingRegressor.fit-58"><span class="linenos">58</span></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Each pretrained model must implement the predict() method.&quot;</span><span class="p">)</span>
</span><span id="BaggingRegressor.fit-59"><a href="#BaggingRegressor.fit-59"><span class="linenos">59</span></a>            <span class="k">return</span> <span class="c1">#We skip training</span>
</span><span id="BaggingRegressor.fit-60"><a href="#BaggingRegressor.fit-60"><span class="linenos">60</span></a>        
</span><span id="BaggingRegressor.fit-61"><a href="#BaggingRegressor.fit-61"><span class="linenos">61</span></a>
</span><span id="BaggingRegressor.fit-62"><a href="#BaggingRegressor.fit-62"><span class="linenos">62</span></a>        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="BaggingRegressor.fit-63"><a href="#BaggingRegressor.fit-63"><span class="linenos">63</span></a>        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
</span><span id="BaggingRegressor.fit-64"><a href="#BaggingRegressor.fit-64"><span class="linenos">64</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X and y must have the same number of samples.&quot;</span><span class="p">)</span>
</span><span id="BaggingRegressor.fit-65"><a href="#BaggingRegressor.fit-65"><span class="linenos">65</span></a>            
</span><span id="BaggingRegressor.fit-66"><a href="#BaggingRegressor.fit-66"><span class="linenos">66</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">,</span> <span class="s1">&#39;fit&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">,</span> <span class="s1">&#39;predict&#39;</span><span class="p">)):</span>
</span><span id="BaggingRegressor.fit-67"><a href="#BaggingRegressor.fit-67"><span class="linenos">67</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The base model must implement both fit() and predict() methods.&quot;</span><span class="p">)</span>
</span><span id="BaggingRegressor.fit-68"><a href="#BaggingRegressor.fit-68"><span class="linenos">68</span></a>        
</span><span id="BaggingRegressor.fit-69"><a href="#BaggingRegressor.fit-69"><span class="linenos">69</span></a>        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
</span><span id="BaggingRegressor.fit-70"><a href="#BaggingRegressor.fit-70"><span class="linenos">70</span></a>        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="BaggingRegressor.fit-71"><a href="#BaggingRegressor.fit-71"><span class="linenos">71</span></a>        
</span><span id="BaggingRegressor.fit-72"><a href="#BaggingRegressor.fit-72"><span class="linenos">72</span></a>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">):</span>
</span><span id="BaggingRegressor.fit-73"><a href="#BaggingRegressor.fit-73"><span class="linenos">73</span></a>            <span class="c1"># Ãchantillonner avec remise</span>
</span><span id="BaggingRegressor.fit-74"><a href="#BaggingRegressor.fit-74"><span class="linenos">74</span></a>            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="BaggingRegressor.fit-75"><a href="#BaggingRegressor.fit-75"><span class="linenos">75</span></a>            <span class="n">X_sample</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="BaggingRegressor.fit-76"><a href="#BaggingRegressor.fit-76"><span class="linenos">76</span></a>            <span class="n">y_sample</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span><span id="BaggingRegressor.fit-77"><a href="#BaggingRegressor.fit-77"><span class="linenos">77</span></a>
</span><span id="BaggingRegressor.fit-78"><a href="#BaggingRegressor.fit-78"><span class="linenos">78</span></a>            <span class="c1">#model = self.base_model</span>
</span><span id="BaggingRegressor.fit-79"><a href="#BaggingRegressor.fit-79"><span class="linenos">79</span></a>            <span class="n">model</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">)</span>            
</span><span id="BaggingRegressor.fit-80"><a href="#BaggingRegressor.fit-80"><span class="linenos">80</span></a>            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sample</span><span class="p">,</span> <span class="n">y_sample</span><span class="p">)</span>
</span><span id="BaggingRegressor.fit-81"><a href="#BaggingRegressor.fit-81"><span class="linenos">81</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Description:
    Trains multiple instances of the base model on bootstrap samples of the training data.</p>

<p>Args:
    X (array-like): Feature matrix of shape (n_samples, n_features).
    y (array-like): Target vector of shape (n_samples,).</p>

<p>Returns:
    None</p>

<p>Example:</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>model.fit(X_train, y_train)</p>
    </blockquote>
  </blockquote>
</blockquote>
</div>


                            </div>
                            <div id="BaggingRegressor.predict" class="classattr">
                                        <input id="BaggingRegressor.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="BaggingRegressor.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaggingRegressor.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaggingRegressor.predict-83"><a href="#BaggingRegressor.predict-83"><span class="linenos"> 83</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span><span id="BaggingRegressor.predict-84"><a href="#BaggingRegressor.predict-84"><span class="linenos"> 84</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaggingRegressor.predict-85"><a href="#BaggingRegressor.predict-85"><span class="linenos"> 85</span></a><span class="sd">        Description:</span>
</span><span id="BaggingRegressor.predict-86"><a href="#BaggingRegressor.predict-86"><span class="linenos"> 86</span></a><span class="sd">            Predicts target values for given input samples by averaging the predictions of all models.</span>
</span><span id="BaggingRegressor.predict-87"><a href="#BaggingRegressor.predict-87"><span class="linenos"> 87</span></a>
</span><span id="BaggingRegressor.predict-88"><a href="#BaggingRegressor.predict-88"><span class="linenos"> 88</span></a><span class="sd">        Args:</span>
</span><span id="BaggingRegressor.predict-89"><a href="#BaggingRegressor.predict-89"><span class="linenos"> 89</span></a><span class="sd">            X (array-like): Feature matrix of shape (n_samples, n_features).</span>
</span><span id="BaggingRegressor.predict-90"><a href="#BaggingRegressor.predict-90"><span class="linenos"> 90</span></a>
</span><span id="BaggingRegressor.predict-91"><a href="#BaggingRegressor.predict-91"><span class="linenos"> 91</span></a><span class="sd">        Returns:</span>
</span><span id="BaggingRegressor.predict-92"><a href="#BaggingRegressor.predict-92"><span class="linenos"> 92</span></a><span class="sd">            np.ndarray: Averaged predictions for all samples.</span>
</span><span id="BaggingRegressor.predict-93"><a href="#BaggingRegressor.predict-93"><span class="linenos"> 93</span></a>
</span><span id="BaggingRegressor.predict-94"><a href="#BaggingRegressor.predict-94"><span class="linenos"> 94</span></a><span class="sd">        Example:</span>
</span><span id="BaggingRegressor.predict-95"><a href="#BaggingRegressor.predict-95"><span class="linenos"> 95</span></a><span class="sd">            &gt;&gt;&gt; y_pred = model.predict(X_test)</span>
</span><span id="BaggingRegressor.predict-96"><a href="#BaggingRegressor.predict-96"><span class="linenos"> 96</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaggingRegressor.predict-97"><a href="#BaggingRegressor.predict-97"><span class="linenos"> 97</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="BaggingRegressor.predict-98"><a href="#BaggingRegressor.predict-98"><span class="linenos"> 98</span></a>        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</span><span id="BaggingRegressor.predict-99"><a href="#BaggingRegressor.predict-99"><span class="linenos"> 99</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">):</span>
</span><span id="BaggingRegressor.predict-100"><a href="#BaggingRegressor.predict-100"><span class="linenos">100</span></a>            <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="BaggingRegressor.predict-101"><a href="#BaggingRegressor.predict-101"><span class="linenos">101</span></a>
</span><span id="BaggingRegressor.predict-102"><a href="#BaggingRegressor.predict-102"><span class="linenos">102</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Description:
    Predicts target values for given input samples by averaging the predictions of all models.</p>

<p>Args:
    X (array-like): Feature matrix of shape (n_samples, n_features).</p>

<p>Returns:
    np.ndarray: Averaged predictions for all samples.</p>

<p>Example:</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>y_pred = model.predict(X_test)</p>
    </blockquote>
  </blockquote>
</blockquote>
</div>


                            </div>
                </section>
                <section id="BayesianSearchCV">
                            <input id="BayesianSearchCV-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">BayesianSearchCV</span>:

                <label class="view-source-button" for="BayesianSearchCV-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BayesianSearchCV"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BayesianSearchCV-129"><a href="#BayesianSearchCV-129"><span class="linenos">129</span></a><span class="k">class</span><span class="w"> </span><span class="nc">BayesianSearchCV</span><span class="p">:</span>
</span><span id="BayesianSearchCV-130"><a href="#BayesianSearchCV-130"><span class="linenos">130</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-131"><a href="#BayesianSearchCV-131"><span class="linenos">131</span></a><span class="sd">    Bayesian optimization with cross-validation for hyperparameter search.</span>
</span><span id="BayesianSearchCV-132"><a href="#BayesianSearchCV-132"><span class="linenos">132</span></a><span class="sd">    Uses a Gaussian process to model the objective function and Expected Improvement for acquisition.</span>
</span><span id="BayesianSearchCV-133"><a href="#BayesianSearchCV-133"><span class="linenos">133</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-134"><a href="#BayesianSearchCV-134"><span class="linenos">134</span></a>
</span><span id="BayesianSearchCV-135"><a href="#BayesianSearchCV-135"><span class="linenos">135</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">estimator</span><span class="p">,</span> <span class="n">param_bounds</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> <span class="n">maximize</span><span class="p">,</span> <span class="n">stratified</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">init_points</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">param_types</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">):</span>
</span><span id="BayesianSearchCV-136"><a href="#BayesianSearchCV-136"><span class="linenos">136</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-137"><a href="#BayesianSearchCV-137"><span class="linenos">137</span></a><span class="sd">        Description:</span>
</span><span id="BayesianSearchCV-138"><a href="#BayesianSearchCV-138"><span class="linenos">138</span></a><span class="sd">            Initialize the Bayesian search optimization.</span>
</span><span id="BayesianSearchCV-139"><a href="#BayesianSearchCV-139"><span class="linenos">139</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-140"><a href="#BayesianSearchCV-140"><span class="linenos">140</span></a><span class="sd">        Args:</span>
</span><span id="BayesianSearchCV-141"><a href="#BayesianSearchCV-141"><span class="linenos">141</span></a><span class="sd">            estimator: ML model to optimize (must implement fit and predict methods)</span>
</span><span id="BayesianSearchCV-142"><a href="#BayesianSearchCV-142"><span class="linenos">142</span></a><span class="sd">            param_bounds: Dictionary of hyperparameter bounds, where keys are parameter </span>
</span><span id="BayesianSearchCV-143"><a href="#BayesianSearchCV-143"><span class="linenos">143</span></a><span class="sd">                         names and values are tuples (min_bound, max_bound)</span>
</span><span id="BayesianSearchCV-144"><a href="#BayesianSearchCV-144"><span class="linenos">144</span></a><span class="sd">            scoring: Evaluation metric function</span>
</span><span id="BayesianSearchCV-145"><a href="#BayesianSearchCV-145"><span class="linenos">145</span></a><span class="sd">            stratified: Whether to use stratified CV (default: None)</span>
</span><span id="BayesianSearchCV-146"><a href="#BayesianSearchCV-146"><span class="linenos">146</span></a><span class="sd">            n_iter: Number of optimization iterations after initialization (default: 20)</span>
</span><span id="BayesianSearchCV-147"><a href="#BayesianSearchCV-147"><span class="linenos">147</span></a><span class="sd">            init_points: Number of random points for initialization (default: 5)</span>
</span><span id="BayesianSearchCV-148"><a href="#BayesianSearchCV-148"><span class="linenos">148</span></a><span class="sd">            cv: Number of cross-validation folds (default: 5)</span>
</span><span id="BayesianSearchCV-149"><a href="#BayesianSearchCV-149"><span class="linenos">149</span></a><span class="sd">            param_types: Types of parameters for casting (default: None)</span>
</span><span id="BayesianSearchCV-150"><a href="#BayesianSearchCV-150"><span class="linenos">150</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-151"><a href="#BayesianSearchCV-151"><span class="linenos">151</span></a><span class="sd">        Returns:</span>
</span><span id="BayesianSearchCV-152"><a href="#BayesianSearchCV-152"><span class="linenos">152</span></a><span class="sd">            None</span>
</span><span id="BayesianSearchCV-153"><a href="#BayesianSearchCV-153"><span class="linenos">153</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-154"><a href="#BayesianSearchCV-154"><span class="linenos">154</span></a><span class="sd">        Example:</span>
</span><span id="BayesianSearchCV-155"><a href="#BayesianSearchCV-155"><span class="linenos">155</span></a><span class="sd">            &gt;&gt;&gt; from ifri_mini_lib.supervised.classification import SVC</span>
</span><span id="BayesianSearchCV-156"><a href="#BayesianSearchCV-156"><span class="linenos">156</span></a><span class="sd">            &gt;&gt;&gt; from ifri_mini_lib.metrics import accuracy_score</span>
</span><span id="BayesianSearchCV-157"><a href="#BayesianSearchCV-157"><span class="linenos">157</span></a><span class="sd">            &gt;&gt;&gt; model = SVC()</span>
</span><span id="BayesianSearchCV-158"><a href="#BayesianSearchCV-158"><span class="linenos">158</span></a><span class="sd">            &gt;&gt;&gt; param_bounds = {&#39;C&#39;: (0.1, 100), &#39;gamma&#39;: (0.001, 1.0)}</span>
</span><span id="BayesianSearchCV-159"><a href="#BayesianSearchCV-159"><span class="linenos">159</span></a><span class="sd">            &gt;&gt;&gt; bo = BayesianSearchCV(model, param_bounds, accuracy_score, n_iter=30)</span>
</span><span id="BayesianSearchCV-160"><a href="#BayesianSearchCV-160"><span class="linenos">160</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-161"><a href="#BayesianSearchCV-161"><span class="linenos">161</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">estimator</span>
</span><span id="BayesianSearchCV-162"><a href="#BayesianSearchCV-162"><span class="linenos">162</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">param_bounds</span> <span class="o">=</span> <span class="n">param_bounds</span>
</span><span id="BayesianSearchCV-163"><a href="#BayesianSearchCV-163"><span class="linenos">163</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>
</span><span id="BayesianSearchCV-164"><a href="#BayesianSearchCV-164"><span class="linenos">164</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_points</span> <span class="o">=</span> <span class="n">init_points</span>
</span><span id="BayesianSearchCV-165"><a href="#BayesianSearchCV-165"><span class="linenos">165</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
</span><span id="BayesianSearchCV-166"><a href="#BayesianSearchCV-166"><span class="linenos">166</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">=</span> <span class="n">scoring</span>
</span><span id="BayesianSearchCV-167"><a href="#BayesianSearchCV-167"><span class="linenos">167</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">stratified</span> <span class="o">=</span> <span class="n">stratified</span>
</span><span id="BayesianSearchCV-168"><a href="#BayesianSearchCV-168"><span class="linenos">168</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">param_types</span><span class="o">=</span> <span class="n">param_types</span> <span class="ow">or</span> <span class="p">{}</span>
</span><span id="BayesianSearchCV-169"><a href="#BayesianSearchCV-169"><span class="linenos">169</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
</span><span id="BayesianSearchCV-170"><a href="#BayesianSearchCV-170"><span class="linenos">170</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">X_obs</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># list of tested hyperparameter vectors</span>
</span><span id="BayesianSearchCV-171"><a href="#BayesianSearchCV-171"><span class="linenos">171</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># corresponding scores</span>
</span><span id="BayesianSearchCV-172"><a href="#BayesianSearchCV-172"><span class="linenos">172</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">gp</span> <span class="o">=</span> <span class="n">GaussianProcess</span><span class="p">()</span>
</span><span id="BayesianSearchCV-173"><a href="#BayesianSearchCV-173"><span class="linenos">173</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">maximize</span> <span class="o">=</span> <span class="n">maximize</span>
</span><span id="BayesianSearchCV-174"><a href="#BayesianSearchCV-174"><span class="linenos">174</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">history_</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="BayesianSearchCV-175"><a href="#BayesianSearchCV-175"><span class="linenos">175</span></a>
</span><span id="BayesianSearchCV-176"><a href="#BayesianSearchCV-176"><span class="linenos">176</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_normalize_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_vector</span><span class="p">):</span>
</span><span id="BayesianSearchCV-177"><a href="#BayesianSearchCV-177"><span class="linenos">177</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalize parameters to [0,1] range&quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-178"><a href="#BayesianSearchCV-178"><span class="linenos">178</span></a>        <span class="n">normalized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x_vector</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="BayesianSearchCV-179"><a href="#BayesianSearchCV-179"><span class="linenos">179</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">((</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">),</span> <span class="n">val</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_bounds</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">x_vector</span><span class="p">)):</span>
</span><span id="BayesianSearchCV-180"><a href="#BayesianSearchCV-180"><span class="linenos">180</span></a>            <span class="n">normalized</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">val</span> <span class="o">-</span> <span class="n">low</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">high</span> <span class="o">-</span> <span class="n">low</span><span class="p">)</span>
</span><span id="BayesianSearchCV-181"><a href="#BayesianSearchCV-181"><span class="linenos">181</span></a>        <span class="k">return</span> <span class="n">normalized</span>
</span><span id="BayesianSearchCV-182"><a href="#BayesianSearchCV-182"><span class="linenos">182</span></a>
</span><span id="BayesianSearchCV-183"><a href="#BayesianSearchCV-183"><span class="linenos">183</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_denormalize_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalized_vector</span><span class="p">):</span>
</span><span id="BayesianSearchCV-184"><a href="#BayesianSearchCV-184"><span class="linenos">184</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert normalized parameters back to original scale&quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-185"><a href="#BayesianSearchCV-185"><span class="linenos">185</span></a>        <span class="n">denormalized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">normalized_vector</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span id="BayesianSearchCV-186"><a href="#BayesianSearchCV-186"><span class="linenos">186</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_bounds</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
</span><span id="BayesianSearchCV-187"><a href="#BayesianSearchCV-187"><span class="linenos">187</span></a>            <span class="n">denormalized</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">normalized_vector</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">high</span> <span class="o">-</span> <span class="n">low</span><span class="p">)</span> <span class="o">+</span> <span class="n">low</span>
</span><span id="BayesianSearchCV-188"><a href="#BayesianSearchCV-188"><span class="linenos">188</span></a>        <span class="k">return</span> <span class="n">denormalized</span>
</span><span id="BayesianSearchCV-189"><a href="#BayesianSearchCV-189"><span class="linenos">189</span></a>
</span><span id="BayesianSearchCV-190"><a href="#BayesianSearchCV-190"><span class="linenos">190</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_sample_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="BayesianSearchCV-191"><a href="#BayesianSearchCV-191"><span class="linenos">191</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-192"><a href="#BayesianSearchCV-192"><span class="linenos">192</span></a><span class="sd">        Description:</span>
</span><span id="BayesianSearchCV-193"><a href="#BayesianSearchCV-193"><span class="linenos">193</span></a><span class="sd">            Generate random hyperparameter vector within specified bounds.</span>
</span><span id="BayesianSearchCV-194"><a href="#BayesianSearchCV-194"><span class="linenos">194</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-195"><a href="#BayesianSearchCV-195"><span class="linenos">195</span></a><span class="sd">        Args:</span>
</span><span id="BayesianSearchCV-196"><a href="#BayesianSearchCV-196"><span class="linenos">196</span></a><span class="sd">            None</span>
</span><span id="BayesianSearchCV-197"><a href="#BayesianSearchCV-197"><span class="linenos">197</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-198"><a href="#BayesianSearchCV-198"><span class="linenos">198</span></a><span class="sd">        Returns:</span>
</span><span id="BayesianSearchCV-199"><a href="#BayesianSearchCV-199"><span class="linenos">199</span></a><span class="sd">            array: Random hyperparameter vector</span>
</span><span id="BayesianSearchCV-200"><a href="#BayesianSearchCV-200"><span class="linenos">200</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-201"><a href="#BayesianSearchCV-201"><span class="linenos">201</span></a><span class="sd">        Example:</span>
</span><span id="BayesianSearchCV-202"><a href="#BayesianSearchCV-202"><span class="linenos">202</span></a><span class="sd">            &gt;&gt;&gt; random_params = bo._sample_params()</span>
</span><span id="BayesianSearchCV-203"><a href="#BayesianSearchCV-203"><span class="linenos">203</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-204"><a href="#BayesianSearchCV-204"><span class="linenos">204</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_bounds</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
</span><span id="BayesianSearchCV-205"><a href="#BayesianSearchCV-205"><span class="linenos">205</span></a>
</span><span id="BayesianSearchCV-206"><a href="#BayesianSearchCV-206"><span class="linenos">206</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_dict_from_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_vector</span><span class="p">):</span>
</span><span id="BayesianSearchCV-207"><a href="#BayesianSearchCV-207"><span class="linenos">207</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-208"><a href="#BayesianSearchCV-208"><span class="linenos">208</span></a><span class="sd">        Description:</span>
</span><span id="BayesianSearchCV-209"><a href="#BayesianSearchCV-209"><span class="linenos">209</span></a><span class="sd">            Convert hyperparameter vector to dictionary with parameter names.</span>
</span><span id="BayesianSearchCV-210"><a href="#BayesianSearchCV-210"><span class="linenos">210</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-211"><a href="#BayesianSearchCV-211"><span class="linenos">211</span></a><span class="sd">        Args:</span>
</span><span id="BayesianSearchCV-212"><a href="#BayesianSearchCV-212"><span class="linenos">212</span></a><span class="sd">            x_vector: Vector of hyperparameter values</span>
</span><span id="BayesianSearchCV-213"><a href="#BayesianSearchCV-213"><span class="linenos">213</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-214"><a href="#BayesianSearchCV-214"><span class="linenos">214</span></a><span class="sd">        Returns:</span>
</span><span id="BayesianSearchCV-215"><a href="#BayesianSearchCV-215"><span class="linenos">215</span></a><span class="sd">            dict: Dictionary mapping parameter names to values</span>
</span><span id="BayesianSearchCV-216"><a href="#BayesianSearchCV-216"><span class="linenos">216</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-217"><a href="#BayesianSearchCV-217"><span class="linenos">217</span></a><span class="sd">        Example:</span>
</span><span id="BayesianSearchCV-218"><a href="#BayesianSearchCV-218"><span class="linenos">218</span></a><span class="sd">            &gt;&gt;&gt; params_dict = bo._dict_from_vector([1.0, 0.1])</span>
</span><span id="BayesianSearchCV-219"><a href="#BayesianSearchCV-219"><span class="linenos">219</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-220"><a href="#BayesianSearchCV-220"><span class="linenos">220</span></a>        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_bounds</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">x_vector</span><span class="p">))</span>
</span><span id="BayesianSearchCV-221"><a href="#BayesianSearchCV-221"><span class="linenos">221</span></a>
</span><span id="BayesianSearchCV-222"><a href="#BayesianSearchCV-222"><span class="linenos">222</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_cast_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
</span><span id="BayesianSearchCV-223"><a href="#BayesianSearchCV-223"><span class="linenos">223</span></a>        <span class="n">casted_params</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span id="BayesianSearchCV-224"><a href="#BayesianSearchCV-224"><span class="linenos">224</span></a>        <span class="k">for</span> <span class="n">param_name</span><span class="p">,</span> <span class="n">param_type</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_types</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="BayesianSearchCV-225"><a href="#BayesianSearchCV-225"><span class="linenos">225</span></a>            <span class="k">if</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="n">casted_params</span><span class="p">:</span>
</span><span id="BayesianSearchCV-226"><a href="#BayesianSearchCV-226"><span class="linenos">226</span></a>                <span class="k">if</span> <span class="n">param_type</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
</span><span id="BayesianSearchCV-227"><a href="#BayesianSearchCV-227"><span class="linenos">227</span></a>                    <span class="n">casted_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">casted_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]))</span>
</span><span id="BayesianSearchCV-228"><a href="#BayesianSearchCV-228"><span class="linenos">228</span></a>                <span class="k">elif</span> <span class="n">param_type</span> <span class="o">==</span> <span class="s2">&quot;float&quot;</span><span class="p">:</span>
</span><span id="BayesianSearchCV-229"><a href="#BayesianSearchCV-229"><span class="linenos">229</span></a>                    <span class="n">casted_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">casted_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">])</span>
</span><span id="BayesianSearchCV-230"><a href="#BayesianSearchCV-230"><span class="linenos">230</span></a>                <span class="k">elif</span> <span class="n">param_type</span> <span class="o">==</span> <span class="s2">&quot;bool&quot;</span><span class="p">:</span>
</span><span id="BayesianSearchCV-231"><a href="#BayesianSearchCV-231"><span class="linenos">231</span></a>                    <span class="n">casted_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">casted_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">])))</span>  
</span><span id="BayesianSearchCV-232"><a href="#BayesianSearchCV-232"><span class="linenos">232</span></a>        <span class="k">return</span> <span class="n">casted_params</span>
</span><span id="BayesianSearchCV-233"><a href="#BayesianSearchCV-233"><span class="linenos">233</span></a>
</span><span id="BayesianSearchCV-234"><a href="#BayesianSearchCV-234"><span class="linenos">234</span></a>
</span><span id="BayesianSearchCV-235"><a href="#BayesianSearchCV-235"><span class="linenos">235</span></a>
</span><span id="BayesianSearchCV-236"><a href="#BayesianSearchCV-236"><span class="linenos">236</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="BayesianSearchCV-237"><a href="#BayesianSearchCV-237"><span class="linenos">237</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-238"><a href="#BayesianSearchCV-238"><span class="linenos">238</span></a><span class="sd">        Description:</span>
</span><span id="BayesianSearchCV-239"><a href="#BayesianSearchCV-239"><span class="linenos">239</span></a><span class="sd">            Evaluate a set of hyperparameters using cross-validation.</span>
</span><span id="BayesianSearchCV-240"><a href="#BayesianSearchCV-240"><span class="linenos">240</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-241"><a href="#BayesianSearchCV-241"><span class="linenos">241</span></a><span class="sd">        Args:</span>
</span><span id="BayesianSearchCV-242"><a href="#BayesianSearchCV-242"><span class="linenos">242</span></a><span class="sd">            X: Input data, array of shape (n_samples, n_features)</span>
</span><span id="BayesianSearchCV-243"><a href="#BayesianSearchCV-243"><span class="linenos">243</span></a><span class="sd">            y: Target values, array of shape (n_samples,)</span>
</span><span id="BayesianSearchCV-244"><a href="#BayesianSearchCV-244"><span class="linenos">244</span></a><span class="sd">            x: Hyperparameters to evaluate, either vector or dictionary</span>
</span><span id="BayesianSearchCV-245"><a href="#BayesianSearchCV-245"><span class="linenos">245</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-246"><a href="#BayesianSearchCV-246"><span class="linenos">246</span></a><span class="sd">        Returns:</span>
</span><span id="BayesianSearchCV-247"><a href="#BayesianSearchCV-247"><span class="linenos">247</span></a><span class="sd">            float: Cross-validation score</span>
</span><span id="BayesianSearchCV-248"><a href="#BayesianSearchCV-248"><span class="linenos">248</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-249"><a href="#BayesianSearchCV-249"><span class="linenos">249</span></a><span class="sd">        Example:</span>
</span><span id="BayesianSearchCV-250"><a href="#BayesianSearchCV-250"><span class="linenos">250</span></a><span class="sd">            &gt;&gt;&gt; score = bo._evaluate(X_train, y_train, {&#39;C&#39;: 10, &#39;gamma&#39;: 0.1})</span>
</span><span id="BayesianSearchCV-251"><a href="#BayesianSearchCV-251"><span class="linenos">251</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-252"><a href="#BayesianSearchCV-252"><span class="linenos">252</span></a>       
</span><span id="BayesianSearchCV-253"><a href="#BayesianSearchCV-253"><span class="linenos">253</span></a>        <span class="c1"># Special handling for integer parameters</span>
</span><span id="BayesianSearchCV-254"><a href="#BayesianSearchCV-254"><span class="linenos">254</span></a>        <span class="k">if</span> <span class="s2">&quot;n_neighbors&quot;</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
</span><span id="BayesianSearchCV-255"><a href="#BayesianSearchCV-255"><span class="linenos">255</span></a>            <span class="n">x</span><span class="p">[</span><span class="s2">&quot;n_neighbors&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;n_neighbors&quot;</span><span class="p">]))</span>
</span><span id="BayesianSearchCV-256"><a href="#BayesianSearchCV-256"><span class="linenos">256</span></a>            <span class="k">if</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;n_neighbors&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="BayesianSearchCV-257"><a href="#BayesianSearchCV-257"><span class="linenos">257</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;n_neighbors must be a positive integer&quot;</span><span class="p">)</span>
</span><span id="BayesianSearchCV-258"><a href="#BayesianSearchCV-258"><span class="linenos">258</span></a>
</span><span id="BayesianSearchCV-259"><a href="#BayesianSearchCV-259"><span class="linenos">259</span></a>        <span class="c1"># Apply parameters to model</span>
</span><span id="BayesianSearchCV-260"><a href="#BayesianSearchCV-260"><span class="linenos">260</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
</span><span id="BayesianSearchCV-261"><a href="#BayesianSearchCV-261"><span class="linenos">261</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_bounds</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">x</span><span class="p">)}</span>
</span><span id="BayesianSearchCV-262"><a href="#BayesianSearchCV-262"><span class="linenos">262</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cast_parameters</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="BayesianSearchCV-263"><a href="#BayesianSearchCV-263"><span class="linenos">263</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">x</span><span class="p">)</span>
</span><span id="BayesianSearchCV-264"><a href="#BayesianSearchCV-264"><span class="linenos">264</span></a>        <span class="n">mean_score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">k_fold_cross_validation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stratified</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">)</span>
</span><span id="BayesianSearchCV-265"><a href="#BayesianSearchCV-265"><span class="linenos">265</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">maximize</span><span class="p">:</span>
</span><span id="BayesianSearchCV-266"><a href="#BayesianSearchCV-266"><span class="linenos">266</span></a>            <span class="n">mean_score</span> <span class="o">=</span> <span class="o">-</span><span class="n">mean_score</span>
</span><span id="BayesianSearchCV-267"><a href="#BayesianSearchCV-267"><span class="linenos">267</span></a>        <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="BayesianSearchCV-268"><a href="#BayesianSearchCV-268"><span class="linenos">268</span></a>        <span class="k">return</span> <span class="n">mean_score</span>
</span><span id="BayesianSearchCV-269"><a href="#BayesianSearchCV-269"><span class="linenos">269</span></a>
</span><span id="BayesianSearchCV-270"><a href="#BayesianSearchCV-270"><span class="linenos">270</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_suggest</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_candidates</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
</span><span id="BayesianSearchCV-271"><a href="#BayesianSearchCV-271"><span class="linenos">271</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-272"><a href="#BayesianSearchCV-272"><span class="linenos">272</span></a><span class="sd">        Description:</span>
</span><span id="BayesianSearchCV-273"><a href="#BayesianSearchCV-273"><span class="linenos">273</span></a><span class="sd">            Suggest next hyperparameters to evaluate using Expected Improvement.</span>
</span><span id="BayesianSearchCV-274"><a href="#BayesianSearchCV-274"><span class="linenos">274</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-275"><a href="#BayesianSearchCV-275"><span class="linenos">275</span></a><span class="sd">        Args:</span>
</span><span id="BayesianSearchCV-276"><a href="#BayesianSearchCV-276"><span class="linenos">276</span></a><span class="sd">            n_candidates: Number of random candidates to generate (default: 100)</span>
</span><span id="BayesianSearchCV-277"><a href="#BayesianSearchCV-277"><span class="linenos">277</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-278"><a href="#BayesianSearchCV-278"><span class="linenos">278</span></a><span class="sd">        Returns:</span>
</span><span id="BayesianSearchCV-279"><a href="#BayesianSearchCV-279"><span class="linenos">279</span></a><span class="sd">            array: Vector of suggested hyperparameter values</span>
</span><span id="BayesianSearchCV-280"><a href="#BayesianSearchCV-280"><span class="linenos">280</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-281"><a href="#BayesianSearchCV-281"><span class="linenos">281</span></a><span class="sd">        Example:</span>
</span><span id="BayesianSearchCV-282"><a href="#BayesianSearchCV-282"><span class="linenos">282</span></a><span class="sd">            &gt;&gt;&gt; next_params = bo._suggest()</span>
</span><span id="BayesianSearchCV-283"><a href="#BayesianSearchCV-283"><span class="linenos">283</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-284"><a href="#BayesianSearchCV-284"><span class="linenos">284</span></a>        <span class="n">X_candidates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_bounds</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_candidates</span><span class="p">)])</span>
</span><span id="BayesianSearchCV-285"><a href="#BayesianSearchCV-285"><span class="linenos">285</span></a>        <span class="n">ei</span> <span class="o">=</span> <span class="n">expected_improvement</span><span class="p">(</span><span class="n">X_candidates</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="p">,</span> <span class="n">y_min</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span><span class="p">))</span>
</span><span id="BayesianSearchCV-286"><a href="#BayesianSearchCV-286"><span class="linenos">286</span></a>        <span class="k">return</span> <span class="n">X_candidates</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">ei</span><span class="p">)]</span>
</span><span id="BayesianSearchCV-287"><a href="#BayesianSearchCV-287"><span class="linenos">287</span></a>
</span><span id="BayesianSearchCV-288"><a href="#BayesianSearchCV-288"><span class="linenos">288</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="BayesianSearchCV-289"><a href="#BayesianSearchCV-289"><span class="linenos">289</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-290"><a href="#BayesianSearchCV-290"><span class="linenos">290</span></a><span class="sd">        Description:</span>
</span><span id="BayesianSearchCV-291"><a href="#BayesianSearchCV-291"><span class="linenos">291</span></a><span class="sd">            Run Bayesian optimization to find optimal hyperparameters.</span>
</span><span id="BayesianSearchCV-292"><a href="#BayesianSearchCV-292"><span class="linenos">292</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-293"><a href="#BayesianSearchCV-293"><span class="linenos">293</span></a><span class="sd">        Args:</span>
</span><span id="BayesianSearchCV-294"><a href="#BayesianSearchCV-294"><span class="linenos">294</span></a><span class="sd">            X: Input data, array of shape (n_samples, n_features)</span>
</span><span id="BayesianSearchCV-295"><a href="#BayesianSearchCV-295"><span class="linenos">295</span></a><span class="sd">            y: Target values, array of shape (n_samples,)</span>
</span><span id="BayesianSearchCV-296"><a href="#BayesianSearchCV-296"><span class="linenos">296</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-297"><a href="#BayesianSearchCV-297"><span class="linenos">297</span></a><span class="sd">        Returns:</span>
</span><span id="BayesianSearchCV-298"><a href="#BayesianSearchCV-298"><span class="linenos">298</span></a><span class="sd">            self: The instance itself</span>
</span><span id="BayesianSearchCV-299"><a href="#BayesianSearchCV-299"><span class="linenos">299</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-300"><a href="#BayesianSearchCV-300"><span class="linenos">300</span></a><span class="sd">        Example:</span>
</span><span id="BayesianSearchCV-301"><a href="#BayesianSearchCV-301"><span class="linenos">301</span></a><span class="sd">            &gt;&gt;&gt; bo.fit(X_train, y_train)</span>
</span><span id="BayesianSearchCV-302"><a href="#BayesianSearchCV-302"><span class="linenos">302</span></a><span class="sd">            &gt;&gt;&gt; best_params = bo.best_params_</span>
</span><span id="BayesianSearchCV-303"><a href="#BayesianSearchCV-303"><span class="linenos">303</span></a><span class="sd">            &gt;&gt;&gt; best_score = bo.best_score_</span>
</span><span id="BayesianSearchCV-304"><a href="#BayesianSearchCV-304"><span class="linenos">304</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-305"><a href="#BayesianSearchCV-305"><span class="linenos">305</span></a>        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="BayesianSearchCV-306"><a href="#BayesianSearchCV-306"><span class="linenos">306</span></a>
</span><span id="BayesianSearchCV-307"><a href="#BayesianSearchCV-307"><span class="linenos">307</span></a>        <span class="c1"># Initial phase: random points</span>
</span><span id="BayesianSearchCV-308"><a href="#BayesianSearchCV-308"><span class="linenos">308</span></a>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_points</span><span class="p">):</span>
</span><span id="BayesianSearchCV-309"><a href="#BayesianSearchCV-309"><span class="linenos">309</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_params</span><span class="p">()</span>
</span><span id="BayesianSearchCV-310"><a href="#BayesianSearchCV-310"><span class="linenos">310</span></a>            <span class="n">x_normalized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_params</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="BayesianSearchCV-311"><a href="#BayesianSearchCV-311"><span class="linenos">311</span></a>            <span class="n">y_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</span><span id="BayesianSearchCV-312"><a href="#BayesianSearchCV-312"><span class="linenos">312</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">X_obs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_normalized</span><span class="p">)</span>
</span><span id="BayesianSearchCV-313"><a href="#BayesianSearchCV-313"><span class="linenos">313</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>
</span><span id="BayesianSearchCV-314"><a href="#BayesianSearchCV-314"><span class="linenos">314</span></a>
</span><span id="BayesianSearchCV-315"><a href="#BayesianSearchCV-315"><span class="linenos">315</span></a>        <span class="c1"># Optimization loop</span>
</span><span id="BayesianSearchCV-316"><a href="#BayesianSearchCV-316"><span class="linenos">316</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">):</span>
</span><span id="BayesianSearchCV-317"><a href="#BayesianSearchCV-317"><span class="linenos">317</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_obs</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span><span class="p">))</span>
</span><span id="BayesianSearchCV-318"><a href="#BayesianSearchCV-318"><span class="linenos">318</span></a>            <span class="n">x_next_normalized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_suggest</span><span class="p">()</span>
</span><span id="BayesianSearchCV-319"><a href="#BayesianSearchCV-319"><span class="linenos">319</span></a>            <span class="n">x_next_original</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_denormalize_params</span><span class="p">(</span><span class="n">x_next_normalized</span><span class="p">)</span>
</span><span id="BayesianSearchCV-320"><a href="#BayesianSearchCV-320"><span class="linenos">320</span></a>            <span class="n">y_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_next_original</span><span class="p">)</span>
</span><span id="BayesianSearchCV-321"><a href="#BayesianSearchCV-321"><span class="linenos">321</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">X_obs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_next_normalized</span><span class="p">)</span>
</span><span id="BayesianSearchCV-322"><a href="#BayesianSearchCV-322"><span class="linenos">322</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>
</span><span id="BayesianSearchCV-323"><a href="#BayesianSearchCV-323"><span class="linenos">323</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">history_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>
</span><span id="BayesianSearchCV-324"><a href="#BayesianSearchCV-324"><span class="linenos">324</span></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="si">}</span><span class="s2">] Score = </span><span class="si">{</span><span class="n">y_next</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="BayesianSearchCV-325"><a href="#BayesianSearchCV-325"><span class="linenos">325</span></a>
</span><span id="BayesianSearchCV-326"><a href="#BayesianSearchCV-326"><span class="linenos">326</span></a>        <span class="c1"># Get best parameters</span>
</span><span id="BayesianSearchCV-327"><a href="#BayesianSearchCV-327"><span class="linenos">327</span></a>        <span class="n">best_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">maximize</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span><span class="p">)</span>
</span><span id="BayesianSearchCV-328"><a href="#BayesianSearchCV-328"><span class="linenos">328</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cast_parameters</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dict_from_vector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_denormalize_params</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_obs</span><span class="p">[</span><span class="n">best_idx</span><span class="p">])))</span>
</span><span id="BayesianSearchCV-329"><a href="#BayesianSearchCV-329"><span class="linenos">329</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span><span class="p">[</span><span class="n">best_idx</span><span class="p">]</span>
</span><span id="BayesianSearchCV-330"><a href="#BayesianSearchCV-330"><span class="linenos">330</span></a>
</span><span id="BayesianSearchCV-331"><a href="#BayesianSearchCV-331"><span class="linenos">331</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="BayesianSearchCV-332"><a href="#BayesianSearchCV-332"><span class="linenos">332</span></a>
</span><span id="BayesianSearchCV-333"><a href="#BayesianSearchCV-333"><span class="linenos">333</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_best_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="BayesianSearchCV-334"><a href="#BayesianSearchCV-334"><span class="linenos">334</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-335"><a href="#BayesianSearchCV-335"><span class="linenos">335</span></a><span class="sd">        Description:</span>
</span><span id="BayesianSearchCV-336"><a href="#BayesianSearchCV-336"><span class="linenos">336</span></a><span class="sd">            Return the best hyperparameters found during optimization.</span>
</span><span id="BayesianSearchCV-337"><a href="#BayesianSearchCV-337"><span class="linenos">337</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-338"><a href="#BayesianSearchCV-338"><span class="linenos">338</span></a><span class="sd">        Args:</span>
</span><span id="BayesianSearchCV-339"><a href="#BayesianSearchCV-339"><span class="linenos">339</span></a><span class="sd">            None</span>
</span><span id="BayesianSearchCV-340"><a href="#BayesianSearchCV-340"><span class="linenos">340</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-341"><a href="#BayesianSearchCV-341"><span class="linenos">341</span></a><span class="sd">        Returns:</span>
</span><span id="BayesianSearchCV-342"><a href="#BayesianSearchCV-342"><span class="linenos">342</span></a><span class="sd">            dict: Dictionary with best hyperparameter values</span>
</span><span id="BayesianSearchCV-343"><a href="#BayesianSearchCV-343"><span class="linenos">343</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV-344"><a href="#BayesianSearchCV-344"><span class="linenos">344</span></a><span class="sd">        Example:</span>
</span><span id="BayesianSearchCV-345"><a href="#BayesianSearchCV-345"><span class="linenos">345</span></a><span class="sd">            &gt;&gt;&gt; best_params = bo.get_best_params()</span>
</span><span id="BayesianSearchCV-346"><a href="#BayesianSearchCV-346"><span class="linenos">346</span></a><span class="sd">            &gt;&gt;&gt; print(best_params)</span>
</span><span id="BayesianSearchCV-347"><a href="#BayesianSearchCV-347"><span class="linenos">347</span></a><span class="sd">            {&#39;C&#39;: 10.0, &#39;gamma&#39;: 0.01}</span>
</span><span id="BayesianSearchCV-348"><a href="#BayesianSearchCV-348"><span class="linenos">348</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV-349"><a href="#BayesianSearchCV-349"><span class="linenos">349</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span>
</span></pre></div>


            <div class="docstring"><p>Bayesian optimization with cross-validation for hyperparameter search.
Uses a Gaussian process to model the objective function and Expected Improvement for acquisition.</p>
</div>


                            <div id="BayesianSearchCV.__init__" class="classattr">
                                        <input id="BayesianSearchCV.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">BayesianSearchCV</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">estimator</span>,</span><span class="param">	<span class="n">param_bounds</span>,</span><span class="param">	<span class="n">scoring</span>,</span><span class="param">	<span class="n">maximize</span>,</span><span class="param">	<span class="n">stratified</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">n_iter</span><span class="o">=</span><span class="mi">20</span>,</span><span class="param">	<span class="n">init_points</span><span class="o">=</span><span class="mi">5</span>,</span><span class="param">	<span class="n">cv</span><span class="o">=</span><span class="mi">5</span>,</span><span class="param">	<span class="n">param_types</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">random_state</span><span class="o">=</span><span class="mi">42</span></span>)</span>

                <label class="view-source-button" for="BayesianSearchCV.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BayesianSearchCV.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BayesianSearchCV.__init__-135"><a href="#BayesianSearchCV.__init__-135"><span class="linenos">135</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">estimator</span><span class="p">,</span> <span class="n">param_bounds</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> <span class="n">maximize</span><span class="p">,</span> <span class="n">stratified</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">init_points</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">param_types</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">):</span>
</span><span id="BayesianSearchCV.__init__-136"><a href="#BayesianSearchCV.__init__-136"><span class="linenos">136</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV.__init__-137"><a href="#BayesianSearchCV.__init__-137"><span class="linenos">137</span></a><span class="sd">        Description:</span>
</span><span id="BayesianSearchCV.__init__-138"><a href="#BayesianSearchCV.__init__-138"><span class="linenos">138</span></a><span class="sd">            Initialize the Bayesian search optimization.</span>
</span><span id="BayesianSearchCV.__init__-139"><a href="#BayesianSearchCV.__init__-139"><span class="linenos">139</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV.__init__-140"><a href="#BayesianSearchCV.__init__-140"><span class="linenos">140</span></a><span class="sd">        Args:</span>
</span><span id="BayesianSearchCV.__init__-141"><a href="#BayesianSearchCV.__init__-141"><span class="linenos">141</span></a><span class="sd">            estimator: ML model to optimize (must implement fit and predict methods)</span>
</span><span id="BayesianSearchCV.__init__-142"><a href="#BayesianSearchCV.__init__-142"><span class="linenos">142</span></a><span class="sd">            param_bounds: Dictionary of hyperparameter bounds, where keys are parameter </span>
</span><span id="BayesianSearchCV.__init__-143"><a href="#BayesianSearchCV.__init__-143"><span class="linenos">143</span></a><span class="sd">                         names and values are tuples (min_bound, max_bound)</span>
</span><span id="BayesianSearchCV.__init__-144"><a href="#BayesianSearchCV.__init__-144"><span class="linenos">144</span></a><span class="sd">            scoring: Evaluation metric function</span>
</span><span id="BayesianSearchCV.__init__-145"><a href="#BayesianSearchCV.__init__-145"><span class="linenos">145</span></a><span class="sd">            stratified: Whether to use stratified CV (default: None)</span>
</span><span id="BayesianSearchCV.__init__-146"><a href="#BayesianSearchCV.__init__-146"><span class="linenos">146</span></a><span class="sd">            n_iter: Number of optimization iterations after initialization (default: 20)</span>
</span><span id="BayesianSearchCV.__init__-147"><a href="#BayesianSearchCV.__init__-147"><span class="linenos">147</span></a><span class="sd">            init_points: Number of random points for initialization (default: 5)</span>
</span><span id="BayesianSearchCV.__init__-148"><a href="#BayesianSearchCV.__init__-148"><span class="linenos">148</span></a><span class="sd">            cv: Number of cross-validation folds (default: 5)</span>
</span><span id="BayesianSearchCV.__init__-149"><a href="#BayesianSearchCV.__init__-149"><span class="linenos">149</span></a><span class="sd">            param_types: Types of parameters for casting (default: None)</span>
</span><span id="BayesianSearchCV.__init__-150"><a href="#BayesianSearchCV.__init__-150"><span class="linenos">150</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV.__init__-151"><a href="#BayesianSearchCV.__init__-151"><span class="linenos">151</span></a><span class="sd">        Returns:</span>
</span><span id="BayesianSearchCV.__init__-152"><a href="#BayesianSearchCV.__init__-152"><span class="linenos">152</span></a><span class="sd">            None</span>
</span><span id="BayesianSearchCV.__init__-153"><a href="#BayesianSearchCV.__init__-153"><span class="linenos">153</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV.__init__-154"><a href="#BayesianSearchCV.__init__-154"><span class="linenos">154</span></a><span class="sd">        Example:</span>
</span><span id="BayesianSearchCV.__init__-155"><a href="#BayesianSearchCV.__init__-155"><span class="linenos">155</span></a><span class="sd">            &gt;&gt;&gt; from ifri_mini_lib.supervised.classification import SVC</span>
</span><span id="BayesianSearchCV.__init__-156"><a href="#BayesianSearchCV.__init__-156"><span class="linenos">156</span></a><span class="sd">            &gt;&gt;&gt; from ifri_mini_lib.metrics import accuracy_score</span>
</span><span id="BayesianSearchCV.__init__-157"><a href="#BayesianSearchCV.__init__-157"><span class="linenos">157</span></a><span class="sd">            &gt;&gt;&gt; model = SVC()</span>
</span><span id="BayesianSearchCV.__init__-158"><a href="#BayesianSearchCV.__init__-158"><span class="linenos">158</span></a><span class="sd">            &gt;&gt;&gt; param_bounds = {&#39;C&#39;: (0.1, 100), &#39;gamma&#39;: (0.001, 1.0)}</span>
</span><span id="BayesianSearchCV.__init__-159"><a href="#BayesianSearchCV.__init__-159"><span class="linenos">159</span></a><span class="sd">            &gt;&gt;&gt; bo = BayesianSearchCV(model, param_bounds, accuracy_score, n_iter=30)</span>
</span><span id="BayesianSearchCV.__init__-160"><a href="#BayesianSearchCV.__init__-160"><span class="linenos">160</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV.__init__-161"><a href="#BayesianSearchCV.__init__-161"><span class="linenos">161</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">estimator</span>
</span><span id="BayesianSearchCV.__init__-162"><a href="#BayesianSearchCV.__init__-162"><span class="linenos">162</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">param_bounds</span> <span class="o">=</span> <span class="n">param_bounds</span>
</span><span id="BayesianSearchCV.__init__-163"><a href="#BayesianSearchCV.__init__-163"><span class="linenos">163</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>
</span><span id="BayesianSearchCV.__init__-164"><a href="#BayesianSearchCV.__init__-164"><span class="linenos">164</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">init_points</span> <span class="o">=</span> <span class="n">init_points</span>
</span><span id="BayesianSearchCV.__init__-165"><a href="#BayesianSearchCV.__init__-165"><span class="linenos">165</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
</span><span id="BayesianSearchCV.__init__-166"><a href="#BayesianSearchCV.__init__-166"><span class="linenos">166</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">=</span> <span class="n">scoring</span>
</span><span id="BayesianSearchCV.__init__-167"><a href="#BayesianSearchCV.__init__-167"><span class="linenos">167</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">stratified</span> <span class="o">=</span> <span class="n">stratified</span>
</span><span id="BayesianSearchCV.__init__-168"><a href="#BayesianSearchCV.__init__-168"><span class="linenos">168</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">param_types</span><span class="o">=</span> <span class="n">param_types</span> <span class="ow">or</span> <span class="p">{}</span>
</span><span id="BayesianSearchCV.__init__-169"><a href="#BayesianSearchCV.__init__-169"><span class="linenos">169</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
</span><span id="BayesianSearchCV.__init__-170"><a href="#BayesianSearchCV.__init__-170"><span class="linenos">170</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">X_obs</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># list of tested hyperparameter vectors</span>
</span><span id="BayesianSearchCV.__init__-171"><a href="#BayesianSearchCV.__init__-171"><span class="linenos">171</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># corresponding scores</span>
</span><span id="BayesianSearchCV.__init__-172"><a href="#BayesianSearchCV.__init__-172"><span class="linenos">172</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">gp</span> <span class="o">=</span> <span class="n">GaussianProcess</span><span class="p">()</span>
</span><span id="BayesianSearchCV.__init__-173"><a href="#BayesianSearchCV.__init__-173"><span class="linenos">173</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">maximize</span> <span class="o">=</span> <span class="n">maximize</span>
</span><span id="BayesianSearchCV.__init__-174"><a href="#BayesianSearchCV.__init__-174"><span class="linenos">174</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">history_</span> <span class="o">=</span> <span class="p">[]</span>
</span></pre></div>


            <div class="docstring"><p>Description:
    Initialize the Bayesian search optimization.</p>

<p>Args:
    estimator: ML model to optimize (must implement fit and predict methods)
    param_bounds: Dictionary of hyperparameter bounds, where keys are parameter 
                 names and values are tuples (min_bound, max_bound)
    scoring: Evaluation metric function
    stratified: Whether to use stratified CV (default: None)
    n_iter: Number of optimization iterations after initialization (default: 20)
    init_points: Number of random points for initialization (default: 5)
    cv: Number of cross-validation folds (default: 5)
    param_types: Types of parameters for casting (default: None)</p>

<p>Returns:
    None</p>

<p>Example:</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>from ifri_mini_lib.supervised.classification import SVC
      from ifri_mini_lib.metrics import accuracy_score
      model = SVC()
      param_bounds = {'C': (0.1, 100), 'gamma': (0.001, 1.0)}
      bo = BayesianSearchCV(model, param_bounds, accuracy_score, n_iter=30)</p>
    </blockquote>
  </blockquote>
</blockquote>
</div>


                            </div>
                            <div id="BayesianSearchCV.estimator" class="classattr">
                                <div class="attr variable">
            <span class="name">estimator</span>

        
    </div>
    <a class="headerlink" href="#BayesianSearchCV.estimator"></a>
    
    

                            </div>
                            <div id="BayesianSearchCV.param_bounds" class="classattr">
                                <div class="attr variable">
            <span class="name">param_bounds</span>

        
    </div>
    <a class="headerlink" href="#BayesianSearchCV.param_bounds"></a>
    
    

                            </div>
                            <div id="BayesianSearchCV.n_iter" class="classattr">
                                <div class="attr variable">
            <span class="name">n_iter</span>

        
    </div>
    <a class="headerlink" href="#BayesianSearchCV.n_iter"></a>
    
    

                            </div>
                            <div id="BayesianSearchCV.init_points" class="classattr">
                                <div class="attr variable">
            <span class="name">init_points</span>

        
    </div>
    <a class="headerlink" href="#BayesianSearchCV.init_points"></a>
    
    

                            </div>
                            <div id="BayesianSearchCV.cv" class="classattr">
                                <div class="attr variable">
            <span class="name">cv</span>

        
    </div>
    <a class="headerlink" href="#BayesianSearchCV.cv"></a>
    
    

                            </div>
                            <div id="BayesianSearchCV.scoring" class="classattr">
                                <div class="attr variable">
            <span class="name">scoring</span>

        
    </div>
    <a class="headerlink" href="#BayesianSearchCV.scoring"></a>
    
    

                            </div>
                            <div id="BayesianSearchCV.stratified" class="classattr">
                                <div class="attr variable">
            <span class="name">stratified</span>

        
    </div>
    <a class="headerlink" href="#BayesianSearchCV.stratified"></a>
    
    

                            </div>
                            <div id="BayesianSearchCV.param_types" class="classattr">
                                <div class="attr variable">
            <span class="name">param_types</span>

        
    </div>
    <a class="headerlink" href="#BayesianSearchCV.param_types"></a>
    
    

                            </div>
                            <div id="BayesianSearchCV.random_state" class="classattr">
                                <div class="attr variable">
            <span class="name">random_state</span>

        
    </div>
    <a class="headerlink" href="#BayesianSearchCV.random_state"></a>
    
    

                            </div>
                            <div id="BayesianSearchCV.X_obs" class="classattr">
                                <div class="attr variable">
            <span class="name">X_obs</span>

        
    </div>
    <a class="headerlink" href="#BayesianSearchCV.X_obs"></a>
    
    

                            </div>
                            <div id="BayesianSearchCV.y_obs" class="classattr">
                                <div class="attr variable">
            <span class="name">y_obs</span>

        
    </div>
    <a class="headerlink" href="#BayesianSearchCV.y_obs"></a>
    
    

                            </div>
                            <div id="BayesianSearchCV.gp" class="classattr">
                                <div class="attr variable">
            <span class="name">gp</span>

        
    </div>
    <a class="headerlink" href="#BayesianSearchCV.gp"></a>
    
    

                            </div>
                            <div id="BayesianSearchCV.maximize" class="classattr">
                                <div class="attr variable">
            <span class="name">maximize</span>

        
    </div>
    <a class="headerlink" href="#BayesianSearchCV.maximize"></a>
    
    

                            </div>
                            <div id="BayesianSearchCV.history_" class="classattr">
                                <div class="attr variable">
            <span class="name">history_</span>

        
    </div>
    <a class="headerlink" href="#BayesianSearchCV.history_"></a>
    
    

                            </div>
                            <div id="BayesianSearchCV.fit" class="classattr">
                                        <input id="BayesianSearchCV.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="n">y</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="BayesianSearchCV.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BayesianSearchCV.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BayesianSearchCV.fit-288"><a href="#BayesianSearchCV.fit-288"><span class="linenos">288</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="BayesianSearchCV.fit-289"><a href="#BayesianSearchCV.fit-289"><span class="linenos">289</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV.fit-290"><a href="#BayesianSearchCV.fit-290"><span class="linenos">290</span></a><span class="sd">        Description:</span>
</span><span id="BayesianSearchCV.fit-291"><a href="#BayesianSearchCV.fit-291"><span class="linenos">291</span></a><span class="sd">            Run Bayesian optimization to find optimal hyperparameters.</span>
</span><span id="BayesianSearchCV.fit-292"><a href="#BayesianSearchCV.fit-292"><span class="linenos">292</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV.fit-293"><a href="#BayesianSearchCV.fit-293"><span class="linenos">293</span></a><span class="sd">        Args:</span>
</span><span id="BayesianSearchCV.fit-294"><a href="#BayesianSearchCV.fit-294"><span class="linenos">294</span></a><span class="sd">            X: Input data, array of shape (n_samples, n_features)</span>
</span><span id="BayesianSearchCV.fit-295"><a href="#BayesianSearchCV.fit-295"><span class="linenos">295</span></a><span class="sd">            y: Target values, array of shape (n_samples,)</span>
</span><span id="BayesianSearchCV.fit-296"><a href="#BayesianSearchCV.fit-296"><span class="linenos">296</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV.fit-297"><a href="#BayesianSearchCV.fit-297"><span class="linenos">297</span></a><span class="sd">        Returns:</span>
</span><span id="BayesianSearchCV.fit-298"><a href="#BayesianSearchCV.fit-298"><span class="linenos">298</span></a><span class="sd">            self: The instance itself</span>
</span><span id="BayesianSearchCV.fit-299"><a href="#BayesianSearchCV.fit-299"><span class="linenos">299</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV.fit-300"><a href="#BayesianSearchCV.fit-300"><span class="linenos">300</span></a><span class="sd">        Example:</span>
</span><span id="BayesianSearchCV.fit-301"><a href="#BayesianSearchCV.fit-301"><span class="linenos">301</span></a><span class="sd">            &gt;&gt;&gt; bo.fit(X_train, y_train)</span>
</span><span id="BayesianSearchCV.fit-302"><a href="#BayesianSearchCV.fit-302"><span class="linenos">302</span></a><span class="sd">            &gt;&gt;&gt; best_params = bo.best_params_</span>
</span><span id="BayesianSearchCV.fit-303"><a href="#BayesianSearchCV.fit-303"><span class="linenos">303</span></a><span class="sd">            &gt;&gt;&gt; best_score = bo.best_score_</span>
</span><span id="BayesianSearchCV.fit-304"><a href="#BayesianSearchCV.fit-304"><span class="linenos">304</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV.fit-305"><a href="#BayesianSearchCV.fit-305"><span class="linenos">305</span></a>        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="BayesianSearchCV.fit-306"><a href="#BayesianSearchCV.fit-306"><span class="linenos">306</span></a>
</span><span id="BayesianSearchCV.fit-307"><a href="#BayesianSearchCV.fit-307"><span class="linenos">307</span></a>        <span class="c1"># Initial phase: random points</span>
</span><span id="BayesianSearchCV.fit-308"><a href="#BayesianSearchCV.fit-308"><span class="linenos">308</span></a>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_points</span><span class="p">):</span>
</span><span id="BayesianSearchCV.fit-309"><a href="#BayesianSearchCV.fit-309"><span class="linenos">309</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_params</span><span class="p">()</span>
</span><span id="BayesianSearchCV.fit-310"><a href="#BayesianSearchCV.fit-310"><span class="linenos">310</span></a>            <span class="n">x_normalized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_params</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="BayesianSearchCV.fit-311"><a href="#BayesianSearchCV.fit-311"><span class="linenos">311</span></a>            <span class="n">y_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</span><span id="BayesianSearchCV.fit-312"><a href="#BayesianSearchCV.fit-312"><span class="linenos">312</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">X_obs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_normalized</span><span class="p">)</span>
</span><span id="BayesianSearchCV.fit-313"><a href="#BayesianSearchCV.fit-313"><span class="linenos">313</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>
</span><span id="BayesianSearchCV.fit-314"><a href="#BayesianSearchCV.fit-314"><span class="linenos">314</span></a>
</span><span id="BayesianSearchCV.fit-315"><a href="#BayesianSearchCV.fit-315"><span class="linenos">315</span></a>        <span class="c1"># Optimization loop</span>
</span><span id="BayesianSearchCV.fit-316"><a href="#BayesianSearchCV.fit-316"><span class="linenos">316</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">):</span>
</span><span id="BayesianSearchCV.fit-317"><a href="#BayesianSearchCV.fit-317"><span class="linenos">317</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">gp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_obs</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span><span class="p">))</span>
</span><span id="BayesianSearchCV.fit-318"><a href="#BayesianSearchCV.fit-318"><span class="linenos">318</span></a>            <span class="n">x_next_normalized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_suggest</span><span class="p">()</span>
</span><span id="BayesianSearchCV.fit-319"><a href="#BayesianSearchCV.fit-319"><span class="linenos">319</span></a>            <span class="n">x_next_original</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_denormalize_params</span><span class="p">(</span><span class="n">x_next_normalized</span><span class="p">)</span>
</span><span id="BayesianSearchCV.fit-320"><a href="#BayesianSearchCV.fit-320"><span class="linenos">320</span></a>            <span class="n">y_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_next_original</span><span class="p">)</span>
</span><span id="BayesianSearchCV.fit-321"><a href="#BayesianSearchCV.fit-321"><span class="linenos">321</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">X_obs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_next_normalized</span><span class="p">)</span>
</span><span id="BayesianSearchCV.fit-322"><a href="#BayesianSearchCV.fit-322"><span class="linenos">322</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>
</span><span id="BayesianSearchCV.fit-323"><a href="#BayesianSearchCV.fit-323"><span class="linenos">323</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">history_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_next</span><span class="p">)</span>
</span><span id="BayesianSearchCV.fit-324"><a href="#BayesianSearchCV.fit-324"><span class="linenos">324</span></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="si">}</span><span class="s2">] Score = </span><span class="si">{</span><span class="n">y_next</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="BayesianSearchCV.fit-325"><a href="#BayesianSearchCV.fit-325"><span class="linenos">325</span></a>
</span><span id="BayesianSearchCV.fit-326"><a href="#BayesianSearchCV.fit-326"><span class="linenos">326</span></a>        <span class="c1"># Get best parameters</span>
</span><span id="BayesianSearchCV.fit-327"><a href="#BayesianSearchCV.fit-327"><span class="linenos">327</span></a>        <span class="n">best_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">maximize</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span><span class="p">)</span>
</span><span id="BayesianSearchCV.fit-328"><a href="#BayesianSearchCV.fit-328"><span class="linenos">328</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cast_parameters</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dict_from_vector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_denormalize_params</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_obs</span><span class="p">[</span><span class="n">best_idx</span><span class="p">])))</span>
</span><span id="BayesianSearchCV.fit-329"><a href="#BayesianSearchCV.fit-329"><span class="linenos">329</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span><span class="p">[</span><span class="n">best_idx</span><span class="p">]</span>
</span><span id="BayesianSearchCV.fit-330"><a href="#BayesianSearchCV.fit-330"><span class="linenos">330</span></a>
</span><span id="BayesianSearchCV.fit-331"><a href="#BayesianSearchCV.fit-331"><span class="linenos">331</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span></pre></div>


            <div class="docstring"><p>Description:
    Run Bayesian optimization to find optimal hyperparameters.</p>

<p>Args:
    X: Input data, array of shape (n_samples, n_features)
    y: Target values, array of shape (n_samples,)</p>

<p>Returns:
    self: The instance itself</p>

<p>Example:</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>bo.fit(X_train, y_train)
      best_params = bo.best_params_
      best_score = bo.best_score_</p>
    </blockquote>
  </blockquote>
</blockquote>
</div>


                            </div>
                            <div id="BayesianSearchCV.get_best_params" class="classattr">
                                        <input id="BayesianSearchCV.get_best_params-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_best_params</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="BayesianSearchCV.get_best_params-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BayesianSearchCV.get_best_params"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BayesianSearchCV.get_best_params-333"><a href="#BayesianSearchCV.get_best_params-333"><span class="linenos">333</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_best_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="BayesianSearchCV.get_best_params-334"><a href="#BayesianSearchCV.get_best_params-334"><span class="linenos">334</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV.get_best_params-335"><a href="#BayesianSearchCV.get_best_params-335"><span class="linenos">335</span></a><span class="sd">        Description:</span>
</span><span id="BayesianSearchCV.get_best_params-336"><a href="#BayesianSearchCV.get_best_params-336"><span class="linenos">336</span></a><span class="sd">            Return the best hyperparameters found during optimization.</span>
</span><span id="BayesianSearchCV.get_best_params-337"><a href="#BayesianSearchCV.get_best_params-337"><span class="linenos">337</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV.get_best_params-338"><a href="#BayesianSearchCV.get_best_params-338"><span class="linenos">338</span></a><span class="sd">        Args:</span>
</span><span id="BayesianSearchCV.get_best_params-339"><a href="#BayesianSearchCV.get_best_params-339"><span class="linenos">339</span></a><span class="sd">            None</span>
</span><span id="BayesianSearchCV.get_best_params-340"><a href="#BayesianSearchCV.get_best_params-340"><span class="linenos">340</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV.get_best_params-341"><a href="#BayesianSearchCV.get_best_params-341"><span class="linenos">341</span></a><span class="sd">        Returns:</span>
</span><span id="BayesianSearchCV.get_best_params-342"><a href="#BayesianSearchCV.get_best_params-342"><span class="linenos">342</span></a><span class="sd">            dict: Dictionary with best hyperparameter values</span>
</span><span id="BayesianSearchCV.get_best_params-343"><a href="#BayesianSearchCV.get_best_params-343"><span class="linenos">343</span></a><span class="sd">            </span>
</span><span id="BayesianSearchCV.get_best_params-344"><a href="#BayesianSearchCV.get_best_params-344"><span class="linenos">344</span></a><span class="sd">        Example:</span>
</span><span id="BayesianSearchCV.get_best_params-345"><a href="#BayesianSearchCV.get_best_params-345"><span class="linenos">345</span></a><span class="sd">            &gt;&gt;&gt; best_params = bo.get_best_params()</span>
</span><span id="BayesianSearchCV.get_best_params-346"><a href="#BayesianSearchCV.get_best_params-346"><span class="linenos">346</span></a><span class="sd">            &gt;&gt;&gt; print(best_params)</span>
</span><span id="BayesianSearchCV.get_best_params-347"><a href="#BayesianSearchCV.get_best_params-347"><span class="linenos">347</span></a><span class="sd">            {&#39;C&#39;: 10.0, &#39;gamma&#39;: 0.01}</span>
</span><span id="BayesianSearchCV.get_best_params-348"><a href="#BayesianSearchCV.get_best_params-348"><span class="linenos">348</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BayesianSearchCV.get_best_params-349"><a href="#BayesianSearchCV.get_best_params-349"><span class="linenos">349</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span>
</span></pre></div>


            <div class="docstring"><p>Description:
    Return the best hyperparameters found during optimization.</p>

<p>Args:
    None</p>

<p>Returns:
    dict: Dictionary with best hyperparameter values</p>

<p>Example:</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>best_params = bo.get_best_params()
      print(best_params)
          {'C': 10.0, 'gamma': 0.01}</p>
    </blockquote>
  </blockquote>
</blockquote>
</div>


                            </div>
                </section>
                <section id="GridSearchCV">
                            <input id="GridSearchCV-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">GridSearchCV</span>:

                <label class="view-source-button" for="GridSearchCV-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GridSearchCV"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GridSearchCV-7"><a href="#GridSearchCV-7"><span class="linenos"> 7</span></a><span class="k">class</span><span class="w"> </span><span class="nc">GridSearchCV</span><span class="p">:</span>
</span><span id="GridSearchCV-8"><a href="#GridSearchCV-8"><span class="linenos"> 8</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="GridSearchCV-9"><a href="#GridSearchCV-9"><span class="linenos"> 9</span></a><span class="sd">    Grid search implementation with cross-validation for hyperparameter optimization.</span>
</span><span id="GridSearchCV-10"><a href="#GridSearchCV-10"><span class="linenos">10</span></a><span class="sd">    </span>
</span><span id="GridSearchCV-11"><a href="#GridSearchCV-11"><span class="linenos">11</span></a><span class="sd">    This class allows to test different combinations of hyperparameters on a machine learning model</span>
</span><span id="GridSearchCV-12"><a href="#GridSearchCV-12"><span class="linenos">12</span></a><span class="sd">    using cross-validation to avoid overfitting and select the best hyperparameter combination.</span>
</span><span id="GridSearchCV-13"><a href="#GridSearchCV-13"><span class="linenos">13</span></a><span class="sd">    </span>
</span><span id="GridSearchCV-14"><a href="#GridSearchCV-14"><span class="linenos">14</span></a><span class="sd">    Args:</span>
</span><span id="GridSearchCV-15"><a href="#GridSearchCV-15"><span class="linenos">15</span></a><span class="sd">        model: ML model to optimize (must implement fit and predict methods)</span>
</span><span id="GridSearchCV-16"><a href="#GridSearchCV-16"><span class="linenos">16</span></a><span class="sd">        param_grid: Dictionary of hyperparameters to test, where keys are parameter </span>
</span><span id="GridSearchCV-17"><a href="#GridSearchCV-17"><span class="linenos">17</span></a><span class="sd">                    names and values are lists of parameter values to try</span>
</span><span id="GridSearchCV-18"><a href="#GridSearchCV-18"><span class="linenos">18</span></a><span class="sd">        scoring: Evaluation function (e.g., accuracy_score, mean_squared_error, f1)</span>
</span><span id="GridSearchCV-19"><a href="#GridSearchCV-19"><span class="linenos">19</span></a><span class="sd">        k: Number of folds for cross-validation (default: 5)</span>
</span><span id="GridSearchCV-20"><a href="#GridSearchCV-20"><span class="linenos">20</span></a><span class="sd">        stratified: Whether to use stratified k-fold validation (default: False)</span>
</span><span id="GridSearchCV-21"><a href="#GridSearchCV-21"><span class="linenos">21</span></a><span class="sd">        </span>
</span><span id="GridSearchCV-22"><a href="#GridSearchCV-22"><span class="linenos">22</span></a><span class="sd">    Returns:</span>
</span><span id="GridSearchCV-23"><a href="#GridSearchCV-23"><span class="linenos">23</span></a><span class="sd">        None</span>
</span><span id="GridSearchCV-24"><a href="#GridSearchCV-24"><span class="linenos">24</span></a><span class="sd">        </span>
</span><span id="GridSearchCV-25"><a href="#GridSearchCV-25"><span class="linenos">25</span></a><span class="sd">    Example:</span>
</span><span id="GridSearchCV-26"><a href="#GridSearchCV-26"><span class="linenos">26</span></a><span class="sd">        &gt;&gt;&gt; from ifri_mini_lib.supervised.classification import SVC</span>
</span><span id="GridSearchCV-27"><a href="#GridSearchCV-27"><span class="linenos">27</span></a><span class="sd">        &gt;&gt;&gt; from ifri_mini_lib.metrics import accuracy_score</span>
</span><span id="GridSearchCV-28"><a href="#GridSearchCV-28"><span class="linenos">28</span></a><span class="sd">        &gt;&gt;&gt; model = SVC()</span>
</span><span id="GridSearchCV-29"><a href="#GridSearchCV-29"><span class="linenos">29</span></a><span class="sd">        &gt;&gt;&gt; param_grid = {&#39;C&#39;: [0.1, 1, 10], &#39;kernel&#39;: [&#39;linear&#39;, &#39;rbf&#39;]}</span>
</span><span id="GridSearchCV-30"><a href="#GridSearchCV-30"><span class="linenos">30</span></a><span class="sd">        &gt;&gt;&gt; grid_search = GridSearchCV(model, param_grid, accuracy_score, k=5)</span>
</span><span id="GridSearchCV-31"><a href="#GridSearchCV-31"><span class="linenos">31</span></a><span class="sd">    </span>
</span><span id="GridSearchCV-32"><a href="#GridSearchCV-32"><span class="linenos">32</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="GridSearchCV-33"><a href="#GridSearchCV-33"><span class="linenos">33</span></a>
</span><span id="GridSearchCV-34"><a href="#GridSearchCV-34"><span class="linenos">34</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">stratified</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="GridSearchCV-35"><a href="#GridSearchCV-35"><span class="linenos">35</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="GridSearchCV-36"><a href="#GridSearchCV-36"><span class="linenos">36</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span>
</span><span id="GridSearchCV-37"><a href="#GridSearchCV-37"><span class="linenos">37</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
</span><span id="GridSearchCV-38"><a href="#GridSearchCV-38"><span class="linenos">38</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">=</span> <span class="n">scoring</span> 
</span><span id="GridSearchCV-39"><a href="#GridSearchCV-39"><span class="linenos">39</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">stratified</span> <span class="o">=</span> <span class="n">stratified</span>
</span><span id="GridSearchCV-40"><a href="#GridSearchCV-40"><span class="linenos">40</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GridSearchCV-41"><a href="#GridSearchCV-41"><span class="linenos">41</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</span><span id="GridSearchCV-42"><a href="#GridSearchCV-42"><span class="linenos">42</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GridSearchCV-43"><a href="#GridSearchCV-43"><span class="linenos">43</span></a>
</span><span id="GridSearchCV-44"><a href="#GridSearchCV-44"><span class="linenos">44</span></a>    
</span><span id="GridSearchCV-45"><a href="#GridSearchCV-45"><span class="linenos">45</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="GridSearchCV-46"><a href="#GridSearchCV-46"><span class="linenos">46</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="GridSearchCV-47"><a href="#GridSearchCV-47"><span class="linenos">47</span></a><span class="sd">        Description:</span>
</span><span id="GridSearchCV-48"><a href="#GridSearchCV-48"><span class="linenos">48</span></a><span class="sd">            Run grid search with cross-validation on the given data.</span>
</span><span id="GridSearchCV-49"><a href="#GridSearchCV-49"><span class="linenos">49</span></a><span class="sd">            Tests all possible combinations of hyperparameters and finds the best set.</span>
</span><span id="GridSearchCV-50"><a href="#GridSearchCV-50"><span class="linenos">50</span></a><span class="sd">            </span>
</span><span id="GridSearchCV-51"><a href="#GridSearchCV-51"><span class="linenos">51</span></a><span class="sd">        Args:</span>
</span><span id="GridSearchCV-52"><a href="#GridSearchCV-52"><span class="linenos">52</span></a><span class="sd">            X: Input features array of shape (n_samples, n_features)</span>
</span><span id="GridSearchCV-53"><a href="#GridSearchCV-53"><span class="linenos">53</span></a><span class="sd">            y: Target values array of shape (n_samples,)</span>
</span><span id="GridSearchCV-54"><a href="#GridSearchCV-54"><span class="linenos">54</span></a><span class="sd">            </span>
</span><span id="GridSearchCV-55"><a href="#GridSearchCV-55"><span class="linenos">55</span></a><span class="sd">        Returns:</span>
</span><span id="GridSearchCV-56"><a href="#GridSearchCV-56"><span class="linenos">56</span></a><span class="sd">            self: The instance itself, allowing for method chaining</span>
</span><span id="GridSearchCV-57"><a href="#GridSearchCV-57"><span class="linenos">57</span></a><span class="sd">            </span>
</span><span id="GridSearchCV-58"><a href="#GridSearchCV-58"><span class="linenos">58</span></a><span class="sd">        Example:</span>
</span><span id="GridSearchCV-59"><a href="#GridSearchCV-59"><span class="linenos">59</span></a><span class="sd">            &gt;&gt;&gt; grid_search.fit(X_train, y_train)</span>
</span><span id="GridSearchCV-60"><a href="#GridSearchCV-60"><span class="linenos">60</span></a><span class="sd">            &gt;&gt;&gt; best_params = grid_search.best_params_</span>
</span><span id="GridSearchCV-61"><a href="#GridSearchCV-61"><span class="linenos">61</span></a><span class="sd">            &gt;&gt;&gt; best_score = grid_search.best_score_</span>
</span><span id="GridSearchCV-62"><a href="#GridSearchCV-62"><span class="linenos">62</span></a><span class="sd">            &gt;&gt;&gt; best_model = grid_search.best_estimator_</span>
</span><span id="GridSearchCV-63"><a href="#GridSearchCV-63"><span class="linenos">63</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GridSearchCV-64"><a href="#GridSearchCV-64"><span class="linenos">64</span></a>        <span class="c1"># Extract hyperparameter names and values</span>
</span><span id="GridSearchCV-65"><a href="#GridSearchCV-65"><span class="linenos">65</span></a>        <span class="n">param_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span><span id="GridSearchCV-66"><a href="#GridSearchCV-66"><span class="linenos">66</span></a>        <span class="n">param_values</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
</span><span id="GridSearchCV-67"><a href="#GridSearchCV-67"><span class="linenos">67</span></a>        
</span><span id="GridSearchCV-68"><a href="#GridSearchCV-68"><span class="linenos">68</span></a>        <span class="c1"># Generate all possible combinations of hyperparameters</span>
</span><span id="GridSearchCV-69"><a href="#GridSearchCV-69"><span class="linenos">69</span></a>        <span class="k">for</span> <span class="n">param_combination</span> <span class="ow">in</span> <span class="n">product</span><span class="p">(</span><span class="o">*</span><span class="n">param_values</span><span class="p">):</span>
</span><span id="GridSearchCV-70"><a href="#GridSearchCV-70"><span class="linenos">70</span></a>            <span class="c1"># Create parameter dictionary for current combination</span>
</span><span id="GridSearchCV-71"><a href="#GridSearchCV-71"><span class="linenos">71</span></a>            <span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">param_names</span><span class="p">,</span> <span class="n">param_combination</span><span class="p">))</span>
</span><span id="GridSearchCV-72"><a href="#GridSearchCV-72"><span class="linenos">72</span></a>            <span class="c1"># Clone the model and set parameters</span>
</span><span id="GridSearchCV-73"><a href="#GridSearchCV-73"><span class="linenos">73</span></a>            <span class="n">model</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
</span><span id="GridSearchCV-74"><a href="#GridSearchCV-74"><span class="linenos">74</span></a>            
</span><span id="GridSearchCV-75"><a href="#GridSearchCV-75"><span class="linenos">75</span></a>            <span class="c1"># Perform cross-validation (stratified or standard)</span>
</span><span id="GridSearchCV-76"><a href="#GridSearchCV-76"><span class="linenos">76</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stratified</span><span class="p">:</span>
</span><span id="GridSearchCV-77"><a href="#GridSearchCV-77"><span class="linenos">77</span></a>                <span class="n">mean_score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">k_fold_cross_validation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span> <span class="n">stratified</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
</span><span id="GridSearchCV-78"><a href="#GridSearchCV-78"><span class="linenos">78</span></a>            <span class="k">else</span><span class="p">:</span> 
</span><span id="GridSearchCV-79"><a href="#GridSearchCV-79"><span class="linenos">79</span></a>                <span class="n">mean_score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">k_fold_cross_validation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span> <span class="n">stratified</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
</span><span id="GridSearchCV-80"><a href="#GridSearchCV-80"><span class="linenos">80</span></a>
</span><span id="GridSearchCV-81"><a href="#GridSearchCV-81"><span class="linenos">81</span></a>            <span class="c1"># Update best parameters if current combination is better</span>
</span><span id="GridSearchCV-82"><a href="#GridSearchCV-82"><span class="linenos">82</span></a>            <span class="k">if</span> <span class="n">mean_score</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span><span class="p">:</span>
</span><span id="GridSearchCV-83"><a href="#GridSearchCV-83"><span class="linenos">83</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span> <span class="o">=</span> <span class="n">mean_score</span>
</span><span id="GridSearchCV-84"><a href="#GridSearchCV-84"><span class="linenos">84</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span> <span class="o">=</span> <span class="n">params</span>
</span><span id="GridSearchCV-85"><a href="#GridSearchCV-85"><span class="linenos">85</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> 
</span><span id="GridSearchCV-86"><a href="#GridSearchCV-86"><span class="linenos">86</span></a>
</span><span id="GridSearchCV-87"><a href="#GridSearchCV-87"><span class="linenos">87</span></a>        <span class="c1">#print(&quot;Best hyperparameters:&quot;, self.best_params_)</span>
</span><span id="GridSearchCV-88"><a href="#GridSearchCV-88"><span class="linenos">88</span></a>        <span class="c1">#print(&quot;Best score:&quot;, self.best_score_)</span>
</span></pre></div>


            <div class="docstring"><p>Grid search implementation with cross-validation for hyperparameter optimization.</p>

<p>This class allows to test different combinations of hyperparameters on a machine learning model
using cross-validation to avoid overfitting and select the best hyperparameter combination.</p>

<p>Args:
    model: ML model to optimize (must implement fit and predict methods)
    param_grid: Dictionary of hyperparameters to test, where keys are parameter 
                names and values are lists of parameter values to try
    scoring: Evaluation function (e.g., accuracy_score, mean_squared_error, f1)
    k: Number of folds for cross-validation (default: 5)
    stratified: Whether to use stratified k-fold validation (default: False)</p>

<p>Returns:
    None</p>

<p>Example:</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>from ifri_mini_lib.supervised.classification import SVC
      from ifri_mini_lib.metrics import accuracy_score
      model = SVC()
      param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}
      grid_search = GridSearchCV(model, param_grid, accuracy_score, k=5)</p>
    </blockquote>
  </blockquote>
</blockquote>
</div>


                            <div id="GridSearchCV.__init__" class="classattr">
                                        <input id="GridSearchCV.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">GridSearchCV</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">model</span>, </span><span class="param"><span class="n">param_grid</span>, </span><span class="param"><span class="n">scoring</span>, </span><span class="param"><span class="n">k</span><span class="o">=</span><span class="mi">5</span>, </span><span class="param"><span class="n">stratified</span><span class="o">=</span><span class="kc">False</span></span>)</span>

                <label class="view-source-button" for="GridSearchCV.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GridSearchCV.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GridSearchCV.__init__-34"><a href="#GridSearchCV.__init__-34"><span class="linenos">34</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">stratified</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="GridSearchCV.__init__-35"><a href="#GridSearchCV.__init__-35"><span class="linenos">35</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="GridSearchCV.__init__-36"><a href="#GridSearchCV.__init__-36"><span class="linenos">36</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span>
</span><span id="GridSearchCV.__init__-37"><a href="#GridSearchCV.__init__-37"><span class="linenos">37</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
</span><span id="GridSearchCV.__init__-38"><a href="#GridSearchCV.__init__-38"><span class="linenos">38</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">=</span> <span class="n">scoring</span> 
</span><span id="GridSearchCV.__init__-39"><a href="#GridSearchCV.__init__-39"><span class="linenos">39</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">stratified</span> <span class="o">=</span> <span class="n">stratified</span>
</span><span id="GridSearchCV.__init__-40"><a href="#GridSearchCV.__init__-40"><span class="linenos">40</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="GridSearchCV.__init__-41"><a href="#GridSearchCV.__init__-41"><span class="linenos">41</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</span><span id="GridSearchCV.__init__-42"><a href="#GridSearchCV.__init__-42"><span class="linenos">42</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span> <span class="o">=</span> <span class="kc">None</span>
</span></pre></div>


    

                            </div>
                            <div id="GridSearchCV.model" class="classattr">
                                <div class="attr variable">
            <span class="name">model</span>

        
    </div>
    <a class="headerlink" href="#GridSearchCV.model"></a>
    
    

                            </div>
                            <div id="GridSearchCV.param_grid" class="classattr">
                                <div class="attr variable">
            <span class="name">param_grid</span>

        
    </div>
    <a class="headerlink" href="#GridSearchCV.param_grid"></a>
    
    

                            </div>
                            <div id="GridSearchCV.k" class="classattr">
                                <div class="attr variable">
            <span class="name">k</span>

        
    </div>
    <a class="headerlink" href="#GridSearchCV.k"></a>
    
    

                            </div>
                            <div id="GridSearchCV.scoring" class="classattr">
                                <div class="attr variable">
            <span class="name">scoring</span>

        
    </div>
    <a class="headerlink" href="#GridSearchCV.scoring"></a>
    
    

                            </div>
                            <div id="GridSearchCV.stratified" class="classattr">
                                <div class="attr variable">
            <span class="name">stratified</span>

        
    </div>
    <a class="headerlink" href="#GridSearchCV.stratified"></a>
    
    

                            </div>
                            <div id="GridSearchCV.best_params_" class="classattr">
                                <div class="attr variable">
            <span class="name">best_params_</span>

        
    </div>
    <a class="headerlink" href="#GridSearchCV.best_params_"></a>
    
    

                            </div>
                            <div id="GridSearchCV.best_score_" class="classattr">
                                <div class="attr variable">
            <span class="name">best_score_</span>

        
    </div>
    <a class="headerlink" href="#GridSearchCV.best_score_"></a>
    
    

                            </div>
                            <div id="GridSearchCV.best_estimator_" class="classattr">
                                <div class="attr variable">
            <span class="name">best_estimator_</span>

        
    </div>
    <a class="headerlink" href="#GridSearchCV.best_estimator_"></a>
    
    

                            </div>
                            <div id="GridSearchCV.fit" class="classattr">
                                        <input id="GridSearchCV.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="n">y</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="GridSearchCV.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#GridSearchCV.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="GridSearchCV.fit-45"><a href="#GridSearchCV.fit-45"><span class="linenos">45</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="GridSearchCV.fit-46"><a href="#GridSearchCV.fit-46"><span class="linenos">46</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="GridSearchCV.fit-47"><a href="#GridSearchCV.fit-47"><span class="linenos">47</span></a><span class="sd">        Description:</span>
</span><span id="GridSearchCV.fit-48"><a href="#GridSearchCV.fit-48"><span class="linenos">48</span></a><span class="sd">            Run grid search with cross-validation on the given data.</span>
</span><span id="GridSearchCV.fit-49"><a href="#GridSearchCV.fit-49"><span class="linenos">49</span></a><span class="sd">            Tests all possible combinations of hyperparameters and finds the best set.</span>
</span><span id="GridSearchCV.fit-50"><a href="#GridSearchCV.fit-50"><span class="linenos">50</span></a><span class="sd">            </span>
</span><span id="GridSearchCV.fit-51"><a href="#GridSearchCV.fit-51"><span class="linenos">51</span></a><span class="sd">        Args:</span>
</span><span id="GridSearchCV.fit-52"><a href="#GridSearchCV.fit-52"><span class="linenos">52</span></a><span class="sd">            X: Input features array of shape (n_samples, n_features)</span>
</span><span id="GridSearchCV.fit-53"><a href="#GridSearchCV.fit-53"><span class="linenos">53</span></a><span class="sd">            y: Target values array of shape (n_samples,)</span>
</span><span id="GridSearchCV.fit-54"><a href="#GridSearchCV.fit-54"><span class="linenos">54</span></a><span class="sd">            </span>
</span><span id="GridSearchCV.fit-55"><a href="#GridSearchCV.fit-55"><span class="linenos">55</span></a><span class="sd">        Returns:</span>
</span><span id="GridSearchCV.fit-56"><a href="#GridSearchCV.fit-56"><span class="linenos">56</span></a><span class="sd">            self: The instance itself, allowing for method chaining</span>
</span><span id="GridSearchCV.fit-57"><a href="#GridSearchCV.fit-57"><span class="linenos">57</span></a><span class="sd">            </span>
</span><span id="GridSearchCV.fit-58"><a href="#GridSearchCV.fit-58"><span class="linenos">58</span></a><span class="sd">        Example:</span>
</span><span id="GridSearchCV.fit-59"><a href="#GridSearchCV.fit-59"><span class="linenos">59</span></a><span class="sd">            &gt;&gt;&gt; grid_search.fit(X_train, y_train)</span>
</span><span id="GridSearchCV.fit-60"><a href="#GridSearchCV.fit-60"><span class="linenos">60</span></a><span class="sd">            &gt;&gt;&gt; best_params = grid_search.best_params_</span>
</span><span id="GridSearchCV.fit-61"><a href="#GridSearchCV.fit-61"><span class="linenos">61</span></a><span class="sd">            &gt;&gt;&gt; best_score = grid_search.best_score_</span>
</span><span id="GridSearchCV.fit-62"><a href="#GridSearchCV.fit-62"><span class="linenos">62</span></a><span class="sd">            &gt;&gt;&gt; best_model = grid_search.best_estimator_</span>
</span><span id="GridSearchCV.fit-63"><a href="#GridSearchCV.fit-63"><span class="linenos">63</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="GridSearchCV.fit-64"><a href="#GridSearchCV.fit-64"><span class="linenos">64</span></a>        <span class="c1"># Extract hyperparameter names and values</span>
</span><span id="GridSearchCV.fit-65"><a href="#GridSearchCV.fit-65"><span class="linenos">65</span></a>        <span class="n">param_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span><span id="GridSearchCV.fit-66"><a href="#GridSearchCV.fit-66"><span class="linenos">66</span></a>        <span class="n">param_values</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
</span><span id="GridSearchCV.fit-67"><a href="#GridSearchCV.fit-67"><span class="linenos">67</span></a>        
</span><span id="GridSearchCV.fit-68"><a href="#GridSearchCV.fit-68"><span class="linenos">68</span></a>        <span class="c1"># Generate all possible combinations of hyperparameters</span>
</span><span id="GridSearchCV.fit-69"><a href="#GridSearchCV.fit-69"><span class="linenos">69</span></a>        <span class="k">for</span> <span class="n">param_combination</span> <span class="ow">in</span> <span class="n">product</span><span class="p">(</span><span class="o">*</span><span class="n">param_values</span><span class="p">):</span>
</span><span id="GridSearchCV.fit-70"><a href="#GridSearchCV.fit-70"><span class="linenos">70</span></a>            <span class="c1"># Create parameter dictionary for current combination</span>
</span><span id="GridSearchCV.fit-71"><a href="#GridSearchCV.fit-71"><span class="linenos">71</span></a>            <span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">param_names</span><span class="p">,</span> <span class="n">param_combination</span><span class="p">))</span>
</span><span id="GridSearchCV.fit-72"><a href="#GridSearchCV.fit-72"><span class="linenos">72</span></a>            <span class="c1"># Clone the model and set parameters</span>
</span><span id="GridSearchCV.fit-73"><a href="#GridSearchCV.fit-73"><span class="linenos">73</span></a>            <span class="n">model</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
</span><span id="GridSearchCV.fit-74"><a href="#GridSearchCV.fit-74"><span class="linenos">74</span></a>            
</span><span id="GridSearchCV.fit-75"><a href="#GridSearchCV.fit-75"><span class="linenos">75</span></a>            <span class="c1"># Perform cross-validation (stratified or standard)</span>
</span><span id="GridSearchCV.fit-76"><a href="#GridSearchCV.fit-76"><span class="linenos">76</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stratified</span><span class="p">:</span>
</span><span id="GridSearchCV.fit-77"><a href="#GridSearchCV.fit-77"><span class="linenos">77</span></a>                <span class="n">mean_score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">k_fold_cross_validation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span> <span class="n">stratified</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
</span><span id="GridSearchCV.fit-78"><a href="#GridSearchCV.fit-78"><span class="linenos">78</span></a>            <span class="k">else</span><span class="p">:</span> 
</span><span id="GridSearchCV.fit-79"><a href="#GridSearchCV.fit-79"><span class="linenos">79</span></a>                <span class="n">mean_score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">k_fold_cross_validation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span> <span class="n">stratified</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
</span><span id="GridSearchCV.fit-80"><a href="#GridSearchCV.fit-80"><span class="linenos">80</span></a>
</span><span id="GridSearchCV.fit-81"><a href="#GridSearchCV.fit-81"><span class="linenos">81</span></a>            <span class="c1"># Update best parameters if current combination is better</span>
</span><span id="GridSearchCV.fit-82"><a href="#GridSearchCV.fit-82"><span class="linenos">82</span></a>            <span class="k">if</span> <span class="n">mean_score</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span><span class="p">:</span>
</span><span id="GridSearchCV.fit-83"><a href="#GridSearchCV.fit-83"><span class="linenos">83</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span> <span class="o">=</span> <span class="n">mean_score</span>
</span><span id="GridSearchCV.fit-84"><a href="#GridSearchCV.fit-84"><span class="linenos">84</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span> <span class="o">=</span> <span class="n">params</span>
</span><span id="GridSearchCV.fit-85"><a href="#GridSearchCV.fit-85"><span class="linenos">85</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> 
</span><span id="GridSearchCV.fit-86"><a href="#GridSearchCV.fit-86"><span class="linenos">86</span></a>
</span><span id="GridSearchCV.fit-87"><a href="#GridSearchCV.fit-87"><span class="linenos">87</span></a>        <span class="c1">#print(&quot;Best hyperparameters:&quot;, self.best_params_)</span>
</span><span id="GridSearchCV.fit-88"><a href="#GridSearchCV.fit-88"><span class="linenos">88</span></a>        <span class="c1">#print(&quot;Best score:&quot;, self.best_score_)</span>
</span></pre></div>


            <div class="docstring"><p>Description:
    Run grid search with cross-validation on the given data.
    Tests all possible combinations of hyperparameters and finds the best set.</p>

<p>Args:
    X: Input features array of shape (n_samples, n_features)
    y: Target values array of shape (n_samples,)</p>

<p>Returns:
    self: The instance itself, allowing for method chaining</p>

<p>Example:</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>grid_search.fit(X_train, y_train)
      best_params = grid_search.best_params_
      best_score = grid_search.best_score_
      best_model = grid_search.best_estimator_</p>
    </blockquote>
  </blockquote>
</blockquote>
</div>


                            </div>
                </section>
                <section id="RandomSearchCV">
                            <input id="RandomSearchCV-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">RandomSearchCV</span>:

                <label class="view-source-button" for="RandomSearchCV-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RandomSearchCV"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RandomSearchCV-7"><a href="#RandomSearchCV-7"><span class="linenos">  7</span></a><span class="k">class</span><span class="w"> </span><span class="nc">RandomSearchCV</span><span class="p">:</span>
</span><span id="RandomSearchCV-8"><a href="#RandomSearchCV-8"><span class="linenos">  8</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="RandomSearchCV-9"><a href="#RandomSearchCV-9"><span class="linenos">  9</span></a><span class="sd">    Description:</span>
</span><span id="RandomSearchCV-10"><a href="#RandomSearchCV-10"><span class="linenos"> 10</span></a><span class="sd">        A manual implementation of Random Search combined with Cross-Validation.</span>
</span><span id="RandomSearchCV-11"><a href="#RandomSearchCV-11"><span class="linenos"> 11</span></a><span class="sd">        This class randomly samples a subset of all hyperparameter combinations</span>
</span><span id="RandomSearchCV-12"><a href="#RandomSearchCV-12"><span class="linenos"> 12</span></a><span class="sd">        and evaluates each using k-fold cross-validation. It selects the model</span>
</span><span id="RandomSearchCV-13"><a href="#RandomSearchCV-13"><span class="linenos"> 13</span></a><span class="sd">        with the best average score based on the provided scoring function.</span>
</span><span id="RandomSearchCV-14"><a href="#RandomSearchCV-14"><span class="linenos"> 14</span></a>
</span><span id="RandomSearchCV-15"><a href="#RandomSearchCV-15"><span class="linenos"> 15</span></a><span class="sd">    Args:</span>
</span><span id="RandomSearchCV-16"><a href="#RandomSearchCV-16"><span class="linenos"> 16</span></a><span class="sd">        model (object): The machine learning model to optimize (must implement `fit`, `predict`, `set_params`).</span>
</span><span id="RandomSearchCV-17"><a href="#RandomSearchCV-17"><span class="linenos"> 17</span></a><span class="sd">        </span>
</span><span id="RandomSearchCV-18"><a href="#RandomSearchCV-18"><span class="linenos"> 18</span></a><span class="sd">        param_grid (dict): Dictionary of hyperparameters to explore. </span>
</span><span id="RandomSearchCV-19"><a href="#RandomSearchCV-19"><span class="linenos"> 19</span></a><span class="sd">                           Format: {&#39;param1&#39;: [v1, v2], &#39;param2&#39;: [v1, v2, v3]}.</span>
</span><span id="RandomSearchCV-20"><a href="#RandomSearchCV-20"><span class="linenos"> 20</span></a><span class="sd">        </span>
</span><span id="RandomSearchCV-21"><a href="#RandomSearchCV-21"><span class="linenos"> 21</span></a><span class="sd">        scoring (callable): Scoring function to evaluate model performance. </span>
</span><span id="RandomSearchCV-22"><a href="#RandomSearchCV-22"><span class="linenos"> 22</span></a><span class="sd">                            Example: ifri_mini_lib.metrics.accuracy_score or custom function.</span>
</span><span id="RandomSearchCV-23"><a href="#RandomSearchCV-23"><span class="linenos"> 23</span></a><span class="sd">        </span>
</span><span id="RandomSearchCV-24"><a href="#RandomSearchCV-24"><span class="linenos"> 24</span></a><span class="sd">        n_iter (int, optional): Number of random parameter combinations to try. Default is 10.</span>
</span><span id="RandomSearchCV-25"><a href="#RandomSearchCV-25"><span class="linenos"> 25</span></a><span class="sd">        </span>
</span><span id="RandomSearchCV-26"><a href="#RandomSearchCV-26"><span class="linenos"> 26</span></a><span class="sd">        k (int, optional): Number of folds for k-fold cross-validation. Default is 5.</span>
</span><span id="RandomSearchCV-27"><a href="#RandomSearchCV-27"><span class="linenos"> 27</span></a><span class="sd">        </span>
</span><span id="RandomSearchCV-28"><a href="#RandomSearchCV-28"><span class="linenos"> 28</span></a><span class="sd">        stratified (bool, optional): Whether to use stratified k-folds (useful for classification). Default is False.</span>
</span><span id="RandomSearchCV-29"><a href="#RandomSearchCV-29"><span class="linenos"> 29</span></a><span class="sd">        random_state (int or None, optional): Random seed for reproducibility.</span>
</span><span id="RandomSearchCV-30"><a href="#RandomSearchCV-30"><span class="linenos"> 30</span></a>
</span><span id="RandomSearchCV-31"><a href="#RandomSearchCV-31"><span class="linenos"> 31</span></a><span class="sd">    Attributes:</span>
</span><span id="RandomSearchCV-32"><a href="#RandomSearchCV-32"><span class="linenos"> 32</span></a><span class="sd">        best_params_ (dict): The best set of hyperparameters found during search.</span>
</span><span id="RandomSearchCV-33"><a href="#RandomSearchCV-33"><span class="linenos"> 33</span></a><span class="sd">        best_score_ (float): The best cross-validated score obtained.</span>
</span><span id="RandomSearchCV-34"><a href="#RandomSearchCV-34"><span class="linenos"> 34</span></a><span class="sd">        best_estimator_ (object): A clone of the model with the best hyperparameters.</span>
</span><span id="RandomSearchCV-35"><a href="#RandomSearchCV-35"><span class="linenos"> 35</span></a><span class="sd">    </span>
</span><span id="RandomSearchCV-36"><a href="#RandomSearchCV-36"><span class="linenos"> 36</span></a><span class="sd">    Example:</span>
</span><span id="RandomSearchCV-37"><a href="#RandomSearchCV-37"><span class="linenos"> 37</span></a><span class="sd">        &gt;&gt;&gt; from ifri_mini_lib.supervised.classification import DecisionTreeClassifier</span>
</span><span id="RandomSearchCV-38"><a href="#RandomSearchCV-38"><span class="linenos"> 38</span></a><span class="sd">        &gt;&gt;&gt; from ifri_mini_lib.metrics import accuracy_score</span>
</span><span id="RandomSearchCV-39"><a href="#RandomSearchCV-39"><span class="linenos"> 39</span></a>
</span><span id="RandomSearchCV-40"><a href="#RandomSearchCV-40"><span class="linenos"> 40</span></a><span class="sd">        &gt;&gt;&gt; param_grid = {</span>
</span><span id="RandomSearchCV-41"><a href="#RandomSearchCV-41"><span class="linenos"> 41</span></a><span class="sd">            &#39;max_depth&#39;: [3, 5, 7],</span>
</span><span id="RandomSearchCV-42"><a href="#RandomSearchCV-42"><span class="linenos"> 42</span></a><span class="sd">            &#39;min_samples_split&#39;: [2, 4, 6]</span>
</span><span id="RandomSearchCV-43"><a href="#RandomSearchCV-43"><span class="linenos"> 43</span></a><span class="sd">            }</span>
</span><span id="RandomSearchCV-44"><a href="#RandomSearchCV-44"><span class="linenos"> 44</span></a>
</span><span id="RandomSearchCV-45"><a href="#RandomSearchCV-45"><span class="linenos"> 45</span></a><span class="sd">        &gt;&gt;&gt; search = RandomSearchCV_Scratch(</span>
</span><span id="RandomSearchCV-46"><a href="#RandomSearchCV-46"><span class="linenos"> 46</span></a><span class="sd">            model=DecisionTreeClassifier(),</span>
</span><span id="RandomSearchCV-47"><a href="#RandomSearchCV-47"><span class="linenos"> 47</span></a><span class="sd">            param_grid=param_grid,</span>
</span><span id="RandomSearchCV-48"><a href="#RandomSearchCV-48"><span class="linenos"> 48</span></a><span class="sd">            scoring=accuracy_score,</span>
</span><span id="RandomSearchCV-49"><a href="#RandomSearchCV-49"><span class="linenos"> 49</span></a><span class="sd">            n_iter=5,</span>
</span><span id="RandomSearchCV-50"><a href="#RandomSearchCV-50"><span class="linenos"> 50</span></a><span class="sd">            k=3,</span>
</span><span id="RandomSearchCV-51"><a href="#RandomSearchCV-51"><span class="linenos"> 51</span></a><span class="sd">            stratified=True,</span>
</span><span id="RandomSearchCV-52"><a href="#RandomSearchCV-52"><span class="linenos"> 52</span></a><span class="sd">            random_state=42</span>
</span><span id="RandomSearchCV-53"><a href="#RandomSearchCV-53"><span class="linenos"> 53</span></a><span class="sd">            )</span>
</span><span id="RandomSearchCV-54"><a href="#RandomSearchCV-54"><span class="linenos"> 54</span></a>
</span><span id="RandomSearchCV-55"><a href="#RandomSearchCV-55"><span class="linenos"> 55</span></a><span class="sd">        &gt;&gt;&gt; search.fit(X_train, y_train)</span>
</span><span id="RandomSearchCV-56"><a href="#RandomSearchCV-56"><span class="linenos"> 56</span></a><span class="sd">        &gt;&gt;&gt; best_model = search.best_estimator_</span>
</span><span id="RandomSearchCV-57"><a href="#RandomSearchCV-57"><span class="linenos"> 57</span></a><span class="sd">        &gt;&gt;&gt; predictions = best_model.predict(X_test)</span>
</span><span id="RandomSearchCV-58"><a href="#RandomSearchCV-58"><span class="linenos"> 58</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="RandomSearchCV-59"><a href="#RandomSearchCV-59"><span class="linenos"> 59</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">stratified</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="RandomSearchCV-60"><a href="#RandomSearchCV-60"><span class="linenos"> 60</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="RandomSearchCV-61"><a href="#RandomSearchCV-61"><span class="linenos"> 61</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span>
</span><span id="RandomSearchCV-62"><a href="#RandomSearchCV-62"><span class="linenos"> 62</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>
</span><span id="RandomSearchCV-63"><a href="#RandomSearchCV-63"><span class="linenos"> 63</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
</span><span id="RandomSearchCV-64"><a href="#RandomSearchCV-64"><span class="linenos"> 64</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">=</span> <span class="n">scoring</span> 
</span><span id="RandomSearchCV-65"><a href="#RandomSearchCV-65"><span class="linenos"> 65</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">stratified</span> <span class="o">=</span> <span class="n">stratified</span>
</span><span id="RandomSearchCV-66"><a href="#RandomSearchCV-66"><span class="linenos"> 66</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
</span><span id="RandomSearchCV-67"><a href="#RandomSearchCV-67"><span class="linenos"> 67</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="RandomSearchCV-68"><a href="#RandomSearchCV-68"><span class="linenos"> 68</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</span><span id="RandomSearchCV-69"><a href="#RandomSearchCV-69"><span class="linenos"> 69</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="RandomSearchCV-70"><a href="#RandomSearchCV-70"><span class="linenos"> 70</span></a>
</span><span id="RandomSearchCV-71"><a href="#RandomSearchCV-71"><span class="linenos"> 71</span></a>    
</span><span id="RandomSearchCV-72"><a href="#RandomSearchCV-72"><span class="linenos"> 72</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="RandomSearchCV-73"><a href="#RandomSearchCV-73"><span class="linenos"> 73</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="RandomSearchCV-74"><a href="#RandomSearchCV-74"><span class="linenos"> 74</span></a><span class="sd">        Description:</span>
</span><span id="RandomSearchCV-75"><a href="#RandomSearchCV-75"><span class="linenos"> 75</span></a><span class="sd">            Runs the random search with cross-validation over the given dataset.</span>
</span><span id="RandomSearchCV-76"><a href="#RandomSearchCV-76"><span class="linenos"> 76</span></a><span class="sd">            Randomly selects hyperparameter combinations and evaluates them.</span>
</span><span id="RandomSearchCV-77"><a href="#RandomSearchCV-77"><span class="linenos"> 77</span></a>
</span><span id="RandomSearchCV-78"><a href="#RandomSearchCV-78"><span class="linenos"> 78</span></a><span class="sd">        Args:</span>
</span><span id="RandomSearchCV-79"><a href="#RandomSearchCV-79"><span class="linenos"> 79</span></a><span class="sd">            X (array-like): Feature matrix.</span>
</span><span id="RandomSearchCV-80"><a href="#RandomSearchCV-80"><span class="linenos"> 80</span></a><span class="sd">            y (array-like): Target vector.</span>
</span><span id="RandomSearchCV-81"><a href="#RandomSearchCV-81"><span class="linenos"> 81</span></a>
</span><span id="RandomSearchCV-82"><a href="#RandomSearchCV-82"><span class="linenos"> 82</span></a><span class="sd">        Returns:</span>
</span><span id="RandomSearchCV-83"><a href="#RandomSearchCV-83"><span class="linenos"> 83</span></a><span class="sd">            None</span>
</span><span id="RandomSearchCV-84"><a href="#RandomSearchCV-84"><span class="linenos"> 84</span></a>
</span><span id="RandomSearchCV-85"><a href="#RandomSearchCV-85"><span class="linenos"> 85</span></a><span class="sd">        Example:</span>
</span><span id="RandomSearchCV-86"><a href="#RandomSearchCV-86"><span class="linenos"> 86</span></a><span class="sd">            &gt;&gt;&gt; search.fit(X_train, y_train)</span>
</span><span id="RandomSearchCV-87"><a href="#RandomSearchCV-87"><span class="linenos"> 87</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="RandomSearchCV-88"><a href="#RandomSearchCV-88"><span class="linenos"> 88</span></a>
</span><span id="RandomSearchCV-89"><a href="#RandomSearchCV-89"><span class="linenos"> 89</span></a>        <span class="n">param_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span><span id="RandomSearchCV-90"><a href="#RandomSearchCV-90"><span class="linenos"> 90</span></a>        <span class="n">param_values</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
</span><span id="RandomSearchCV-91"><a href="#RandomSearchCV-91"><span class="linenos"> 91</span></a>        <span class="n">all_combinations</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">product</span><span class="p">(</span><span class="o">*</span><span class="n">param_values</span><span class="p">))</span>
</span><span id="RandomSearchCV-92"><a href="#RandomSearchCV-92"><span class="linenos"> 92</span></a>        
</span><span id="RandomSearchCV-93"><a href="#RandomSearchCV-93"><span class="linenos"> 93</span></a>        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
</span><span id="RandomSearchCV-94"><a href="#RandomSearchCV-94"><span class="linenos"> 94</span></a>        
</span><span id="RandomSearchCV-95"><a href="#RandomSearchCV-95"><span class="linenos"> 95</span></a>        <span class="c1">#Tire au hasard (et sans doublons) des indices parmi toutes les combinaisons dâhyperparamÃ¨tres disponibles, dans la limite de n_iter.</span>
</span><span id="RandomSearchCV-96"><a href="#RandomSearchCV-96"><span class="linenos"> 96</span></a>        <span class="n">sampled_combinations</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_combinations</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_combinations</span><span class="p">)),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="RandomSearchCV-97"><a href="#RandomSearchCV-97"><span class="linenos"> 97</span></a>
</span><span id="RandomSearchCV-98"><a href="#RandomSearchCV-98"><span class="linenos"> 98</span></a>        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">sampled_combinations</span><span class="p">:</span>
</span><span id="RandomSearchCV-99"><a href="#RandomSearchCV-99"><span class="linenos"> 99</span></a>            <span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">param_names</span><span class="p">,</span> <span class="n">all_combinations</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
</span><span id="RandomSearchCV-100"><a href="#RandomSearchCV-100"><span class="linenos">100</span></a>           
</span><span id="RandomSearchCV-101"><a href="#RandomSearchCV-101"><span class="linenos">101</span></a>            <span class="n">model</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</span><span id="RandomSearchCV-102"><a href="#RandomSearchCV-102"><span class="linenos">102</span></a>            <span class="n">model</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
</span><span id="RandomSearchCV-103"><a href="#RandomSearchCV-103"><span class="linenos">103</span></a>
</span><span id="RandomSearchCV-104"><a href="#RandomSearchCV-104"><span class="linenos">104</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stratified</span><span class="p">:</span>
</span><span id="RandomSearchCV-105"><a href="#RandomSearchCV-105"><span class="linenos">105</span></a>                <span class="n">mean_score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">k_fold_cross_validation</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">metric</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span> <span class="n">stratified</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
</span><span id="RandomSearchCV-106"><a href="#RandomSearchCV-106"><span class="linenos">106</span></a>            <span class="k">else</span><span class="p">:</span> 
</span><span id="RandomSearchCV-107"><a href="#RandomSearchCV-107"><span class="linenos">107</span></a>                <span class="n">mean_score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">k_fold_cross_validation</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">metric</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span> <span class="n">stratified</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
</span><span id="RandomSearchCV-108"><a href="#RandomSearchCV-108"><span class="linenos">108</span></a>            
</span><span id="RandomSearchCV-109"><a href="#RandomSearchCV-109"><span class="linenos">109</span></a>            <span class="k">if</span> <span class="n">mean_score</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span><span class="p">:</span>
</span><span id="RandomSearchCV-110"><a href="#RandomSearchCV-110"><span class="linenos">110</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span> <span class="o">=</span> <span class="n">mean_score</span>
</span><span id="RandomSearchCV-111"><a href="#RandomSearchCV-111"><span class="linenos">111</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span> <span class="o">=</span> <span class="n">params</span>
</span><span id="RandomSearchCV-112"><a href="#RandomSearchCV-112"><span class="linenos">112</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span> <span class="o">=</span> <span class="n">model</span>
</span></pre></div>


            <div class="docstring"><p>Description:
    A manual implementation of Random Search combined with Cross-Validation.
    This class randomly samples a subset of all hyperparameter combinations
    and evaluates each using k-fold cross-validation. It selects the model
    with the best average score based on the provided scoring function.</p>

<p>Args:
    model (object): The machine learning model to optimize (must implement <code><a href="#RandomSearchCV.fit">fit</a></code>, <code>predict</code>, <code>set_params</code>).</p>

<pre><code>param_grid (dict): Dictionary of hyperparameters to explore. 
                   Format: {'param1': [v1, v2], 'param2': [v1, v2, v3]}.

scoring (callable): Scoring function to evaluate model performance. 
                    Example: ifri_mini_lib.metrics.accuracy_score or custom function.

n_iter (int, optional): Number of random parameter combinations to try. Default is 10.

k (int, optional): Number of folds for k-fold cross-validation. Default is 5.

stratified (bool, optional): Whether to use stratified k-folds (useful for classification). Default is False.
random_state (int or None, optional): Random seed for reproducibility.
</code></pre>

<p>Attributes:
    best_params_ (dict): The best set of hyperparameters found during search.
    best_score_ (float): The best cross-validated score obtained.
    best_estimator_ (object): A clone of the model with the best hyperparameters.</p>

<p>Example:</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>from ifri_mini_lib.supervised.classification import DecisionTreeClassifier
      from ifri_mini_lib.metrics import accuracy_score</p>

<pre><code>&gt;&gt;&gt; param_grid = {
    'max_depth': [3, 5, 7],
    'min_samples_split': [2, 4, 6]
    }

&gt;&gt;&gt; search = RandomSearchCV_Scratch(
    model=DecisionTreeClassifier(),
    param_grid=param_grid,
    scoring=accuracy_score,
    n_iter=5,
    k=3,
    stratified=True,
    random_state=42
    )

&gt;&gt;&gt; search.fit(X_train, y_train)
&gt;&gt;&gt; best_model = search.best_estimator_
&gt;&gt;&gt; predictions = best_model.predict(X_test)
</code></pre>
    </blockquote>
  </blockquote>
</blockquote>
</div>


                            <div id="RandomSearchCV.__init__" class="classattr">
                                        <input id="RandomSearchCV.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">RandomSearchCV</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">model</span>,</span><span class="param">	<span class="n">param_grid</span>,</span><span class="param">	<span class="n">scoring</span>,</span><span class="param">	<span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span>,</span><span class="param">	<span class="n">k</span><span class="o">=</span><span class="mi">5</span>,</span><span class="param">	<span class="n">stratified</span><span class="o">=</span><span class="kc">False</span>,</span><span class="param">	<span class="n">random_state</span><span class="o">=</span><span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="RandomSearchCV.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RandomSearchCV.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RandomSearchCV.__init__-59"><a href="#RandomSearchCV.__init__-59"><span class="linenos">59</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">scoring</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">stratified</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="RandomSearchCV.__init__-60"><a href="#RandomSearchCV.__init__-60"><span class="linenos">60</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="RandomSearchCV.__init__-61"><a href="#RandomSearchCV.__init__-61"><span class="linenos">61</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span>
</span><span id="RandomSearchCV.__init__-62"><a href="#RandomSearchCV.__init__-62"><span class="linenos">62</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span> <span class="o">=</span> <span class="n">n_iter</span>
</span><span id="RandomSearchCV.__init__-63"><a href="#RandomSearchCV.__init__-63"><span class="linenos">63</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
</span><span id="RandomSearchCV.__init__-64"><a href="#RandomSearchCV.__init__-64"><span class="linenos">64</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">=</span> <span class="n">scoring</span> 
</span><span id="RandomSearchCV.__init__-65"><a href="#RandomSearchCV.__init__-65"><span class="linenos">65</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">stratified</span> <span class="o">=</span> <span class="n">stratified</span>
</span><span id="RandomSearchCV.__init__-66"><a href="#RandomSearchCV.__init__-66"><span class="linenos">66</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
</span><span id="RandomSearchCV.__init__-67"><a href="#RandomSearchCV.__init__-67"><span class="linenos">67</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="RandomSearchCV.__init__-68"><a href="#RandomSearchCV.__init__-68"><span class="linenos">68</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</span><span id="RandomSearchCV.__init__-69"><a href="#RandomSearchCV.__init__-69"><span class="linenos">69</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span> <span class="o">=</span> <span class="kc">None</span>
</span></pre></div>


    

                            </div>
                            <div id="RandomSearchCV.model" class="classattr">
                                <div class="attr variable">
            <span class="name">model</span>

        
    </div>
    <a class="headerlink" href="#RandomSearchCV.model"></a>
    
    

                            </div>
                            <div id="RandomSearchCV.param_grid" class="classattr">
                                <div class="attr variable">
            <span class="name">param_grid</span>

        
    </div>
    <a class="headerlink" href="#RandomSearchCV.param_grid"></a>
    
    

                            </div>
                            <div id="RandomSearchCV.n_iter" class="classattr">
                                <div class="attr variable">
            <span class="name">n_iter</span>

        
    </div>
    <a class="headerlink" href="#RandomSearchCV.n_iter"></a>
    
    

                            </div>
                            <div id="RandomSearchCV.k" class="classattr">
                                <div class="attr variable">
            <span class="name">k</span>

        
    </div>
    <a class="headerlink" href="#RandomSearchCV.k"></a>
    
    

                            </div>
                            <div id="RandomSearchCV.scoring" class="classattr">
                                <div class="attr variable">
            <span class="name">scoring</span>

        
    </div>
    <a class="headerlink" href="#RandomSearchCV.scoring"></a>
    
    

                            </div>
                            <div id="RandomSearchCV.stratified" class="classattr">
                                <div class="attr variable">
            <span class="name">stratified</span>

        
    </div>
    <a class="headerlink" href="#RandomSearchCV.stratified"></a>
    
    

                            </div>
                            <div id="RandomSearchCV.random_state" class="classattr">
                                <div class="attr variable">
            <span class="name">random_state</span>

        
    </div>
    <a class="headerlink" href="#RandomSearchCV.random_state"></a>
    
    

                            </div>
                            <div id="RandomSearchCV.best_params_" class="classattr">
                                <div class="attr variable">
            <span class="name">best_params_</span>

        
    </div>
    <a class="headerlink" href="#RandomSearchCV.best_params_"></a>
    
    

                            </div>
                            <div id="RandomSearchCV.best_score_" class="classattr">
                                <div class="attr variable">
            <span class="name">best_score_</span>

        
    </div>
    <a class="headerlink" href="#RandomSearchCV.best_score_"></a>
    
    

                            </div>
                            <div id="RandomSearchCV.best_estimator_" class="classattr">
                                <div class="attr variable">
            <span class="name">best_estimator_</span>

        
    </div>
    <a class="headerlink" href="#RandomSearchCV.best_estimator_"></a>
    
    

                            </div>
                            <div id="RandomSearchCV.fit" class="classattr">
                                        <input id="RandomSearchCV.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="n">y</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="RandomSearchCV.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RandomSearchCV.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RandomSearchCV.fit-72"><a href="#RandomSearchCV.fit-72"><span class="linenos"> 72</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="RandomSearchCV.fit-73"><a href="#RandomSearchCV.fit-73"><span class="linenos"> 73</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="RandomSearchCV.fit-74"><a href="#RandomSearchCV.fit-74"><span class="linenos"> 74</span></a><span class="sd">        Description:</span>
</span><span id="RandomSearchCV.fit-75"><a href="#RandomSearchCV.fit-75"><span class="linenos"> 75</span></a><span class="sd">            Runs the random search with cross-validation over the given dataset.</span>
</span><span id="RandomSearchCV.fit-76"><a href="#RandomSearchCV.fit-76"><span class="linenos"> 76</span></a><span class="sd">            Randomly selects hyperparameter combinations and evaluates them.</span>
</span><span id="RandomSearchCV.fit-77"><a href="#RandomSearchCV.fit-77"><span class="linenos"> 77</span></a>
</span><span id="RandomSearchCV.fit-78"><a href="#RandomSearchCV.fit-78"><span class="linenos"> 78</span></a><span class="sd">        Args:</span>
</span><span id="RandomSearchCV.fit-79"><a href="#RandomSearchCV.fit-79"><span class="linenos"> 79</span></a><span class="sd">            X (array-like): Feature matrix.</span>
</span><span id="RandomSearchCV.fit-80"><a href="#RandomSearchCV.fit-80"><span class="linenos"> 80</span></a><span class="sd">            y (array-like): Target vector.</span>
</span><span id="RandomSearchCV.fit-81"><a href="#RandomSearchCV.fit-81"><span class="linenos"> 81</span></a>
</span><span id="RandomSearchCV.fit-82"><a href="#RandomSearchCV.fit-82"><span class="linenos"> 82</span></a><span class="sd">        Returns:</span>
</span><span id="RandomSearchCV.fit-83"><a href="#RandomSearchCV.fit-83"><span class="linenos"> 83</span></a><span class="sd">            None</span>
</span><span id="RandomSearchCV.fit-84"><a href="#RandomSearchCV.fit-84"><span class="linenos"> 84</span></a>
</span><span id="RandomSearchCV.fit-85"><a href="#RandomSearchCV.fit-85"><span class="linenos"> 85</span></a><span class="sd">        Example:</span>
</span><span id="RandomSearchCV.fit-86"><a href="#RandomSearchCV.fit-86"><span class="linenos"> 86</span></a><span class="sd">            &gt;&gt;&gt; search.fit(X_train, y_train)</span>
</span><span id="RandomSearchCV.fit-87"><a href="#RandomSearchCV.fit-87"><span class="linenos"> 87</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="RandomSearchCV.fit-88"><a href="#RandomSearchCV.fit-88"><span class="linenos"> 88</span></a>
</span><span id="RandomSearchCV.fit-89"><a href="#RandomSearchCV.fit-89"><span class="linenos"> 89</span></a>        <span class="n">param_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span><span id="RandomSearchCV.fit-90"><a href="#RandomSearchCV.fit-90"><span class="linenos"> 90</span></a>        <span class="n">param_values</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
</span><span id="RandomSearchCV.fit-91"><a href="#RandomSearchCV.fit-91"><span class="linenos"> 91</span></a>        <span class="n">all_combinations</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">product</span><span class="p">(</span><span class="o">*</span><span class="n">param_values</span><span class="p">))</span>
</span><span id="RandomSearchCV.fit-92"><a href="#RandomSearchCV.fit-92"><span class="linenos"> 92</span></a>        
</span><span id="RandomSearchCV.fit-93"><a href="#RandomSearchCV.fit-93"><span class="linenos"> 93</span></a>        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
</span><span id="RandomSearchCV.fit-94"><a href="#RandomSearchCV.fit-94"><span class="linenos"> 94</span></a>        
</span><span id="RandomSearchCV.fit-95"><a href="#RandomSearchCV.fit-95"><span class="linenos"> 95</span></a>        <span class="c1">#Tire au hasard (et sans doublons) des indices parmi toutes les combinaisons dâhyperparamÃ¨tres disponibles, dans la limite de n_iter.</span>
</span><span id="RandomSearchCV.fit-96"><a href="#RandomSearchCV.fit-96"><span class="linenos"> 96</span></a>        <span class="n">sampled_combinations</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_combinations</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iter</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_combinations</span><span class="p">)),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="RandomSearchCV.fit-97"><a href="#RandomSearchCV.fit-97"><span class="linenos"> 97</span></a>
</span><span id="RandomSearchCV.fit-98"><a href="#RandomSearchCV.fit-98"><span class="linenos"> 98</span></a>        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">sampled_combinations</span><span class="p">:</span>
</span><span id="RandomSearchCV.fit-99"><a href="#RandomSearchCV.fit-99"><span class="linenos"> 99</span></a>            <span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">param_names</span><span class="p">,</span> <span class="n">all_combinations</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
</span><span id="RandomSearchCV.fit-100"><a href="#RandomSearchCV.fit-100"><span class="linenos">100</span></a>           
</span><span id="RandomSearchCV.fit-101"><a href="#RandomSearchCV.fit-101"><span class="linenos">101</span></a>            <span class="n">model</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</span><span id="RandomSearchCV.fit-102"><a href="#RandomSearchCV.fit-102"><span class="linenos">102</span></a>            <span class="n">model</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
</span><span id="RandomSearchCV.fit-103"><a href="#RandomSearchCV.fit-103"><span class="linenos">103</span></a>
</span><span id="RandomSearchCV.fit-104"><a href="#RandomSearchCV.fit-104"><span class="linenos">104</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stratified</span><span class="p">:</span>
</span><span id="RandomSearchCV.fit-105"><a href="#RandomSearchCV.fit-105"><span class="linenos">105</span></a>                <span class="n">mean_score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">k_fold_cross_validation</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">metric</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span> <span class="n">stratified</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
</span><span id="RandomSearchCV.fit-106"><a href="#RandomSearchCV.fit-106"><span class="linenos">106</span></a>            <span class="k">else</span><span class="p">:</span> 
</span><span id="RandomSearchCV.fit-107"><a href="#RandomSearchCV.fit-107"><span class="linenos">107</span></a>                <span class="n">mean_score</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">k_fold_cross_validation</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">metric</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">,</span> <span class="n">stratified</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
</span><span id="RandomSearchCV.fit-108"><a href="#RandomSearchCV.fit-108"><span class="linenos">108</span></a>            
</span><span id="RandomSearchCV.fit-109"><a href="#RandomSearchCV.fit-109"><span class="linenos">109</span></a>            <span class="k">if</span> <span class="n">mean_score</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span><span class="p">:</span>
</span><span id="RandomSearchCV.fit-110"><a href="#RandomSearchCV.fit-110"><span class="linenos">110</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">best_score_</span> <span class="o">=</span> <span class="n">mean_score</span>
</span><span id="RandomSearchCV.fit-111"><a href="#RandomSearchCV.fit-111"><span class="linenos">111</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">best_params_</span> <span class="o">=</span> <span class="n">params</span>
</span><span id="RandomSearchCV.fit-112"><a href="#RandomSearchCV.fit-112"><span class="linenos">112</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">best_estimator_</span> <span class="o">=</span> <span class="n">model</span>
</span></pre></div>


            <div class="docstring"><p>Description:
    Runs the random search with cross-validation over the given dataset.
    Randomly selects hyperparameter combinations and evaluates them.</p>

<p>Args:
    X (array-like): Feature matrix.
    y (array-like): Target vector.</p>

<p>Returns:
    None</p>

<p>Example:</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>search.fit(X_train, y_train)</p>
    </blockquote>
  </blockquote>
</blockquote>
</div>


                            </div>
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>